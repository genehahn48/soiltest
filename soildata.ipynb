{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangling Soil Test data from University of Kentucky's Soil Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Microsoft Access to export data into CSV text file with FIPS code add and quary to select just County by County name. Export as soildata_fips.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import profiling to get quick analysis of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets\n",
    "from pandas_profiling import ProfileReport\n",
    "# from pandas_profiling.utils.cache import cache_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set file path to get data to work on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = Path('data')\n",
    "fileOut = Path('project-data')\n",
    "file_soil = filePath.joinpath('soildata_fips.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soil = pd.read_csv(file_soil, dtype='str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that file is read into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1190126 entries, 0 to 1190125\n",
      "Data columns (total 14 columns):\n",
      "FIPS_NO    1190126 non-null object\n",
      "YEAR       1190126 non-null object\n",
      "FM         1190052 non-null object\n",
      "COUNTY     1190126 non-null object\n",
      "AREA       1190126 non-null object\n",
      "PH         1187607 non-null object\n",
      "BUPH       1056246 non-null object\n",
      "P          1187473 non-null object\n",
      "K          1187494 non-null object\n",
      "CA         969266 non-null object\n",
      "MG         969725 non-null object\n",
      "ZN         967041 non-null object\n",
      "ACRES      525128 non-null object\n",
      "CROP       1183431 non-null object\n",
      "dtypes: object(14)\n",
      "memory usage: 127.1+ MB\n"
     ]
    }
   ],
   "source": [
    "soil.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1990.00', '1991.00', '1992.00', '1993.00', '1994.00', '1995.00',\n",
       "       '1996.00', '1997.00', '1998.00', '1999.00', '2000.00', '2001.00',\n",
       "       '2002.00', '2003.00', '2004.00', '2005.00', '2006.00', '2007.00',\n",
       "       '2008.00', '2009.00', '2010.00', '2011.00', '2012.00', '2013.00',\n",
       "       '2014.00', '2015.00', '2016.00', '2017.00', '2018.00', '2019.00'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_dup = soil.YEAR.unique()\n",
    "year_dup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove decimal from FIPS_NO and Year, can't convert to an integer because of pivot table columns later in processing. Convert PH, BUPH, P, K, and Acres into Float type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = soil.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1190126 entries, 0 to 1190125\n",
      "Data columns (total 14 columns):\n",
      "FIPS_NO    1190126 non-null object\n",
      "YEAR       1190126 non-null object\n",
      "FM         1190052 non-null object\n",
      "COUNTY     1190126 non-null object\n",
      "AREA       1190126 non-null object\n",
      "PH         1187607 non-null float64\n",
      "BUPH       1056246 non-null float64\n",
      "P          1187473 non-null float64\n",
      "K          1187494 non-null float64\n",
      "CA         969266 non-null object\n",
      "MG         969725 non-null object\n",
      "ZN         967041 non-null object\n",
      "ACRES      525128 non-null float64\n",
      "CROP       1183431 non-null object\n",
      "dtypes: float64(5), object(9)\n",
      "memory usage: 127.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.FIPS_NO = df.FIPS_NO.astype('str').replace('\\.00','',regex=True)\n",
    "df.YEAR = df.YEAR.astype('str').replace('\\.00','',regex=True)\n",
    "df.PH = df.PH.astype('float')\n",
    "df.BUPH = df.BUPH.astype('float')\n",
    "df.P = df.P.astype('float')\n",
    "df.K = df.K.astype('float')\n",
    "df.ACRES = df.ACRES.astype('float')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1190126 entries, 0 to 1190125\n",
      "Data columns (total 14 columns):\n",
      "FIPS_NO    1190126 non-null object\n",
      "YEAR       1190126 non-null object\n",
      "FM         1190052 non-null object\n",
      "COUNTY     1190126 non-null object\n",
      "AREA       1190126 non-null object\n",
      "PH         1187607 non-null float64\n",
      "BUPH       1056246 non-null float64\n",
      "P          1187473 non-null float64\n",
      "K          1187494 non-null float64\n",
      "CA         969266 non-null object\n",
      "MG         969725 non-null object\n",
      "ZN         967041 non-null object\n",
      "ACRES      525128 non-null float64\n",
      "CROP       1183431 non-null object\n",
      "dtypes: float64(5), object(9)\n",
      "memory usage: 127.1+ MB\n",
      "  FIPS_NO  YEAR FM COUNTY                AREA    PH  BUPH      P      K  \\\n",
      "0       1  1990  A  ADAIR  Eastern Pennyroyal  7.15  7.23   28.0  158.0   \n",
      "1       1  1990  A  ADAIR  Eastern Pennyroyal  6.95  7.22   88.0  134.0   \n",
      "2       1  1990  A  ADAIR  Eastern Pennyroyal  6.26  6.94   70.0  256.0   \n",
      "3       1  1990  A  ADAIR  Eastern Pennyroyal  5.67  6.69  161.0  611.0   \n",
      "4       1  1990  A  ADAIR  Eastern Pennyroyal  7.26  7.47  105.0  315.0   \n",
      "\n",
      "        CA      MG   ZN  ACRES     CROP  \n",
      "0      NaN     NaN  NaN   18.0  Alfalfa  \n",
      "1  2890.00  159.00  NaN   15.0  Alfalfa  \n",
      "2      NaN     NaN  NaN   16.0  Alfalfa  \n",
      "3      NaN     NaN  NaN    6.0  Alfalfa  \n",
      "4  2940.00  137.00  NaN   25.0  Alfalfa  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS_NO</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>FM</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>AREA</th>\n",
       "      <th>PH</th>\n",
       "      <th>BUPH</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>CA</th>\n",
       "      <th>MG</th>\n",
       "      <th>ZN</th>\n",
       "      <th>ACRES</th>\n",
       "      <th>CROP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1190121</th>\n",
       "      <td>239</td>\n",
       "      <td>2019</td>\n",
       "      <td>A</td>\n",
       "      <td>WOODFORD</td>\n",
       "      <td>Bluegrass</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>62.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>1489.00</td>\n",
       "      <td>223.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Wildlife Food Plot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190122</th>\n",
       "      <td>239</td>\n",
       "      <td>2019</td>\n",
       "      <td>A</td>\n",
       "      <td>WOODFORD</td>\n",
       "      <td>Bluegrass</td>\n",
       "      <td>5.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>46.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>5247.00</td>\n",
       "      <td>268.00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Wildlife Food Plot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190123</th>\n",
       "      <td>239</td>\n",
       "      <td>2019</td>\n",
       "      <td>A</td>\n",
       "      <td>WOODFORD</td>\n",
       "      <td>Bluegrass</td>\n",
       "      <td>6.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>12047.00</td>\n",
       "      <td>281.00</td>\n",
       "      <td>1.20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Wildlife Food Plot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190124</th>\n",
       "      <td>239</td>\n",
       "      <td>2019</td>\n",
       "      <td>A</td>\n",
       "      <td>WOODFORD</td>\n",
       "      <td>Bluegrass</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6.6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>3304.00</td>\n",
       "      <td>396.00</td>\n",
       "      <td>2.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wildlife Food Plot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190125</th>\n",
       "      <td>239</td>\n",
       "      <td>2019</td>\n",
       "      <td>A</td>\n",
       "      <td>WOODFORD</td>\n",
       "      <td>Bluegrass</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>59.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>4341.00</td>\n",
       "      <td>349.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Wildlife Food Plot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        FIPS_NO  YEAR FM    COUNTY       AREA   PH  BUPH     P      K  \\\n",
       "1190121     239  2019  A  WOODFORD  Bluegrass  5.0   6.3  62.0  319.0   \n",
       "1190122     239  2019  A  WOODFORD  Bluegrass  5.9   6.7  46.0  257.0   \n",
       "1190123     239  2019  A  WOODFORD  Bluegrass  6.8   7.0  75.0  243.0   \n",
       "1190124     239  2019  A  WOODFORD  Bluegrass  5.3   6.6  60.0  407.0   \n",
       "1190125     239  2019  A  WOODFORD  Bluegrass  5.0   6.3  59.0  377.0   \n",
       "\n",
       "               CA      MG    ZN  ACRES                CROP  \n",
       "1190121   1489.00  223.00  3.50    1.0  Wildlife Food Plot  \n",
       "1190122   5247.00  268.00  2.10    2.0  Wildlife Food Plot  \n",
       "1190123  12047.00  281.00  1.20    2.0  Wildlife Food Plot  \n",
       "1190124   3304.00  396.00  2.80    NaN  Wildlife Food Plot  \n",
       "1190125   4341.00  349.00  2.00    1.5  Wildlife Food Plot  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "print(df.head())\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create profile report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop CA, MG, ZN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['CA','MG','ZN'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1190126 entries, 0 to 1190125\n",
      "Data columns (total 11 columns):\n",
      "FIPS_NO    1190126 non-null object\n",
      "YEAR       1190126 non-null object\n",
      "FM         1190052 non-null object\n",
      "COUNTY     1190126 non-null object\n",
      "AREA       1190126 non-null object\n",
      "PH         1187607 non-null float64\n",
      "BUPH       1056246 non-null float64\n",
      "P          1187473 non-null float64\n",
      "K          1187494 non-null float64\n",
      "ACRES      525128 non-null float64\n",
      "CROP       1183431 non-null object\n",
      "dtypes: float64(5), object(6)\n",
      "memory usage: 99.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the maximum and minimum values for P and K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max P = 21658.0 min P = -9.0\n",
      "max K 60452.0 min K = -26.0\n"
     ]
    }
   ],
   "source": [
    "print(\"max P =\", df.P.max(), \"min P =\",df.P.min())\n",
    "print(\"max K\" , df.K.max(), \"min K =\", df.K.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove values less than zero and above 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df['P'] < 0)]\n",
    "df = df[~(df['K'] < 0)]\n",
    "df = df[~(df['P'] >= 9999)]\n",
    "df = df[~(df['K'] >= 9999)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max P = 9778.0 min P = 0.0\n",
      "max K 9964.0 min K = 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"max P =\", df.P.max(), \"min P =\",df.P.min())\n",
    "print(\"max K\" , df.K.max(), \"min K =\", df.K.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select agricultural \"A\" and commercial \"C\" types from FM column. Append df together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.loc[(df['FM'] == 'A')]\n",
    "df2 = df.loc[(df['FM'] == 'C')]\n",
    "df3 = df1.append(df2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 941637 entries, 0 to 1190125\n",
      "Data columns (total 11 columns):\n",
      "FIPS_NO    941637 non-null object\n",
      "YEAR       941637 non-null object\n",
      "FM         941637 non-null object\n",
      "COUNTY     941637 non-null object\n",
      "AREA       941637 non-null object\n",
      "PH         940288 non-null float64\n",
      "BUPH       836405 non-null float64\n",
      "P          940284 non-null float64\n",
      "K          940295 non-null float64\n",
      "ACRES      511570 non-null float64\n",
      "CROP       938347 non-null object\n",
      "dtypes: float64(5), object(6)\n",
      "memory usage: 86.2+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21910 entries, 153 to 1190012\n",
      "Data columns (total 11 columns):\n",
      "FIPS_NO    21910 non-null object\n",
      "YEAR       21910 non-null object\n",
      "FM         21910 non-null object\n",
      "COUNTY     21910 non-null object\n",
      "AREA       21910 non-null object\n",
      "PH         21882 non-null float64\n",
      "BUPH       20540 non-null float64\n",
      "P          21881 non-null float64\n",
      "K          21883 non-null float64\n",
      "ACRES      7362 non-null float64\n",
      "CROP       21858 non-null object\n",
      "dtypes: float64(5), object(6)\n",
      "memory usage: 2.0+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 963547 entries, 0 to 963546\n",
      "Data columns (total 11 columns):\n",
      "FIPS_NO    963547 non-null object\n",
      "YEAR       963547 non-null object\n",
      "FM         963547 non-null object\n",
      "COUNTY     963547 non-null object\n",
      "AREA       963547 non-null object\n",
      "PH         962170 non-null float64\n",
      "BUPH       856945 non-null float64\n",
      "P          962165 non-null float64\n",
      "K          962178 non-null float64\n",
      "ACRES      518932 non-null float64\n",
      "CROP       960205 non-null object\n",
      "dtypes: float64(5), object(6)\n",
      "memory usage: 80.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df1.info())\n",
    "print(df2.info())\n",
    "print(df3.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop null values from CROP, P, K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 958826 entries, 0 to 963546\n",
      "Data columns (total 11 columns):\n",
      "FIPS_NO    958826 non-null object\n",
      "YEAR       958826 non-null object\n",
      "FM         958826 non-null object\n",
      "COUNTY     958826 non-null object\n",
      "AREA       958826 non-null object\n",
      "PH         958813 non-null float64\n",
      "BUPH       854104 non-null float64\n",
      "P          958826 non-null float64\n",
      "K          958826 non-null float64\n",
      "ACRES      517097 non-null float64\n",
      "CROP       958826 non-null object\n",
      "dtypes: float64(5), object(6)\n",
      "memory usage: 87.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df3.drop(df3[df3['CROP'].isnull()].index, inplace=True)\n",
    "df3.drop(df3[df3['P'].isnull()].index, inplace=True)\n",
    "df3.drop(df3[df3['K'].isnull()].index, inplace=True)\n",
    "df3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resort and index dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS_NO</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>AREA</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>CROP</th>\n",
       "      <th>ACRES</th>\n",
       "      <th>PH</th>\n",
       "      <th>BUPH</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>Eastern Pennyroyal</td>\n",
       "      <td>1990</td>\n",
       "      <td>Alfalfa</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.15</td>\n",
       "      <td>7.23</td>\n",
       "      <td>28.0</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>Eastern Pennyroyal</td>\n",
       "      <td>1990</td>\n",
       "      <td>Alfalfa</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.95</td>\n",
       "      <td>7.22</td>\n",
       "      <td>88.0</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>Eastern Pennyroyal</td>\n",
       "      <td>1990</td>\n",
       "      <td>Alfalfa</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.26</td>\n",
       "      <td>6.94</td>\n",
       "      <td>70.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>Eastern Pennyroyal</td>\n",
       "      <td>1990</td>\n",
       "      <td>Alfalfa</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.67</td>\n",
       "      <td>6.69</td>\n",
       "      <td>161.0</td>\n",
       "      <td>611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>Eastern Pennyroyal</td>\n",
       "      <td>1990</td>\n",
       "      <td>Alfalfa</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.26</td>\n",
       "      <td>7.47</td>\n",
       "      <td>105.0</td>\n",
       "      <td>315.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FIPS_NO COUNTY                AREA  YEAR     CROP  ACRES    PH  BUPH      P  \\\n",
       "0       1  ADAIR  Eastern Pennyroyal  1990  Alfalfa   18.0  7.15  7.23   28.0   \n",
       "1       1  ADAIR  Eastern Pennyroyal  1990  Alfalfa   15.0  6.95  7.22   88.0   \n",
       "2       1  ADAIR  Eastern Pennyroyal  1990  Alfalfa   16.0  6.26  6.94   70.0   \n",
       "3       1  ADAIR  Eastern Pennyroyal  1990  Alfalfa    6.0  5.67  6.69  161.0   \n",
       "4       1  ADAIR  Eastern Pennyroyal  1990  Alfalfa   25.0  7.26  7.47  105.0   \n",
       "\n",
       "       K  \n",
       "0  158.0  \n",
       "1  134.0  \n",
       "2  256.0  \n",
       "3  611.0  \n",
       "4  315.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df3[['FIPS_NO','COUNTY','AREA','YEAR','CROP','ACRES', 'PH', 'BUPH', 'P', 'K', ]]\n",
    "order_by_cols = ['FIPS_NO','YEAR','CROP']\n",
    "df = df.sort_values(by=order_by_cols, ascending=[True,True,True]).copy()\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save clean CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'data\\clean_soil_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 958826 entries, 0 to 958825\n",
      "Data columns (total 10 columns):\n",
      "FIPS_NO    958826 non-null object\n",
      "COUNTY     958826 non-null object\n",
      "AREA       958826 non-null object\n",
      "YEAR       958826 non-null object\n",
      "CROP       958826 non-null object\n",
      "ACRES      517097 non-null float64\n",
      "PH         958813 non-null float64\n",
      "BUPH       854104 non-null float64\n",
      "P          958826 non-null float64\n",
      "K          958826 non-null float64\n",
      "dtypes: float64(5), object(5)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find unique CROP types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alfalfa', 'Alfalfa/Cool Season', 'Burley Tobacco', 'Clover/Grass',\n",
       "       'Cole Crops (broccoli, etc.)', 'Corn', 'Corn, Sweet', 'Cucumbers',\n",
       "       'Fescue', 'No Info Given', 'Orchardgrass', 'Other Vegetables',\n",
       "       'Peppers (bell & pimento)', 'Red Clover', 'Timothy', 'Tomatoes',\n",
       "       'White Clover', 'White Clover/Grass', 'Rye', 'Soybeans',\n",
       "       'Tobacco Beds', 'Wheat', 'Oats', 'Red Clover/Grass',\n",
       "       'Warm Season Grass', 'Blueberries', 'Fescue/Lespedeza (multiple)',\n",
       "       'Forage Sorghum', 'Strawberries', 'Cool Season Grass',\n",
       "       'Evergreen Shrubs, Broadleaved', 'Sudangrass',\n",
       "       'Timothy/Red Clover', 'Lespedeza', 'Other Fruit & Nuts',\n",
       "       'Small Grains/Corn', 'Small Grains/Soybeans', 'Squash & Pumpkins',\n",
       "       'Birdsfoot Trefoil', 'Grain Sorghum', 'Lespedeza/Grass', 'Annuals',\n",
       "       'Fescue/Lespedeza', 'Forage Crops', 'Millet',\n",
       "       'Orchardgrass/Red Clover', 'Apples', 'Grapes', 'Peaches',\n",
       "       'Small Grains', 'Bermudagrass, common', 'Sweet Potatoes', 'Other',\n",
       "       'Azaleas', 'Brambles', 'Wheat/Soybeans', 'Potatoes',\n",
       "       'Warm Season Annual Grass', 'Bermudagrass, improved', 'Sunflower',\n",
       "       'Fescue/White Clover', 'Sorghum/Sudangras', 'Cherries, Tart',\n",
       "       'Pears', 'Watermelons', 'Root Crops (beets, carrots,etc.)',\n",
       "       'Switchgrass', 'Muskmelons (cantaloupes)',\n",
       "       'Native Grassland Restoration', 'Wildlife Food Plot',\n",
       "       'Beans (snap,dry,lima,etc.)', 'Greens (collards, kale, etc.)',\n",
       "       'Okra', 'Asparagus', 'Eggplant', 'Hemp', 'Rhubarb',\n",
       "       'Sorghum Sudangrass', 'Crownvetch', 'Canola/Soybeans',\n",
       "       'Dark Tobacco', 'Grain Crops (multiple)', 'Bluestem', 'Walnuts',\n",
       "       'Indiangrass', 'Warm Season Native Grass', 'Deciduous Trees',\n",
       "       'Conifers (not pines or junipers)', 'Conifers, pines', 'Pecans',\n",
       "       'Hollies', 'Orchardgrass/White Clover', 'Perrenials (not bulbs)',\n",
       "       'Bluegrass', 'Onions (green & bulb)', 'Canola', 'Rye/Soybeans',\n",
       "       'Buffer or Filter Strip', 'Triticale', 'Bulbs', 'Other Flowers',\n",
       "       'Other Nursery plants', 'Deciduous Shrubs',\n",
       "       'Evergreen Trees, Broadleaved', 'Oats/Soybeans',\n",
       "       'Currants and Gooseberries', 'Barley', 'Bluegrass/White Clover',\n",
       "       'Side-oats grama', 'Wheat/Corn', 'Rhododendrons', 'Plums',\n",
       "       'Cool Peas', 'Southern Peas', 'Barley/Soybeans', 'Unknown',\n",
       "       'Conifers, junipers', 'Triticale/Soybeans'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "croptypes = df.CROP.unique()\n",
    "croptypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select CROP based on AGR-1 crop types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list to select Corn from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Corn', 'Small Grains/Corn', 'Wheat/Corn']\n"
     ]
    }
   ],
   "source": [
    "corn_sel = ['Corn','Small Grains/Corn','Wheat/Corn']\n",
    "corn_sel.sort()\n",
    "print(corn_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe for nutrients phosphorus (P) and potassium (K)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    FIPS_NO COUNTY  YEAR     P      K\n",
      "155       1  ADAIR  1990  37.0  146.0\n",
      "156       1  ADAIR  1990  93.0  105.0\n",
      "157       1  ADAIR  1990  25.0  252.0\n",
      "158       1  ADAIR  1990  24.0  121.0\n",
      "159       1  ADAIR  1990  92.0  283.0\n"
     ]
    }
   ],
   "source": [
    "df_corn = df[df.CROP.isin(corn_sel)]\n",
    "df_corn_nu = df_corn[['FIPS_NO','COUNTY','YEAR','P','K']].copy()\n",
    "print(df_corn_nu.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate median for each County and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            K                                               ...      P         \\\n",
      "          len                                               ... median          \n",
      "YEAR     1990 1991 1992 1993 1994 1995 1996 1997 1998 1999  ...   2010   2011   \n",
      "COUNTY                                                      ...                 \n",
      "ADAIR      30   35   37   74   21   74   68   73   46   54  ...  108.0   62.0   \n",
      "ALLEN      23   41   26   49   12   20    6    7   13   24  ...   55.0   50.0   \n",
      "ANDERSON   15   30   10    6   10    8    8    5    1    8  ...  269.0  150.0   \n",
      "BALLARD    81   65   65   62   56   87   81   40  158  126  ...   56.0   54.0   \n",
      "BARREN    101  140  171  136  105  143   50   42   37   10  ...  104.0   62.0   \n",
      "...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
      "WAYNE     110   62   85  114   95  141  114  171  191  149  ...   64.0   87.0   \n",
      "WEBSTER   164  191  168   55   70   89   43   47  110  125  ...   58.0   42.0   \n",
      "WHITLEY    15   15   11   25   16   10   38   14   21    3  ...   45.0   41.0   \n",
      "WOLFE      20   15   16   10   15    6   15   11   10   13  ...   70.0  148.0   \n",
      "WOODFORD   31   32   31   49   73   96  107   76   63   77  ...  180.0  197.0   \n",
      "\n",
      "                                                                  \n",
      "                                                                  \n",
      "YEAR       2012   2013   2014   2015   2016   2017   2018   2019  \n",
      "COUNTY                                                            \n",
      "ADAIR      80.0   71.0   73.0   46.0   78.0   69.0   57.0   76.0  \n",
      "ALLEN      52.0   62.0  310.0   63.0   93.0   64.0   35.0   25.0  \n",
      "ANDERSON  149.0  212.0  232.0  346.0  228.0  393.0   31.0  226.0  \n",
      "BALLARD    53.0   48.0   52.0   54.0   46.0   55.0   40.0   49.0  \n",
      "BARREN     62.0   59.0   80.0   63.0   80.0   67.0   53.0   45.0  \n",
      "...         ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "WAYNE      73.0  138.0   68.0   80.0   77.0   79.0   68.0   80.0  \n",
      "WEBSTER    39.0   48.0   41.0   48.0   89.0   61.0   26.0   46.0  \n",
      "WHITLEY    62.0   42.0   30.0   41.0   36.0   34.0   25.0   22.0  \n",
      "WOLFE      57.0   16.0    0.0  178.0    0.0   63.0   88.0   30.0  \n",
      "WOODFORD  280.0  219.0  151.0  280.0  248.0  385.0  217.0  260.0  \n",
      "\n",
      "[120 rows x 120 columns]\n",
      "MultiIndex([('K',    'len', '1990'),\n",
      "            ('K',    'len', '1991'),\n",
      "            ('K',    'len', '1992'),\n",
      "            ('K',    'len', '1993'),\n",
      "            ('K',    'len', '1994'),\n",
      "            ('K',    'len', '1995'),\n",
      "            ('K',    'len', '1996'),\n",
      "            ('K',    'len', '1997'),\n",
      "            ('K',    'len', '1998'),\n",
      "            ('K',    'len', '1999'),\n",
      "            ...\n",
      "            ('P', 'median', '2010'),\n",
      "            ('P', 'median', '2011'),\n",
      "            ('P', 'median', '2012'),\n",
      "            ('P', 'median', '2013'),\n",
      "            ('P', 'median', '2014'),\n",
      "            ('P', 'median', '2015'),\n",
      "            ('P', 'median', '2016'),\n",
      "            ('P', 'median', '2017'),\n",
      "            ('P', 'median', '2018'),\n",
      "            ('P', 'median', '2019')],\n",
      "           names=[None, None, 'YEAR'], length=120)\n",
      "Index(['K_count_1990', 'K_count_1991', 'K_count_1992', 'K_count_1993',\n",
      "       'K_count_1994', 'K_count_1995', 'K_count_1996', 'K_count_1997',\n",
      "       'K_count_1998', 'K_count_1999',\n",
      "       ...\n",
      "       'P_med2010', 'P_med2011', 'P_med2012', 'P_med2013', 'P_med2014',\n",
      "       'P_med2015', 'P_med2016', 'P_med2017', 'P_med2018', 'P_med2019'],\n",
      "      dtype='object', length=120)\n",
      "       COUNTY  K_count_1990  K_count_1991  K_count_1992  K_count_1993  \\\n",
      "0       ADAIR            30            35            37            74   \n",
      "1       ALLEN            23            41            26            49   \n",
      "2    ANDERSON            15            30            10             6   \n",
      "3     BALLARD            81            65            65            62   \n",
      "4      BARREN           101           140           171           136   \n",
      "..        ...           ...           ...           ...           ...   \n",
      "115     WAYNE           110            62            85           114   \n",
      "116   WEBSTER           164           191           168            55   \n",
      "117   WHITLEY            15            15            11            25   \n",
      "118     WOLFE            20            15            16            10   \n",
      "119  WOODFORD            31            32            31            49   \n",
      "\n",
      "     K_count_1994  K_count_1995  K_count_1996  K_count_1997  K_count_1998  \\\n",
      "0              21            74            68            73            46   \n",
      "1              12            20             6             7            13   \n",
      "2              10             8             8             5             1   \n",
      "3              56            87            81            40           158   \n",
      "4             105           143            50            42            37   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "115            95           141           114           171           191   \n",
      "116            70            89            43            47           110   \n",
      "117            16            10            38            14            21   \n",
      "118            15             6            15            11            10   \n",
      "119            73            96           107            76            63   \n",
      "\n",
      "     ...  P_med2010  P_med2011  P_med2012  P_med2013  P_med2014  P_med2015  \\\n",
      "0    ...      108.0       62.0       80.0       71.0       73.0       46.0   \n",
      "1    ...       55.0       50.0       52.0       62.0      310.0       63.0   \n",
      "2    ...      269.0      150.0      149.0      212.0      232.0      346.0   \n",
      "3    ...       56.0       54.0       53.0       48.0       52.0       54.0   \n",
      "4    ...      104.0       62.0       62.0       59.0       80.0       63.0   \n",
      "..   ...        ...        ...        ...        ...        ...        ...   \n",
      "115  ...       64.0       87.0       73.0      138.0       68.0       80.0   \n",
      "116  ...       58.0       42.0       39.0       48.0       41.0       48.0   \n",
      "117  ...       45.0       41.0       62.0       42.0       30.0       41.0   \n",
      "118  ...       70.0      148.0       57.0       16.0        0.0      178.0   \n",
      "119  ...      180.0      197.0      280.0      219.0      151.0      280.0   \n",
      "\n",
      "     P_med2016  P_med2017  P_med2018  P_med2019  \n",
      "0         78.0       69.0       57.0       76.0  \n",
      "1         93.0       64.0       35.0       25.0  \n",
      "2        228.0      393.0       31.0      226.0  \n",
      "3         46.0       55.0       40.0       49.0  \n",
      "4         80.0       67.0       53.0       45.0  \n",
      "..         ...        ...        ...        ...  \n",
      "115       77.0       79.0       68.0       80.0  \n",
      "116       89.0       61.0       26.0       46.0  \n",
      "117       36.0       34.0       25.0       22.0  \n",
      "118        0.0       63.0       88.0       30.0  \n",
      "119      248.0      385.0      217.0      260.0  \n",
      "\n",
      "[120 rows x 121 columns]\n",
      "total number of records written to CSV: 120 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_corn_median = np.round( df_corn_nu.pivot_table(index='COUNTY', columns=['YEAR'], values=['P','K'],aggfunc=(np.median,len),fill_value=0),0)\n",
    "print(df_corn_median)\n",
    "print(df_corn_median.columns)\n",
    "df_corn_median.columns = list(map(\"_\".join,df_corn_median.columns))\n",
    "df_corn_median.columns = df_corn_median.columns.str.replace(\"P_median_\", \"P_med\")\n",
    "df_corn_median.columns = df_corn_median.columns.str.replace(\"P_len\", \"P_count\")\n",
    "df_corn_median.columns = df_corn_median.columns.str.replace(\"K_median_\",\"K_med\")\n",
    "df_corn_median.columns = df_corn_median.columns.str.replace(\"K_len\",\"K_count\")\n",
    "print(df_corn_median.columns)\n",
    "df_corn_median = df_corn_median.reset_index()\n",
    "print(df_corn_median)\n",
    "file_out_median = fileOut.joinpath('corn_median.csv')  # path and filename\n",
    "df_corn_median.to_csv(file_out_median, index=False)  # output to csv\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_corn_median)),'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corn,  Set categories for P and K values to very low, low, medium, high, very high. Base values from AGR-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories for P\n",
    "        Cat      Title       Break\n",
    "        -------------------------------------\n",
    "        VL       very low    P<= 5\n",
    "        L        low         P>5 & P<=27\n",
    "        M        medium      P>27 & P<=60\n",
    "        H        high        P>60\n",
    "\n",
    "#### Categories for K\n",
    "        Cat      Title      Break\n",
    "       --------------------------------------\n",
    "        VL       very low   K< 100\n",
    "        L        low        K>=100 & K <=190\n",
    "        M        medium     K>=191 & K <=300\n",
    "        H        high       K>=301 & K <=420\n",
    "        VH       very high  K>420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS_NO</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>CAT_P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>1990</td>\n",
       "      <td>37.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>1990</td>\n",
       "      <td>93.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>1990</td>\n",
       "      <td>25.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>1990</td>\n",
       "      <td>24.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>1990</td>\n",
       "      <td>92.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    FIPS_NO COUNTY  YEAR     P      K CAT_P\n",
       "155       1  ADAIR  1990  37.0  146.0     M\n",
       "156       1  ADAIR  1990  93.0  105.0     H\n",
       "157       1  ADAIR  1990  25.0  252.0     L\n",
       "158       1  ADAIR  1990  24.0  121.0     L\n",
       "159       1  ADAIR  1990  92.0  283.0     H"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corn_nu['CAT_P'] = ''\n",
    "df_corn_nu['CAT_P'] = np.where(df_corn_nu.P <= 5, 'VL', df_corn_nu.CAT_P)\n",
    "df_corn_nu['CAT_P'] = np.where(((df_corn_nu.P > 5) & (df_corn_nu.P <= 27)), 'L', df_corn_nu.CAT_P)\n",
    "df_corn_nu['CAT_P'] = np.where(((df_corn_nu.P > 27) & (df_corn_nu.P <= 60)), 'M', df_corn_nu.CAT_P)\n",
    "df_corn_nu['CAT_P'] = np.where((df_corn_nu.P > 60), 'H', df_corn_nu.CAT_P)\n",
    "df_corn_nu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS_NO</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>CAT_P</th>\n",
       "      <th>CAT_K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>1990</td>\n",
       "      <td>37.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>M</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>1990</td>\n",
       "      <td>93.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>H</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>1990</td>\n",
       "      <td>25.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>L</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>1990</td>\n",
       "      <td>24.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>L</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>1990</td>\n",
       "      <td>92.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    FIPS_NO COUNTY  YEAR     P      K CAT_P CAT_K\n",
       "155       1  ADAIR  1990  37.0  146.0     M     L\n",
       "156       1  ADAIR  1990  93.0  105.0     H     L\n",
       "157       1  ADAIR  1990  25.0  252.0     L     M\n",
       "158       1  ADAIR  1990  24.0  121.0     L     L\n",
       "159       1  ADAIR  1990  92.0  283.0     H     M"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corn_nu['CAT_K'] = ''\n",
    "df_corn_nu['CAT_K'] = np.where(df_corn_nu.K <= 100, 'VL', df_corn_nu.CAT_K)\n",
    "df_corn_nu['CAT_K'] = np.where(((df_corn_nu.K > 100) & (df_corn_nu.K <= 190)), 'L', df_corn_nu.CAT_K)\n",
    "df_corn_nu['CAT_K'] = np.where(((df_corn_nu.K > 190) & (df_corn_nu.K <= 300)), 'M', df_corn_nu.CAT_K)\n",
    "df_corn_nu['CAT_K'] = np.where(((df_corn_nu.K > 300) & (df_corn_nu.K <= 420)), 'H', df_corn_nu.CAT_K)\n",
    "df_corn_nu['CAT_K'] = np.where((df_corn_nu.K > 420), 'VH', df_corn_nu.CAT_K)\n",
    "df_corn_nu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create pivot table to sort categories by year and County for each nutrient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get median value of P and K nutrient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            P                                     ...                         \\\n",
      "          len                                     ... median                   \n",
      "YEAR     1990            1991           1992      ...   2017      2018         \n",
      "CAT_P       H   L   M VL    H  L   M VL    H   L  ...      M VL      H     L   \n",
      "COUNTY                                            ...                          \n",
      "ADAIR      15   4  11  0   24  7   4  0   18   4  ...   44.0  0  140.0  20.0   \n",
      "ALLEN       7  10   6  0   19  4  18  0    9   5  ...   36.0  0  116.0   0.0   \n",
      "ANDERSON   10   3   1  1   18  3   9  0    9   1  ...    0.0  0  147.0   8.0   \n",
      "BALLARD    69   0  12  0   33  4  28  0   51   2  ...   42.0  0   74.0   0.0   \n",
      "BARREN     66   9  26  0   86  9  45  0  114  12  ...   58.0  0  108.0  24.0   \n",
      "\n",
      "                                         \n",
      "                                         \n",
      "YEAR                2019                 \n",
      "CAT_P        M VL      H     L     M VL  \n",
      "COUNTY                                   \n",
      "ADAIR     42.0  0  104.0  24.0  43.0  2  \n",
      "ALLEN     34.0  0  312.0  16.0  38.0  0  \n",
      "ANDERSON  30.0  0  248.0   0.0  51.0  0  \n",
      "BALLARD   37.0  0   74.0  24.0  46.0  0  \n",
      "BARREN    45.0  0  133.0  20.0  45.0  2  \n",
      "\n",
      "[5 rows x 240 columns]\n",
      "            K                                     ...                       \\\n",
      "          len                                     ... median                 \n",
      "YEAR     1990                1991                 ...   2018                 \n",
      "CAT_K       H   L   M  VH VL    H   L   M  VH VL  ...      H      L      M   \n",
      "COUNTY                                            ...                        \n",
      "ADAIR       3  12  12   1  2    5  12  12   4  2  ...  346.0  156.0  237.0   \n",
      "ALLEN       2   6  13   1  1   11   7  18   5  0  ...    0.0    0.0  234.0   \n",
      "ANDERSON    4   5   3   2  1    9   6  11   4  0  ...    0.0  174.0  216.0   \n",
      "BALLARD    20  10  48   3  0   11  17  35   2  0  ...  309.0  168.0  222.0   \n",
      "BARREN     32  16  26  26  1   35  23  62  19  1  ...  339.0  184.0  243.0   \n",
      "\n",
      "                                                         \n",
      "                                                         \n",
      "YEAR                    2019                             \n",
      "CAT_K        VH    VL      H      L      M     VH    VL  \n",
      "COUNTY                                                   \n",
      "ADAIR     455.0  91.0  336.0  160.0  234.0    0.0  78.0  \n",
      "ALLEN       0.0  95.0    0.0  140.0  217.0    0.0  86.0  \n",
      "ANDERSON  502.0  96.0    0.0  181.0  209.0  543.0   0.0  \n",
      "BALLARD   509.0   0.0  387.0  164.0  211.0    0.0   0.0  \n",
      "BARREN    451.0   0.0  358.0  162.0  219.0  422.0  90.0  \n",
      "\n",
      "[5 rows x 300 columns]\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "df_corn_p = np.round( df_corn_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_P'], values=['P'],aggfunc=(np.median,len),fill_value=0),0)\n",
    "df_corn_k = np.round( df_corn_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_K'], values=['K'],aggfunc=(np.median,len),fill_value=0),0)\n",
    "print(df_corn_p.head())\n",
    "print(df_corn_k.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpivot table and save to CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create column names from pivot table data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex([('P',    'len', '1990',  'H'),\n",
      "            ('P',    'len', '1990',  'L'),\n",
      "            ('P',    'len', '1990',  'M'),\n",
      "            ('P',    'len', '1990', 'VL'),\n",
      "            ('P',    'len', '1991',  'H'),\n",
      "            ('P',    'len', '1991',  'L'),\n",
      "            ('P',    'len', '1991',  'M'),\n",
      "            ('P',    'len', '1991', 'VL'),\n",
      "            ('P',    'len', '1992',  'H'),\n",
      "            ('P',    'len', '1992',  'L'),\n",
      "            ...\n",
      "            ('P', 'median', '2017',  'M'),\n",
      "            ('P', 'median', '2017', 'VL'),\n",
      "            ('P', 'median', '2018',  'H'),\n",
      "            ('P', 'median', '2018',  'L'),\n",
      "            ('P', 'median', '2018',  'M'),\n",
      "            ('P', 'median', '2018', 'VL'),\n",
      "            ('P', 'median', '2019',  'H'),\n",
      "            ('P', 'median', '2019',  'L'),\n",
      "            ('P', 'median', '2019',  'M'),\n",
      "            ('P', 'median', '2019', 'VL')],\n",
      "           names=[None, None, 'YEAR', 'CAT_P'], length=240)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiIndex([('K',    'len', '1990',  'H'),\n",
       "            ('K',    'len', '1990',  'L'),\n",
       "            ('K',    'len', '1990',  'M'),\n",
       "            ('K',    'len', '1990', 'VH'),\n",
       "            ('K',    'len', '1990', 'VL'),\n",
       "            ('K',    'len', '1991',  'H'),\n",
       "            ('K',    'len', '1991',  'L'),\n",
       "            ('K',    'len', '1991',  'M'),\n",
       "            ('K',    'len', '1991', 'VH'),\n",
       "            ('K',    'len', '1991', 'VL'),\n",
       "            ...\n",
       "            ('K', 'median', '2018',  'H'),\n",
       "            ('K', 'median', '2018',  'L'),\n",
       "            ('K', 'median', '2018',  'M'),\n",
       "            ('K', 'median', '2018', 'VH'),\n",
       "            ('K', 'median', '2018', 'VL'),\n",
       "            ('K', 'median', '2019',  'H'),\n",
       "            ('K', 'median', '2019',  'L'),\n",
       "            ('K', 'median', '2019',  'M'),\n",
       "            ('K', 'median', '2019', 'VH'),\n",
       "            ('K', 'median', '2019', 'VL')],\n",
       "           names=[None, None, 'YEAR', 'CAT_K'], length=300)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_corn_p.columns)\n",
    "df_corn_k.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corn_p.columns = list(map(\"_\".join,df_corn_p.columns))\n",
    "df_corn_k.columns = list(map(\"_\".join,df_corn_k.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['P_len_1990_H', 'P_len_1990_L', 'P_len_1990_M', 'P_len_1990_VL',\n",
      "       'P_len_1991_H', 'P_len_1991_L', 'P_len_1991_M', 'P_len_1991_VL',\n",
      "       'P_len_1992_H', 'P_len_1992_L',\n",
      "       ...\n",
      "       'P_median_2017_M', 'P_median_2017_VL', 'P_median_2018_H',\n",
      "       'P_median_2018_L', 'P_median_2018_M', 'P_median_2018_VL',\n",
      "       'P_median_2019_H', 'P_median_2019_L', 'P_median_2019_M',\n",
      "       'P_median_2019_VL'],\n",
      "      dtype='object', length=240)\n",
      "Index(['K_len_1990_H', 'K_len_1990_L', 'K_len_1990_M', 'K_len_1990_VH',\n",
      "       'K_len_1990_VL', 'K_len_1991_H', 'K_len_1991_L', 'K_len_1991_M',\n",
      "       'K_len_1991_VH', 'K_len_1991_VL',\n",
      "       ...\n",
      "       'K_median_2018_H', 'K_median_2018_L', 'K_median_2018_M',\n",
      "       'K_median_2018_VH', 'K_median_2018_VL', 'K_median_2019_H',\n",
      "       'K_median_2019_L', 'K_median_2019_M', 'K_median_2019_VH',\n",
      "       'K_median_2019_VL'],\n",
      "      dtype='object', length=300)\n"
     ]
    }
   ],
   "source": [
    "print(df_corn_p.columns)\n",
    "print(df_corn_k.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['P_count_1990_H', 'P_count_1990_L', 'P_count_1990_M', 'P_count_1990_VL',\n",
      "       'P_count_1991_H', 'P_count_1991_L', 'P_count_1991_M', 'P_count_1991_VL',\n",
      "       'P_count_1992_H', 'P_count_1992_L',\n",
      "       ...\n",
      "       'P_2017_M', 'P_2017_VL', 'P_2018_H', 'P_2018_L', 'P_2018_M',\n",
      "       'P_2018_VL', 'P_2019_H', 'P_2019_L', 'P_2019_M', 'P_2019_VL'],\n",
      "      dtype='object', length=240)\n",
      "Index(['K_count_1990_H', 'K_count_1990_L', 'K_count_1990_M', 'K_count_1990_VH',\n",
      "       'K_count_1990_VL', 'K_count_1991_H', 'K_count_1991_L', 'K_count_1991_M',\n",
      "       'K_count_1991_VH', 'K_count_1991_VL',\n",
      "       ...\n",
      "       'K_2018_H', 'K_2018_L', 'K_2018_M', 'K_2018_VH', 'K_2018_VL',\n",
      "       'K_2019_H', 'K_2019_L', 'K_2019_M', 'K_2019_VH', 'K_2019_VL'],\n",
      "      dtype='object', length=300)\n"
     ]
    }
   ],
   "source": [
    "df_corn_p.columns = df_corn_p.columns.str.replace(\"P_median_\", \"P_\")\n",
    "df_corn_p.columns = df_corn_p.columns.str.replace(\"P_len\", \"P_count\")\n",
    "df_corn_k.columns = df_corn_k.columns.str.replace(\"K_median_\",\"K_\")\n",
    "df_corn_k.columns = df_corn_k.columns.str.replace(\"K_len\",\"K_count\")\n",
    "print(df_corn_p.columns)\n",
    "print(df_corn_k.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reindex unpivot table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     COUNTY  P_count_1990_H  P_count_1990_L  P_count_1990_M  P_count_1990_VL  \\\n",
      "0     ADAIR              15               4              11                0   \n",
      "1     ALLEN               7              10               6                0   \n",
      "2  ANDERSON              10               3               1                1   \n",
      "3   BALLARD              69               0              12                0   \n",
      "4    BARREN              66               9              26                0   \n",
      "\n",
      "   P_count_1991_H  P_count_1991_L  P_count_1991_M  P_count_1991_VL  \\\n",
      "0              24               7               4                0   \n",
      "1              19               4              18                0   \n",
      "2              18               3               9                0   \n",
      "3              33               4              28                0   \n",
      "4              86               9              45                0   \n",
      "\n",
      "   P_count_1992_H  ...  P_2017_M  P_2017_VL  P_2018_H  P_2018_L  P_2018_M  \\\n",
      "0              18  ...      44.0          0     140.0      20.0      42.0   \n",
      "1               9  ...      36.0          0     116.0       0.0      34.0   \n",
      "2               9  ...       0.0          0     147.0       8.0      30.0   \n",
      "3              51  ...      42.0          0      74.0       0.0      37.0   \n",
      "4             114  ...      58.0          0     108.0      24.0      45.0   \n",
      "\n",
      "   P_2018_VL  P_2019_H  P_2019_L  P_2019_M  P_2019_VL  \n",
      "0          0     104.0      24.0      43.0          2  \n",
      "1          0     312.0      16.0      38.0          0  \n",
      "2          0     248.0       0.0      51.0          0  \n",
      "3          0      74.0      24.0      46.0          0  \n",
      "4          0     133.0      20.0      45.0          2  \n",
      "\n",
      "[5 rows x 241 columns]\n",
      "     COUNTY  K_count_1990_H  K_count_1990_L  K_count_1990_M  K_count_1990_VH  \\\n",
      "0     ADAIR               3              12              12                1   \n",
      "1     ALLEN               2               6              13                1   \n",
      "2  ANDERSON               4               5               3                2   \n",
      "3   BALLARD              20              10              48                3   \n",
      "4    BARREN              32              16              26               26   \n",
      "\n",
      "   K_count_1990_VL  K_count_1991_H  K_count_1991_L  K_count_1991_M  \\\n",
      "0                2               5              12              12   \n",
      "1                1              11               7              18   \n",
      "2                1               9               6              11   \n",
      "3                0              11              17              35   \n",
      "4                1              35              23              62   \n",
      "\n",
      "   K_count_1991_VH  ...  K_2018_H  K_2018_L  K_2018_M  K_2018_VH  K_2018_VL  \\\n",
      "0                4  ...     346.0     156.0     237.0      455.0       91.0   \n",
      "1                5  ...       0.0       0.0     234.0        0.0       95.0   \n",
      "2                4  ...       0.0     174.0     216.0      502.0       96.0   \n",
      "3                2  ...     309.0     168.0     222.0      509.0        0.0   \n",
      "4               19  ...     339.0     184.0     243.0      451.0        0.0   \n",
      "\n",
      "   K_2019_H  K_2019_L  K_2019_M  K_2019_VH  K_2019_VL  \n",
      "0     336.0     160.0     234.0        0.0       78.0  \n",
      "1       0.0     140.0     217.0        0.0       86.0  \n",
      "2       0.0     181.0     209.0      543.0        0.0  \n",
      "3     387.0     164.0     211.0        0.0        0.0  \n",
      "4     358.0     162.0     219.0      422.0       90.0  \n",
      "\n",
      "[5 rows x 301 columns]\n"
     ]
    }
   ],
   "source": [
    "df_corn_p = df_corn_p.reset_index()\n",
    "df_corn_k = df_corn_k.reset_index()\n",
    "print(df_corn_p.head())\n",
    "print(df_corn_k.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge dataframes into one file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       COUNTY  P_count_1990_H  P_count_1990_L  P_count_1990_M  \\\n",
      "0       ADAIR              15               4              11   \n",
      "1       ALLEN               7              10               6   \n",
      "2    ANDERSON              10               3               1   \n",
      "3     BALLARD              69               0              12   \n",
      "4      BARREN              66               9              26   \n",
      "..        ...             ...             ...             ...   \n",
      "115     WAYNE              69              10              31   \n",
      "116   WEBSTER              54              41              69   \n",
      "117   WHITLEY               4               4               7   \n",
      "118     WOLFE              13               1               6   \n",
      "119  WOODFORD              25               3               3   \n",
      "\n",
      "     P_count_1990_VL  P_count_1991_H  P_count_1991_L  P_count_1991_M  \\\n",
      "0                  0              24               7               4   \n",
      "1                  0              19               4              18   \n",
      "2                  1              18               3               9   \n",
      "3                  0              33               4              28   \n",
      "4                  0              86               9              45   \n",
      "..               ...             ...             ...             ...   \n",
      "115                0              34               8              20   \n",
      "116                0              72              34              81   \n",
      "117                0               1              10               3   \n",
      "118                0              11               1               3   \n",
      "119                0              23               1               8   \n",
      "\n",
      "     P_count_1991_VL  P_count_1992_H  ...  K_2018_H  K_2018_L  K_2018_M  \\\n",
      "0                  0              18  ...     346.0     156.0     237.0   \n",
      "1                  0               9  ...       0.0       0.0     234.0   \n",
      "2                  0               9  ...       0.0     174.0     216.0   \n",
      "3                  0              51  ...     309.0     168.0     222.0   \n",
      "4                  0             114  ...     339.0     184.0     243.0   \n",
      "..               ...             ...  ...       ...       ...       ...   \n",
      "115                0              40  ...     336.0     158.0     238.0   \n",
      "116                4              84  ...       0.0     150.0     201.0   \n",
      "117                1               2  ...       0.0     160.0     236.0   \n",
      "118                0              11  ...       0.0     120.0     196.0   \n",
      "119                0              28  ...     356.0     162.0     238.0   \n",
      "\n",
      "     K_2018_VH  K_2018_VL  K_2019_H  K_2019_L  K_2019_M  K_2019_VH  K_2019_VL  \n",
      "0        455.0       91.0     336.0     160.0     234.0        0.0       78.0  \n",
      "1          0.0       95.0       0.0     140.0     217.0        0.0       86.0  \n",
      "2        502.0       96.0       0.0     181.0     209.0      543.0        0.0  \n",
      "3        509.0        0.0     387.0     164.0     211.0        0.0        0.0  \n",
      "4        451.0        0.0     358.0     162.0     219.0      422.0       90.0  \n",
      "..         ...        ...       ...       ...       ...        ...        ...  \n",
      "115      590.0        0.0     346.0     165.0     226.0      486.0        0.0  \n",
      "116        0.0        0.0     326.0     168.0     236.0      480.0        0.0  \n",
      "117        0.0        0.0       0.0     117.0       0.0        0.0       82.0  \n",
      "118        0.0       86.0       0.0       0.0       0.0        0.0       75.0  \n",
      "119      504.0       90.0     329.0     158.0     229.0      582.0       89.0  \n",
      "\n",
      "[120 rows x 541 columns]\n"
     ]
    }
   ],
   "source": [
    "corn_level = df_corn_p.merge(df_corn_k, left_on='COUNTY', right_on='COUNTY')\n",
    "print(corn_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save categorized data to file. Separate by crop and nutrient type (P and K) with count by category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records written to CSV: 120 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_out_level = fileOut.joinpath('corn_levels.csv')\n",
    "corn_level.to_csv(file_out_level, index=False)\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(corn_level)),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soybeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list to select Soybeans from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barley/Soybeans', 'Canola/Soybeans', 'Oats/Soybeans', 'Rye/Soybeans', 'Small Grains/Soybeans', 'Soybeans', 'Triticale/Soybeans', 'Wheat/Soybeans']\n"
     ]
    }
   ],
   "source": [
    "soy_sel = ['Soybeans', 'Small Grains/Soybeans', 'Wheat/Soybeans', 'Canola/Soybeans', 'Rye/Soybeans', 'Oats/Soybeans', 'Barley/Soybeans', 'Triticale/Soybeans']\n",
    "soy_sel.sort()\n",
    "print(soy_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select soybeans from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     FIPS_NO COUNTY  YEAR      P      K\n",
      "628        1  ADAIR  1991  238.0  318.0\n",
      "1879       1  ADAIR  1995   83.0  173.0\n",
      "1880       1  ADAIR  1995   59.0  150.0\n",
      "1881       1  ADAIR  1995   65.0  152.0\n",
      "1882       1  ADAIR  1995  148.0  317.0\n"
     ]
    }
   ],
   "source": [
    "df_soy = df[df.CROP.isin(soy_sel)]\n",
    "df_soy_nu = df_soy[['FIPS_NO','COUNTY','YEAR','P','K']].copy()\n",
    "print(df_soy_nu.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate median for each year by County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            K                                               ...      P         \\\n",
      "          len                                               ... median          \n",
      "YEAR     1990 1991 1992 1993 1994 1995 1996 1997 1998 1999  ...   2010   2011   \n",
      "COUNTY                                                      ...                 \n",
      "ADAIR       0    1    0    0    0    4    0    2    5    0  ...   86.0   88.0   \n",
      "ALLEN       5    3    3   15    0   21   11    2    5    2  ...  127.0   43.0   \n",
      "ANDERSON    0   12    1    1    1    0    0    0    0    2  ...  290.0  367.0   \n",
      "BALLARD    58   36   11   58   30   54   59   89  111  124  ...   50.0   62.0   \n",
      "BARREN     16   26   30   14   22   19   15   13    5    0  ...  234.0   85.0   \n",
      "...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
      "WAYNE      69   39   50   60   44  105   35   62   77   59  ...   80.0   95.0   \n",
      "WEBSTER    40  102   58   41   63  106   30   44   64  102  ...   69.0   36.0   \n",
      "WHITLEY     1    2    4    1    1    1    1    0    0    0  ...   95.0    0.0   \n",
      "WOLFE       1    0    0    0    0    0    0    0    0    0  ...    0.0    0.0   \n",
      "WOODFORD    5   12    2    4   24   32   53   36   29   37  ...  334.0  188.0   \n",
      "\n",
      "                                                                  \n",
      "                                                                  \n",
      "YEAR       2012   2013   2014   2015   2016   2017   2018   2019  \n",
      "COUNTY                                                            \n",
      "ADAIR      72.0   88.0   66.0   78.0   60.0   73.0   65.0   69.0  \n",
      "ALLEN       0.0    0.0    0.0   62.0   57.0   46.0   40.0  652.0  \n",
      "ANDERSON  360.0  242.0  274.0  198.0  361.0  297.0   53.0  162.0  \n",
      "BALLARD    54.0   62.0   52.0   54.0   62.0   42.0   45.0   44.0  \n",
      "BARREN     62.0   72.0   58.0   66.0   60.0   47.0   47.0  236.0  \n",
      "...         ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "WAYNE      69.0   81.0   74.0   72.0   72.0   56.0   56.0   72.0  \n",
      "WEBSTER    62.0   41.0   67.0   48.0   55.0   72.0   62.0   60.0  \n",
      "WHITLEY    56.0   42.0   18.0   38.0   46.0   10.0    0.0    0.0  \n",
      "WOLFE       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
      "WOODFORD  273.0  346.0  250.0  236.0  301.0  239.0  324.0  261.0  \n",
      "\n",
      "[117 rows x 120 columns]\n",
      "MultiIndex([('K',    'len', '1990'),\n",
      "            ('K',    'len', '1991'),\n",
      "            ('K',    'len', '1992'),\n",
      "            ('K',    'len', '1993'),\n",
      "            ('K',    'len', '1994'),\n",
      "            ('K',    'len', '1995'),\n",
      "            ('K',    'len', '1996'),\n",
      "            ('K',    'len', '1997'),\n",
      "            ('K',    'len', '1998'),\n",
      "            ('K',    'len', '1999'),\n",
      "            ...\n",
      "            ('P', 'median', '2010'),\n",
      "            ('P', 'median', '2011'),\n",
      "            ('P', 'median', '2012'),\n",
      "            ('P', 'median', '2013'),\n",
      "            ('P', 'median', '2014'),\n",
      "            ('P', 'median', '2015'),\n",
      "            ('P', 'median', '2016'),\n",
      "            ('P', 'median', '2017'),\n",
      "            ('P', 'median', '2018'),\n",
      "            ('P', 'median', '2019')],\n",
      "           names=[None, None, 'YEAR'], length=120)\n",
      "Index(['K_count_1990', 'K_count_1991', 'K_count_1992', 'K_count_1993',\n",
      "       'K_count_1994', 'K_count_1995', 'K_count_1996', 'K_count_1997',\n",
      "       'K_count_1998', 'K_count_1999',\n",
      "       ...\n",
      "       'P_med2010', 'P_med2011', 'P_med2012', 'P_med2013', 'P_med2014',\n",
      "       'P_med2015', 'P_med2016', 'P_med2017', 'P_med2018', 'P_med2019'],\n",
      "      dtype='object', length=120)\n",
      "       COUNTY  K_count_1990  K_count_1991  K_count_1992  K_count_1993  \\\n",
      "0       ADAIR             0             1             0             0   \n",
      "1       ALLEN             5             3             3            15   \n",
      "2    ANDERSON             0            12             1             1   \n",
      "3     BALLARD            58            36            11            58   \n",
      "4      BARREN            16            26            30            14   \n",
      "..        ...           ...           ...           ...           ...   \n",
      "112     WAYNE            69            39            50            60   \n",
      "113   WEBSTER            40           102            58            41   \n",
      "114   WHITLEY             1             2             4             1   \n",
      "115     WOLFE             1             0             0             0   \n",
      "116  WOODFORD             5            12             2             4   \n",
      "\n",
      "     K_count_1994  K_count_1995  K_count_1996  K_count_1997  K_count_1998  \\\n",
      "0               0             4             0             2             5   \n",
      "1               0            21            11             2             5   \n",
      "2               1             0             0             0             0   \n",
      "3              30            54            59            89           111   \n",
      "4              22            19            15            13             5   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "112            44           105            35            62            77   \n",
      "113            63           106            30            44            64   \n",
      "114             1             1             1             0             0   \n",
      "115             0             0             0             0             0   \n",
      "116            24            32            53            36            29   \n",
      "\n",
      "     ...  P_med2010  P_med2011  P_med2012  P_med2013  P_med2014  P_med2015  \\\n",
      "0    ...       86.0       88.0       72.0       88.0       66.0       78.0   \n",
      "1    ...      127.0       43.0        0.0        0.0        0.0       62.0   \n",
      "2    ...      290.0      367.0      360.0      242.0      274.0      198.0   \n",
      "3    ...       50.0       62.0       54.0       62.0       52.0       54.0   \n",
      "4    ...      234.0       85.0       62.0       72.0       58.0       66.0   \n",
      "..   ...        ...        ...        ...        ...        ...        ...   \n",
      "112  ...       80.0       95.0       69.0       81.0       74.0       72.0   \n",
      "113  ...       69.0       36.0       62.0       41.0       67.0       48.0   \n",
      "114  ...       95.0        0.0       56.0       42.0       18.0       38.0   \n",
      "115  ...        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "116  ...      334.0      188.0      273.0      346.0      250.0      236.0   \n",
      "\n",
      "     P_med2016  P_med2017  P_med2018  P_med2019  \n",
      "0         60.0       73.0       65.0       69.0  \n",
      "1         57.0       46.0       40.0      652.0  \n",
      "2        361.0      297.0       53.0      162.0  \n",
      "3         62.0       42.0       45.0       44.0  \n",
      "4         60.0       47.0       47.0      236.0  \n",
      "..         ...        ...        ...        ...  \n",
      "112       72.0       56.0       56.0       72.0  \n",
      "113       55.0       72.0       62.0       60.0  \n",
      "114       46.0       10.0        0.0        0.0  \n",
      "115        0.0        0.0        0.0        0.0  \n",
      "116      301.0      239.0      324.0      261.0  \n",
      "\n",
      "[117 rows x 121 columns]\n",
      "total number of records written to CSV: 117 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_soy_median = np.round( df_soy_nu.pivot_table(index='COUNTY', columns=['YEAR'], values=['P','K'],aggfunc=(np.median,len),fill_value=0),0)\n",
    "print(df_soy_median)\n",
    "print(df_soy_median.columns)\n",
    "df_soy_median.columns = list(map(\"_\".join,df_soy_median.columns))\n",
    "df_soy_median.columns = df_soy_median.columns.str.replace(\"P_median_\", \"P_med\")\n",
    "df_soy_median.columns = df_soy_median.columns.str.replace(\"P_len\", \"P_count\")\n",
    "df_soy_median.columns = df_soy_median.columns.str.replace(\"K_median_\",\"K_med\")\n",
    "df_soy_median.columns = df_soy_median.columns.str.replace(\"K_len\",\"K_count\")\n",
    "print(df_soy_median.columns)\n",
    "df_soy_median = df_soy_median.reset_index()\n",
    "print(df_soy_median)\n",
    "file_out_median = fileOut.joinpath('soy_median.csv')  # path and filename\n",
    "df_soy_median.to_csv(file_out_median, index=False)  # output to csv\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_soy_median)),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soybeans, Set categories for P and K values to very low, low, medium, high, very high. Base values from AGR-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories for P\n",
    "        Cat      Title       Break\n",
    "        -------------------------------------\n",
    "        VL       very low    P<= 5\n",
    "        L        low         P>5 & P<=27\n",
    "        M        medium      P>27 & P<=60\n",
    "        H        high        P>60\n",
    "\n",
    "#### Categories for K\n",
    "        Cat      Title      Break\n",
    "       --------------------------------------\n",
    "        VL       very low   K< 100\n",
    "        L        low        K>=100 & K <=190\n",
    "        M        medium     K>=191 & K <=300\n",
    "        H        high       K>300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soy_nu['CAT_P'] = ''\n",
    "df_soy_nu['CAT_P'] = np.where(df_soy_nu.P <= 5, 'VL', df_soy_nu.CAT_P)\n",
    "df_soy_nu['CAT_P'] = np.where(((df_soy_nu.P > 5) & (df_soy_nu.P <= 27)), 'L', df_soy_nu.CAT_P)\n",
    "df_soy_nu['CAT_P'] = np.where(((df_soy_nu.P > 27) & (df_soy_nu.P <= 60)), 'M', df_soy_nu.CAT_P)\n",
    "df_soy_nu['CAT_P'] = np.where((df_soy_nu.P > 60), 'H', df_soy_nu.CAT_P)\n",
    "\n",
    "df_soy_nu['CAT_K'] = ''\n",
    "df_soy_nu['CAT_K'] = np.where(df_soy_nu.K <= 99, 'VL', df_soy_nu.CAT_K)\n",
    "df_soy_nu['CAT_K'] = np.where(((df_soy_nu.K > 99) & (df_soy_nu.K <= 190)), 'L', df_soy_nu.CAT_K)\n",
    "df_soy_nu['CAT_K'] = np.where(((df_soy_nu.K > 190) & (df_soy_nu.K <= 300)), 'M', df_soy_nu.CAT_K)\n",
    "df_soy_nu['CAT_K'] = np.where((df_soy_nu.K > 300), 'H', df_soy_nu.CAT_K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "df_soy_p = np.round( df_soy_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_P'], values=['P'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "df_soy_k = np.round( df_soy_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_K'], values=['K'],aggfunc=(np.median,len),fill_value=0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records written to CSV: 117 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_soy_p.columns\n",
    "df_soy_k.columns\n",
    "df_soy_p.columns = list(map(\"_\".join,df_soy_p.columns))\n",
    "df_soy_k.columns = list(map(\"_\".join,df_soy_k.columns))\n",
    "df_soy_p.columns = df_soy_p.columns.str.replace(\"P_median_\", \"P_\")\n",
    "df_soy_p.columns = df_soy_p.columns.str.replace(\"P_len\", \"P_count\")\n",
    "df_soy_k.columns = df_soy_k.columns.str.replace(\"K_median_\",\"K_\")\n",
    "df_soy_k.columns = df_soy_k.columns.str.replace(\"K_len\",\"K_count\")\n",
    "df_soy_p = df_soy_p.reset_index()\n",
    "df_soy_k = df_soy_k.reset_index()\n",
    "\n",
    "soy_level = df_soy_p.merge(df_soy_k, left_on='COUNTY', right_on='COUNTY')\n",
    "\n",
    "file_out_level = fileOut.joinpath('soy_levels.csv')\n",
    "soy_level.to_csv(file_out_level, index=False)\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(soy_level)),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canola"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list to select Canola from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Canola', 'Canola/Soybeans']\n"
     ]
    }
   ],
   "source": [
    "canola_sel = ['Canola', 'Canola/Soybeans']\n",
    "canola_sel.sort()\n",
    "print(canola_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Canola from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      FIPS_NO     COUNTY  YEAR     P      K\n",
      "14175     101  HENDERSON  1991  29.0  200.0\n",
      "14176     101  HENDERSON  1991  36.0  163.0\n",
      "14177     101  HENDERSON  1991  43.0  250.0\n",
      "14178     101  HENDERSON  1991  25.0  163.0\n",
      "14179     101  HENDERSON  1991  36.0  158.0\n"
     ]
    }
   ],
   "source": [
    "df_canola = df[df.CROP.isin(canola_sel)]\n",
    "df_canola_nu = df_canola[['FIPS_NO','COUNTY','YEAR','P','K']].copy()\n",
    "print(df_canola_nu.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate median for each year by County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              K                                               ...      P       \\\n",
      "            len                                               ... median        \n",
      "YEAR       1990 1991 1992 1993 1994 1995 1996 1997 1998 1999  ...   2010 2011   \n",
      "COUNTY                                                        ...               \n",
      "ALLEN         0    0    0    0    0    0    0    0    0    0  ...      0  0.0   \n",
      "BARREN        0    2    0    0    0    0    0    0    0    0  ...      0  0.0   \n",
      "BOONE         0    0    0    0    2    0    0    0    0    0  ...      0  0.0   \n",
      "BOURBON       1    0    0    0    0    0    0    0    0    0  ...      0  0.0   \n",
      "BOYLE         0    0    0    0    0    0    0    0    1    0  ...      0  0.0   \n",
      "...         ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...  ...   \n",
      "WARREN        0    1    0    0    1    0    0    0    0    0  ...      0  0.0   \n",
      "WASHINGTON    0    0    0    0    0    0    0    0    1    0  ...      0  0.0   \n",
      "WAYNE         0    0    0    0    0    0    0    0    0    0  ...      0  0.0   \n",
      "WEBSTER       0    0    0    0    0    0    0    3    2    0  ...      0  0.0   \n",
      "WOODFORD      0    0    2    0    1    0    2    0    0    0  ...      0  0.0   \n",
      "\n",
      "                                                    \n",
      "                                                    \n",
      "YEAR       2012 2013 2014 2015 2016 2017 2018 2019  \n",
      "COUNTY                                              \n",
      "ALLEN         0  0.0  0.0   28  0.0    0    0    0  \n",
      "BARREN        0  0.0  0.0    0  0.0    0    0    0  \n",
      "BOONE         0  0.0  0.0    0  0.0    0   24    0  \n",
      "BOURBON       0  0.0  0.0    0  0.0    0    0    0  \n",
      "BOYLE         0  0.0  0.0    0  0.0    0    0    0  \n",
      "...         ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "WARREN        0  0.0  0.0    0  0.0   48    0    0  \n",
      "WASHINGTON    0  0.0  0.0    0  0.0    0    0    0  \n",
      "WAYNE         0  0.0  0.0    0  0.0    0    0    0  \n",
      "WEBSTER       0  0.0  0.0    0  0.0    0    0    0  \n",
      "WOODFORD      0  0.0  0.0    0  0.0    0    0    0  \n",
      "\n",
      "[65 rows x 120 columns]\n",
      "MultiIndex([('K',    'len', '1990'),\n",
      "            ('K',    'len', '1991'),\n",
      "            ('K',    'len', '1992'),\n",
      "            ('K',    'len', '1993'),\n",
      "            ('K',    'len', '1994'),\n",
      "            ('K',    'len', '1995'),\n",
      "            ('K',    'len', '1996'),\n",
      "            ('K',    'len', '1997'),\n",
      "            ('K',    'len', '1998'),\n",
      "            ('K',    'len', '1999'),\n",
      "            ...\n",
      "            ('P', 'median', '2010'),\n",
      "            ('P', 'median', '2011'),\n",
      "            ('P', 'median', '2012'),\n",
      "            ('P', 'median', '2013'),\n",
      "            ('P', 'median', '2014'),\n",
      "            ('P', 'median', '2015'),\n",
      "            ('P', 'median', '2016'),\n",
      "            ('P', 'median', '2017'),\n",
      "            ('P', 'median', '2018'),\n",
      "            ('P', 'median', '2019')],\n",
      "           names=[None, None, 'YEAR'], length=120)\n",
      "Index(['K_count_1990', 'K_count_1991', 'K_count_1992', 'K_count_1993',\n",
      "       'K_count_1994', 'K_count_1995', 'K_count_1996', 'K_count_1997',\n",
      "       'K_count_1998', 'K_count_1999',\n",
      "       ...\n",
      "       'P_med2010', 'P_med2011', 'P_med2012', 'P_med2013', 'P_med2014',\n",
      "       'P_med2015', 'P_med2016', 'P_med2017', 'P_med2018', 'P_med2019'],\n",
      "      dtype='object', length=120)\n",
      "        COUNTY  K_count_1990  K_count_1991  K_count_1992  K_count_1993  \\\n",
      "0        ALLEN             0             0             0             0   \n",
      "1       BARREN             0             2             0             0   \n",
      "2        BOONE             0             0             0             0   \n",
      "3      BOURBON             1             0             0             0   \n",
      "4        BOYLE             0             0             0             0   \n",
      "..         ...           ...           ...           ...           ...   \n",
      "60      WARREN             0             1             0             0   \n",
      "61  WASHINGTON             0             0             0             0   \n",
      "62       WAYNE             0             0             0             0   \n",
      "63     WEBSTER             0             0             0             0   \n",
      "64    WOODFORD             0             0             2             0   \n",
      "\n",
      "    K_count_1994  K_count_1995  K_count_1996  K_count_1997  K_count_1998  ...  \\\n",
      "0              0             0             0             0             0  ...   \n",
      "1              0             0             0             0             0  ...   \n",
      "2              2             0             0             0             0  ...   \n",
      "3              0             0             0             0             0  ...   \n",
      "4              0             0             0             0             1  ...   \n",
      "..           ...           ...           ...           ...           ...  ...   \n",
      "60             1             0             0             0             0  ...   \n",
      "61             0             0             0             0             1  ...   \n",
      "62             0             0             0             0             0  ...   \n",
      "63             0             0             0             3             2  ...   \n",
      "64             1             0             2             0             0  ...   \n",
      "\n",
      "    P_med2010  P_med2011  P_med2012  P_med2013  P_med2014  P_med2015  \\\n",
      "0           0        0.0          0        0.0        0.0         28   \n",
      "1           0        0.0          0        0.0        0.0          0   \n",
      "2           0        0.0          0        0.0        0.0          0   \n",
      "3           0        0.0          0        0.0        0.0          0   \n",
      "4           0        0.0          0        0.0        0.0          0   \n",
      "..        ...        ...        ...        ...        ...        ...   \n",
      "60          0        0.0          0        0.0        0.0          0   \n",
      "61          0        0.0          0        0.0        0.0          0   \n",
      "62          0        0.0          0        0.0        0.0          0   \n",
      "63          0        0.0          0        0.0        0.0          0   \n",
      "64          0        0.0          0        0.0        0.0          0   \n",
      "\n",
      "    P_med2016  P_med2017  P_med2018  P_med2019  \n",
      "0         0.0          0          0          0  \n",
      "1         0.0          0          0          0  \n",
      "2         0.0          0         24          0  \n",
      "3         0.0          0          0          0  \n",
      "4         0.0          0          0          0  \n",
      "..        ...        ...        ...        ...  \n",
      "60        0.0         48          0          0  \n",
      "61        0.0          0          0          0  \n",
      "62        0.0          0          0          0  \n",
      "63        0.0          0          0          0  \n",
      "64        0.0          0          0          0  \n",
      "\n",
      "[65 rows x 121 columns]\n",
      "total number of records written to CSV: 65 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_canola_median = np.round( df_canola_nu.pivot_table(index='COUNTY', columns=['YEAR'], values=['P','K'],aggfunc=(np.median,len),fill_value=0),0)\n",
    "print(df_canola_median)\n",
    "print(df_canola_median.columns)\n",
    "df_canola_median.columns = list(map(\"_\".join,df_canola_median.columns))\n",
    "df_canola_median.columns = df_canola_median.columns.str.replace(\"P_median_\", \"P_med\")\n",
    "df_canola_median.columns = df_canola_median.columns.str.replace(\"P_len\", \"P_count\")\n",
    "df_canola_median.columns = df_canola_median.columns.str.replace(\"K_median_\",\"K_med\")\n",
    "df_canola_median.columns = df_canola_median.columns.str.replace(\"K_len\",\"K_count\")\n",
    "print(df_canola_median.columns)\n",
    "df_canola_median = df_canola_median.reset_index()\n",
    "print(df_canola_median)\n",
    "file_out_median = fileOut.joinpath('canola_median.csv')  # path and filename\n",
    "df_canola_median.to_csv(file_out_median, index=False)  # output to csv\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_canola_median)),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Canola, Set categories for P and K values to very low, low, medium, high, very high. Base values from AGR-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories for P\n",
    "    Cat      Title       Break\n",
    "    -------------------------------------\n",
    "    VL       very low    P< 10\n",
    "    L        low         P>= 10 & P<=30\n",
    "    M        medium      P>30 & P<=60\n",
    "    H        high        P>60\n",
    "    \n",
    "#### Categories for K\n",
    "    Cat      Title      Break\n",
    "   --------------------------------------\n",
    "    VL       very low   K< 104\n",
    "    L        low        K>=104 & K <=186\n",
    "    M        medium     K>=187 & K <=300\n",
    "    H        high       K>300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_canola_nu['CAT_P'] = ''\n",
    "df_canola_nu['CAT_P'] = np.where(df_canola_nu.P < 10, 'VL', df_canola_nu.CAT_P)\n",
    "df_canola_nu['CAT_P'] = np.where(((df_canola_nu.P > 10) & (df_canola_nu.P <= 30)), 'L', df_canola_nu.CAT_P)\n",
    "df_canola_nu['CAT_P'] = np.where(((df_canola_nu.P > 30) & (df_canola_nu.P <= 60)), 'M', df_canola_nu.CAT_P)\n",
    "df_canola_nu['CAT_P'] = np.where((df_canola_nu.P > 60), 'H', df_canola_nu.CAT_P)\n",
    "\n",
    "df_canola_nu['CAT_K'] = ''\n",
    "df_canola_nu['CAT_K'] = np.where(df_canola_nu.K < 104, 'VL', df_canola_nu.CAT_K)\n",
    "df_canola_nu['CAT_K'] = np.where(((df_canola_nu.K > 104) & (df_canola_nu.K <= 186)), 'L', df_canola_nu.CAT_K)\n",
    "df_canola_nu['CAT_K'] = np.where(((df_canola_nu.K > 186) & (df_canola_nu.K <= 300)), 'M', df_canola_nu.CAT_K)\n",
    "df_canola_nu['CAT_K'] = np.where((df_canola_nu.K > 300), 'H', df_canola_nu.CAT_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "df_canola_p = np.round( df_canola_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_P'], values=['P'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "df_canola_k = np.round( df_canola_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_K'], values=['K'],aggfunc=(np.median,len),fill_value=0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records written to CSV: 65 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_canola_p.columns\n",
    "df_canola_k.columns\n",
    "df_canola_p.columns = list(map(\"_\".join,df_canola_p.columns))\n",
    "df_canola_k.columns = list(map(\"_\".join,df_canola_k.columns))\n",
    "df_canola_p.columns = df_canola_p.columns.str.replace(\"P_median_\", \"P_\")\n",
    "df_canola_p.columns = df_canola_p.columns.str.replace(\"P_len\", \"P_count\")\n",
    "df_canola_k.columns = df_canola_k.columns.str.replace(\"K_median_\",\"K_\")\n",
    "df_canola_k.columns = df_canola_k.columns.str.replace(\"K_len\",\"K_count\")\n",
    "df_canola_p = df_canola_p.reset_index()\n",
    "df_canola_k = df_canola_k.reset_index()\n",
    "\n",
    "\n",
    "canola_level = df_canola_p.merge(df_canola_k, left_on='COUNTY', right_on='COUNTY')\n",
    "\n",
    "file_out_level = fileOut.joinpath('canola_levels.csv')\n",
    "canola_level.to_csv(file_out_level, index=False)\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(canola_level)),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorghum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list to select Sorghum from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Grain Sorghum']\n"
     ]
    }
   ],
   "source": [
    "sorghum_sel = ['Grain Sorghum']\n",
    "sorghum_sel.sort()\n",
    "print(sorghum_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Sorghum from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      FIPS_NO     COUNTY  YEAR      P       K\n",
      "2237        1      ADAIR  1996   67.0   284.0\n",
      "2532        1      ADAIR  1997  318.0   303.0\n",
      "18439     101  HENDERSON  2007   42.0  1281.0\n",
      "18440     101  HENDERSON  2007  120.0  1499.0\n",
      "19885     101  HENDERSON  2014   48.0   110.0\n"
     ]
    }
   ],
   "source": [
    "df_sorghum = df[df.CROP.isin(sorghum_sel)]\n",
    "df_sorghum_nu = df_sorghum[['FIPS_NO','COUNTY','YEAR','P','K']].copy()\n",
    "print(df_sorghum_nu.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate median for each year by County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              K                                               ...      P  \\\n",
      "            len                                               ... median   \n",
      "YEAR       1990 1991 1992 1993 1994 1995 1996 1997 1998 1999  ...   2010   \n",
      "COUNTY                                                        ...          \n",
      "ADAIR         0    0    0    0    0    0    1    1    0    0  ...    0.0   \n",
      "ALLEN         0    0    0    0    0    0    0    0    0    0  ...    0.0   \n",
      "BALLARD      11    0    5    3    6    7    1    5    8    0  ...    0.0   \n",
      "BATH          0    0    0    0    0    0    0    0    0    0  ...   15.0   \n",
      "BELL          0    0    0    0    0    0    1    0    0    0  ...    0.0   \n",
      "...         ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...   \n",
      "TRIGG         0    0    1    0    0    0    0    0    0    2  ...  141.0   \n",
      "UNION         0    1    0    0    0    0    0    0    0    0  ...    0.0   \n",
      "WASHINGTON    0    0    5    0    1    2    0    0    0    0  ...    0.0   \n",
      "WEBSTER       2    0    0    0    0    0    0    0    0    3  ...    0.0   \n",
      "WHITLEY       0    0    0    0    0    0    0    0    0    0  ...   20.0   \n",
      "\n",
      "                                                             \n",
      "                                                             \n",
      "YEAR        2011 2012  2013  2014 2015  2016 2017 2018 2019  \n",
      "COUNTY                                                       \n",
      "ADAIR        0.0    0   0.0   0.0    0   0.0  0.0    0    0  \n",
      "ALLEN        0.0    0   0.0   0.0    0   0.0  0.0    0    0  \n",
      "BALLARD      0.0    0   0.0   0.0    0   0.0  0.0    0    0  \n",
      "BATH        48.0    0   0.0   0.0   19   0.0  0.0  160    0  \n",
      "BELL         0.0    0   0.0   0.0    0   0.0  0.0    0    0  \n",
      "...          ...  ...   ...   ...  ...   ...  ...  ...  ...  \n",
      "TRIGG        0.0   15   0.0   0.0  114   0.0  0.0    0    0  \n",
      "UNION       20.0   16  45.0   0.0    0   0.0  0.0    0    0  \n",
      "WASHINGTON   0.0    0   0.0   0.0    0   0.0  0.0    0    0  \n",
      "WEBSTER      0.0    0  61.0  33.0   62  63.0  0.0    0    0  \n",
      "WHITLEY      0.0    0   0.0   0.0    0   0.0  0.0    0    0  \n",
      "\n",
      "[73 rows x 120 columns]\n",
      "MultiIndex([('K',    'len', '1990'),\n",
      "            ('K',    'len', '1991'),\n",
      "            ('K',    'len', '1992'),\n",
      "            ('K',    'len', '1993'),\n",
      "            ('K',    'len', '1994'),\n",
      "            ('K',    'len', '1995'),\n",
      "            ('K',    'len', '1996'),\n",
      "            ('K',    'len', '1997'),\n",
      "            ('K',    'len', '1998'),\n",
      "            ('K',    'len', '1999'),\n",
      "            ...\n",
      "            ('P', 'median', '2010'),\n",
      "            ('P', 'median', '2011'),\n",
      "            ('P', 'median', '2012'),\n",
      "            ('P', 'median', '2013'),\n",
      "            ('P', 'median', '2014'),\n",
      "            ('P', 'median', '2015'),\n",
      "            ('P', 'median', '2016'),\n",
      "            ('P', 'median', '2017'),\n",
      "            ('P', 'median', '2018'),\n",
      "            ('P', 'median', '2019')],\n",
      "           names=[None, None, 'YEAR'], length=120)\n",
      "Index(['K_count_1990', 'K_count_1991', 'K_count_1992', 'K_count_1993',\n",
      "       'K_count_1994', 'K_count_1995', 'K_count_1996', 'K_count_1997',\n",
      "       'K_count_1998', 'K_count_1999',\n",
      "       ...\n",
      "       'P_med2010', 'P_med2011', 'P_med2012', 'P_med2013', 'P_med2014',\n",
      "       'P_med2015', 'P_med2016', 'P_med2017', 'P_med2018', 'P_med2019'],\n",
      "      dtype='object', length=120)\n",
      "        COUNTY  K_count_1990  K_count_1991  K_count_1992  K_count_1993  \\\n",
      "0        ADAIR             0             0             0             0   \n",
      "1        ALLEN             0             0             0             0   \n",
      "2      BALLARD            11             0             5             3   \n",
      "3         BATH             0             0             0             0   \n",
      "4         BELL             0             0             0             0   \n",
      "..         ...           ...           ...           ...           ...   \n",
      "68       TRIGG             0             0             1             0   \n",
      "69       UNION             0             1             0             0   \n",
      "70  WASHINGTON             0             0             5             0   \n",
      "71     WEBSTER             2             0             0             0   \n",
      "72     WHITLEY             0             0             0             0   \n",
      "\n",
      "    K_count_1994  K_count_1995  K_count_1996  K_count_1997  K_count_1998  ...  \\\n",
      "0              0             0             1             1             0  ...   \n",
      "1              0             0             0             0             0  ...   \n",
      "2              6             7             1             5             8  ...   \n",
      "3              0             0             0             0             0  ...   \n",
      "4              0             0             1             0             0  ...   \n",
      "..           ...           ...           ...           ...           ...  ...   \n",
      "68             0             0             0             0             0  ...   \n",
      "69             0             0             0             0             0  ...   \n",
      "70             1             2             0             0             0  ...   \n",
      "71             0             0             0             0             0  ...   \n",
      "72             0             0             0             0             0  ...   \n",
      "\n",
      "    P_med2010  P_med2011  P_med2012  P_med2013  P_med2014  P_med2015  \\\n",
      "0         0.0        0.0          0        0.0        0.0          0   \n",
      "1         0.0        0.0          0        0.0        0.0          0   \n",
      "2         0.0        0.0          0        0.0        0.0          0   \n",
      "3        15.0       48.0          0        0.0        0.0         19   \n",
      "4         0.0        0.0          0        0.0        0.0          0   \n",
      "..        ...        ...        ...        ...        ...        ...   \n",
      "68      141.0        0.0         15        0.0        0.0        114   \n",
      "69        0.0       20.0         16       45.0        0.0          0   \n",
      "70        0.0        0.0          0        0.0        0.0          0   \n",
      "71        0.0        0.0          0       61.0       33.0         62   \n",
      "72       20.0        0.0          0        0.0        0.0          0   \n",
      "\n",
      "    P_med2016  P_med2017  P_med2018  P_med2019  \n",
      "0         0.0        0.0          0          0  \n",
      "1         0.0        0.0          0          0  \n",
      "2         0.0        0.0          0          0  \n",
      "3         0.0        0.0        160          0  \n",
      "4         0.0        0.0          0          0  \n",
      "..        ...        ...        ...        ...  \n",
      "68        0.0        0.0          0          0  \n",
      "69        0.0        0.0          0          0  \n",
      "70        0.0        0.0          0          0  \n",
      "71       63.0        0.0          0          0  \n",
      "72        0.0        0.0          0          0  \n",
      "\n",
      "[73 rows x 121 columns]\n",
      "total number of records written to CSV: 73 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sorghum_median = np.round( df_sorghum_nu.pivot_table(index='COUNTY', columns=['YEAR'], values=['P','K'],aggfunc=(np.median,len),fill_value=0),0)\n",
    "print(df_sorghum_median)\n",
    "print(df_sorghum_median.columns)\n",
    "df_sorghum_median.columns = list(map(\"_\".join,df_sorghum_median.columns))\n",
    "df_sorghum_median.columns = df_sorghum_median.columns.str.replace(\"P_median_\", \"P_med\")\n",
    "df_sorghum_median.columns = df_sorghum_median.columns.str.replace(\"P_len\", \"P_count\")\n",
    "df_sorghum_median.columns = df_sorghum_median.columns.str.replace(\"K_median_\",\"K_med\")\n",
    "df_sorghum_median.columns = df_sorghum_median.columns.str.replace(\"K_len\",\"K_count\")\n",
    "print(df_sorghum_median.columns)\n",
    "df_sorghum_median = df_sorghum_median.reset_index()\n",
    "print(df_sorghum_median)\n",
    "file_out_median = fileOut.joinpath('sorghum_median.csv')  # path and filename\n",
    "df_sorghum_median.to_csv(file_out_median, index=False)  # output to csv\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_sorghum_median)),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorghum, Set categories for P and K values to very low, low, medium, high, very high. Base values from AGR-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories for P\n",
    "    Cat      Title       Break\n",
    "    -------------------------------------\n",
    "    VL       very low    P< 6\n",
    "    L        low         P>= 6 & P<=27\n",
    "    M        medium      P>27 & P<=60\n",
    "    H        high        P>60\n",
    "    \n",
    "#### Categories for K\n",
    "    Cat      Title      Break\n",
    "   --------------------------------------\n",
    "    VL       very low   K< 100\n",
    "    L        low        K>=100 & K <=190\n",
    "    M        medium     K>=191 & K <=300\n",
    "    H        high       K>300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorghum_nu['CAT_P'] = ''\n",
    "df_sorghum_nu['CAT_P'] = np.where(df_sorghum_nu.P < 6, 'VL', df_sorghum_nu.CAT_P)\n",
    "df_sorghum_nu['CAT_P'] = np.where(((df_sorghum_nu.P >= 6) & (df_sorghum_nu.P <= 27)), 'L', df_sorghum_nu.CAT_P)\n",
    "df_sorghum_nu['CAT_P'] = np.where(((df_sorghum_nu.P > 27) & (df_sorghum_nu.P <= 60)), 'M', df_sorghum_nu.CAT_P)\n",
    "df_sorghum_nu['CAT_P'] = np.where((df_sorghum_nu.P > 60), 'H', df_sorghum_nu.CAT_P)\n",
    "\n",
    "df_sorghum_nu['CAT_K'] = ''\n",
    "df_sorghum_nu['CAT_K'] = np.where(df_sorghum_nu.K < 100, 'VL', df_sorghum_nu.CAT_K)\n",
    "df_sorghum_nu['CAT_K'] = np.where(((df_sorghum_nu.K >= 100) & (df_sorghum_nu.K <= 190)), 'L', df_sorghum_nu.CAT_K)\n",
    "df_sorghum_nu['CAT_K'] = np.where(((df_sorghum_nu.K > 190) & (df_sorghum_nu.K <= 300)), 'M', df_sorghum_nu.CAT_K)\n",
    "df_sorghum_nu['CAT_K'] = np.where((df_sorghum_nu.K > 300), 'H', df_sorghum_nu.CAT_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records written to CSV: 73 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "df_sorghum_p = np.round( df_sorghum_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_P'], values=['P'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "df_sorghum_k = np.round( df_sorghum_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_K'], values=['K'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "\n",
    "df_sorghum_p.columns\n",
    "df_sorghum_k.columns\n",
    "df_sorghum_p.columns = list(map(\"_\".join,df_sorghum_p.columns))\n",
    "df_sorghum_k.columns = list(map(\"_\".join,df_sorghum_k.columns))\n",
    "df_sorghum_p.columns = df_sorghum_p.columns.str.replace(\"P_median_\", \"P_\")\n",
    "df_sorghum_p.columns = df_sorghum_p.columns.str.replace(\"P_len\", \"P_count\")\n",
    "df_sorghum_k.columns = df_sorghum_k.columns.str.replace(\"K_median_\",\"K_\")\n",
    "df_sorghum_k.columns = df_sorghum_k.columns.str.replace(\"K_len\",\"K_count\")\n",
    "df_sorghum_p = df_sorghum_p.reset_index()\n",
    "df_sorghum_k = df_sorghum_k.reset_index()\n",
    "\n",
    "\n",
    "sorghum_level = df_sorghum_p.merge(df_sorghum_k, left_on='COUNTY', right_on='COUNTY')\n",
    "\n",
    "file_out_level = fileOut.joinpath('sorghum_levels.csv')\n",
    "sorghum_level.to_csv(file_out_level, index=False)\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(sorghum_level)),'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small Grains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list to select Small Grains from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barley', 'Barley/Soybeans', 'Grain Crops (multiple)', 'Oats', 'Oats/Soybeans', 'Rye/Soybeans', 'Small Grains', 'Small Grains/Corn', 'Small Grains/Soybeans', 'Triticale', 'Triticale/Soybeans', 'Wheat', 'Wheat/Corn', 'Wheat/Soybeans']\n"
     ]
    }
   ],
   "source": [
    "smallgrains_sel = ['Barley' , 'Barley/Soybeans', 'Grain Crops (multiple)','Oats','Oats/Soybeans', 'Rye/Soybeans', 'Small Grains', 'Small Grains/Corn', 'Small Grains/Soybeans', 'Triticale', 'Triticale/Soybeans', 'Wheat', 'Wheat/Corn', 'Wheat/Soybeans']\n",
    "smallgrains_sel.sort()\n",
    "print(smallgrains_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Small Grains from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     FIPS_NO COUNTY  YEAR     P      K\n",
      "635        1  ADAIR  1991  16.0  234.0\n",
      "901        1  ADAIR  1992  51.0  203.0\n",
      "969        1  ADAIR  1992  29.0  152.0\n",
      "970        1  ADAIR  1992  15.0  193.0\n",
      "1333       1  ADAIR  1993  16.0   94.0\n"
     ]
    }
   ],
   "source": [
    "df_smallgrains = df[df.CROP.isin(smallgrains_sel)]\n",
    "df_smallgrains_nu = df_smallgrains[['FIPS_NO','COUNTY','YEAR','P','K']].copy()\n",
    "print(df_smallgrains_nu.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate median for each year by County."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            K                                               ...      P         \\\n",
      "          len                                               ... median          \n",
      "YEAR     1990 1991 1992 1993 1994 1995 1996 1997 1998 1999  ...   2010   2011   \n",
      "COUNTY                                                      ...                 \n",
      "ADAIR       0    1    3    1    1   11   19   18    6    9  ...   92.0  202.0   \n",
      "ALLEN      15    5    0   10    6    7    3    4    0    2  ...   39.0   53.0   \n",
      "ANDERSON    0    1    1    0    0    0    1    0    0    0  ...   62.0    0.0   \n",
      "BALLARD    35   11    5   13   19   13   22   23   31   46  ...  186.0    0.0   \n",
      "BARREN     11    6   11    7   33   41    7    6    0    5  ...  246.0    0.0   \n",
      "...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
      "WAYNE      24   17   10   31   29   21   30   30   54   30  ...  137.0  151.0   \n",
      "WEBSTER    79  195  117   50   50   66   13   11    2   34  ...    0.0    0.0   \n",
      "WHITLEY     0    2    0    0    2    0    1    0    1    1  ...    0.0    0.0   \n",
      "WOLFE       2    1    0    0    1    1    1    0    0    1  ...    0.0    0.0   \n",
      "WOODFORD   10    6    4    5   15   51   39    6    8   24  ...  362.0  138.0   \n",
      "\n",
      "                                                                  \n",
      "                                                                  \n",
      "YEAR       2012   2013   2014   2015   2016   2017   2018   2019  \n",
      "COUNTY                                                            \n",
      "ADAIR      47.0  116.0   38.0  115.0  264.0   33.0  539.0  215.0  \n",
      "ALLEN      66.0  138.0   94.0   77.0  119.0   43.0   93.0  192.0  \n",
      "ANDERSON  368.0    0.0  232.0   36.0  180.0  414.0   69.0  270.0  \n",
      "BALLARD    67.0   80.0   82.0   63.0   39.0   74.0    0.0   58.0  \n",
      "BARREN    339.0   34.0   64.0   94.0  128.0   50.0   63.0   23.0  \n",
      "...         ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "WAYNE     163.0  112.0  151.0  103.0  110.0   52.0   27.0   56.0  \n",
      "WEBSTER     0.0   42.0    0.0    0.0    0.0    0.0   56.0   53.0  \n",
      "WHITLEY     0.0  184.0    0.0   36.0    9.0    0.0    0.0   16.0  \n",
      "WOLFE       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
      "WOODFORD  202.0  241.0  283.0  207.0  430.0  100.0   42.0   56.0  \n",
      "\n",
      "[119 rows x 120 columns]\n",
      "MultiIndex([('K',    'len', '1990'),\n",
      "            ('K',    'len', '1991'),\n",
      "            ('K',    'len', '1992'),\n",
      "            ('K',    'len', '1993'),\n",
      "            ('K',    'len', '1994'),\n",
      "            ('K',    'len', '1995'),\n",
      "            ('K',    'len', '1996'),\n",
      "            ('K',    'len', '1997'),\n",
      "            ('K',    'len', '1998'),\n",
      "            ('K',    'len', '1999'),\n",
      "            ...\n",
      "            ('P', 'median', '2010'),\n",
      "            ('P', 'median', '2011'),\n",
      "            ('P', 'median', '2012'),\n",
      "            ('P', 'median', '2013'),\n",
      "            ('P', 'median', '2014'),\n",
      "            ('P', 'median', '2015'),\n",
      "            ('P', 'median', '2016'),\n",
      "            ('P', 'median', '2017'),\n",
      "            ('P', 'median', '2018'),\n",
      "            ('P', 'median', '2019')],\n",
      "           names=[None, None, 'YEAR'], length=120)\n",
      "Index(['K_count_1990', 'K_count_1991', 'K_count_1992', 'K_count_1993',\n",
      "       'K_count_1994', 'K_count_1995', 'K_count_1996', 'K_count_1997',\n",
      "       'K_count_1998', 'K_count_1999',\n",
      "       ...\n",
      "       'P_med2010', 'P_med2011', 'P_med2012', 'P_med2013', 'P_med2014',\n",
      "       'P_med2015', 'P_med2016', 'P_med2017', 'P_med2018', 'P_med2019'],\n",
      "      dtype='object', length=120)\n",
      "       COUNTY  K_count_1990  K_count_1991  K_count_1992  K_count_1993  \\\n",
      "0       ADAIR             0             1             3             1   \n",
      "1       ALLEN            15             5             0            10   \n",
      "2    ANDERSON             0             1             1             0   \n",
      "3     BALLARD            35            11             5            13   \n",
      "4      BARREN            11             6            11             7   \n",
      "..        ...           ...           ...           ...           ...   \n",
      "114     WAYNE            24            17            10            31   \n",
      "115   WEBSTER            79           195           117            50   \n",
      "116   WHITLEY             0             2             0             0   \n",
      "117     WOLFE             2             1             0             0   \n",
      "118  WOODFORD            10             6             4             5   \n",
      "\n",
      "     K_count_1994  K_count_1995  K_count_1996  K_count_1997  K_count_1998  \\\n",
      "0               1            11            19            18             6   \n",
      "1               6             7             3             4             0   \n",
      "2               0             0             1             0             0   \n",
      "3              19            13            22            23            31   \n",
      "4              33            41             7             6             0   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "114            29            21            30            30            54   \n",
      "115            50            66            13            11             2   \n",
      "116             2             0             1             0             1   \n",
      "117             1             1             1             0             0   \n",
      "118            15            51            39             6             8   \n",
      "\n",
      "     ...  P_med2010  P_med2011  P_med2012  P_med2013  P_med2014  P_med2015  \\\n",
      "0    ...       92.0      202.0       47.0      116.0       38.0      115.0   \n",
      "1    ...       39.0       53.0       66.0      138.0       94.0       77.0   \n",
      "2    ...       62.0        0.0      368.0        0.0      232.0       36.0   \n",
      "3    ...      186.0        0.0       67.0       80.0       82.0       63.0   \n",
      "4    ...      246.0        0.0      339.0       34.0       64.0       94.0   \n",
      "..   ...        ...        ...        ...        ...        ...        ...   \n",
      "114  ...      137.0      151.0      163.0      112.0      151.0      103.0   \n",
      "115  ...        0.0        0.0        0.0       42.0        0.0        0.0   \n",
      "116  ...        0.0        0.0        0.0      184.0        0.0       36.0   \n",
      "117  ...        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "118  ...      362.0      138.0      202.0      241.0      283.0      207.0   \n",
      "\n",
      "     P_med2016  P_med2017  P_med2018  P_med2019  \n",
      "0        264.0       33.0      539.0      215.0  \n",
      "1        119.0       43.0       93.0      192.0  \n",
      "2        180.0      414.0       69.0      270.0  \n",
      "3         39.0       74.0        0.0       58.0  \n",
      "4        128.0       50.0       63.0       23.0  \n",
      "..         ...        ...        ...        ...  \n",
      "114      110.0       52.0       27.0       56.0  \n",
      "115        0.0        0.0       56.0       53.0  \n",
      "116        9.0        0.0        0.0       16.0  \n",
      "117        0.0        0.0        0.0        0.0  \n",
      "118      430.0      100.0       42.0       56.0  \n",
      "\n",
      "[119 rows x 121 columns]\n",
      "total number of records written to CSV: 119 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_smallgrains_median = np.round( df_smallgrains_nu.pivot_table(index='COUNTY', columns=['YEAR'], values=['P','K'],aggfunc=(np.median,len),fill_value=0),0)\n",
    "print(df_smallgrains_median)\n",
    "print(df_smallgrains_median.columns)\n",
    "df_smallgrains_median.columns = list(map(\"_\".join,df_smallgrains_median.columns))\n",
    "df_smallgrains_median.columns = df_smallgrains_median.columns.str.replace(\"P_median_\", \"P_med\")\n",
    "df_smallgrains_median.columns = df_smallgrains_median.columns.str.replace(\"P_len\", \"P_count\")\n",
    "df_smallgrains_median.columns = df_smallgrains_median.columns.str.replace(\"K_median_\",\"K_med\")\n",
    "df_smallgrains_median.columns = df_smallgrains_median.columns.str.replace(\"K_len\",\"K_count\")\n",
    "print(df_smallgrains_median.columns)\n",
    "df_smallgrains_median = df_smallgrains_median.reset_index()\n",
    "print(df_smallgrains_median)\n",
    "file_out_median = fileOut.joinpath('smallgrains_median.csv')  # path and filename\n",
    "df_smallgrains_median.to_csv(file_out_median, index=False)  # output to csv\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_smallgrains_median)),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small Grains, Set categories for P and K values to very low, low, medium, high, very high. Base values from AGR-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories for P\n",
    "    Cat      Title       Break\n",
    "    -------------------------------------\n",
    "    VL       very low    P< 10\n",
    "    L        low         P>= 10 & P<=30\n",
    "    M        medium      P>30 & P<=60\n",
    "    H        high        P>60\n",
    "    \n",
    "#### Categories for K\n",
    "    Cat      Title      Break\n",
    "   --------------------------------------\n",
    "    VL       very low   K< 104\n",
    "    L        low        K>=104 & K <=186\n",
    "    M        medium     K>=187 & K <=300\n",
    "    H        high       K>300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smallgrains_nu['CAT_P'] = ''\n",
    "df_smallgrains_nu['CAT_P'] = np.where(df_smallgrains_nu.P < 10, 'VL', df_smallgrains_nu.CAT_P)\n",
    "df_smallgrains_nu['CAT_P'] = np.where(((df_smallgrains_nu.P > 10) & (df_smallgrains_nu.P <= 30)), 'L', df_smallgrains_nu.CAT_P)\n",
    "df_smallgrains_nu['CAT_P'] = np.where(((df_smallgrains_nu.P > 30) & (df_smallgrains_nu.P <= 60)), 'M', df_smallgrains_nu.CAT_P)\n",
    "df_smallgrains_nu['CAT_P'] = np.where((df_smallgrains_nu.P > 60), 'H', df_smallgrains_nu.CAT_P)\n",
    "\n",
    "df_smallgrains_nu['CAT_K'] = ''\n",
    "df_smallgrains_nu['CAT_K'] = np.where(df_smallgrains_nu.K < 104, 'VL', df_smallgrains_nu.CAT_K)\n",
    "df_smallgrains_nu['CAT_K'] = np.where(((df_smallgrains_nu.K >= 104) & (df_smallgrains_nu.K <= 186)), 'L', df_smallgrains_nu.CAT_K)\n",
    "df_smallgrains_nu['CAT_K'] = np.where(((df_smallgrains_nu.K > 186) & (df_smallgrains_nu.K <= 300)), 'M', df_smallgrains_nu.CAT_K)\n",
    "df_smallgrains_nu['CAT_K'] = np.where((df_smallgrains_nu.K > 300), 'H', df_smallgrains_nu.CAT_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records written to CSV: 119 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "df_smallgrains_p = np.round( df_smallgrains_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_P'], values=['P'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "df_smallgrains_k = np.round( df_smallgrains_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_K'], values=['K'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "\n",
    "df_smallgrains_p.columns\n",
    "df_smallgrains_k.columns\n",
    "df_smallgrains_p.columns = list(map(\"_\".join,df_smallgrains_p.columns))\n",
    "df_smallgrains_k.columns = list(map(\"_\".join,df_smallgrains_k.columns))\n",
    "df_smallgrains_p.columns = df_smallgrains_p.columns.str.replace(\"P_median_\", \"P_\")\n",
    "df_smallgrains_p.columns = df_smallgrains_p.columns.str.replace(\"P_len\", \"P_count\")\n",
    "df_smallgrains_k.columns = df_smallgrains_k.columns.str.replace(\"K_median_\",\"K_\")\n",
    "df_smallgrains_k.columns = df_smallgrains_k.columns.str.replace(\"K_len\",\"K_count\")\n",
    "df_smallgrains_p = df_smallgrains_p.reset_index()\n",
    "df_smallgrains_k = df_smallgrains_k.reset_index()\n",
    "\n",
    "\n",
    "smallgrains_level = df_smallgrains_p.merge(df_smallgrains_k, left_on='COUNTY', right_on='COUNTY')\n",
    "\n",
    "file_out_level = fileOut.joinpath('smallgrains_levels.csv')\n",
    "smallgrains_level.to_csv(file_out_level, index=False)\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(smallgrains_level)),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tobacco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list to select Tobacco from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Burley Tobacco', 'Dark Tobacco']\n"
     ]
    }
   ],
   "source": [
    "tobacco_sel = ['Burley Tobacco', 'Dark Tobacco']\n",
    "tobacco_sel.sort()\n",
    "print(tobacco_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Tobacco from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FIPS_NO COUNTY  YEAR      P      K\n",
      "24       1  ADAIR  1990  282.0  298.0\n",
      "25       1  ADAIR  1990  206.0  611.0\n",
      "26       1  ADAIR  1990   71.0  120.0\n",
      "27       1  ADAIR  1990  124.0  320.0\n",
      "28       1  ADAIR  1990  300.0  283.0\n"
     ]
    }
   ],
   "source": [
    "df_tobacco = df[df.CROP.isin(tobacco_sel)]\n",
    "df_tobacco_nu = df_tobacco[['FIPS_NO','COUNTY','YEAR','P','K']].copy()\n",
    "print(df_tobacco_nu.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate median for each year by County."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            K                                               ...      P         \\\n",
      "          len                                               ... median          \n",
      "YEAR     1990 1991 1992 1993 1994 1995 1996 1997 1998 1999  ...   2010   2011   \n",
      "COUNTY                                                      ...                 \n",
      "ADAIR      69   86  100   89   53   80  111  116   79  103  ...  139.0  156.0   \n",
      "ALLEN      80   90   82   69   43   22   40   25   27   10  ...  151.0   72.0   \n",
      "ANDERSON  122  137  116   84   71   56   73   68   88   52  ...  355.0  284.0   \n",
      "BALLARD    43   51   80   58   36   49   60   69   84   97  ...  145.0    0.0   \n",
      "BARREN    167  176  291  291  187  147  111   92   45   37  ...  144.0   60.0   \n",
      "...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
      "WAYNE     102   98  119   95   62   87   73  158  100   92  ...  126.0  135.0   \n",
      "WEBSTER     4   16   16    6   10   15   12   10   12   16  ...   82.0   85.0   \n",
      "WHITLEY    37   63   75   39   22   21   29   36   39   42  ...   74.0   46.0   \n",
      "WOLFE      99   92   90   59   35   32   43   61   71   54  ...  322.0  395.0   \n",
      "WOODFORD  320  375  194  162  129  176  160  187  199  151  ...  308.0  243.0   \n",
      "\n",
      "                                                                  \n",
      "                                                                  \n",
      "YEAR       2012   2013   2014   2015   2016   2017   2018   2019  \n",
      "COUNTY                                                            \n",
      "ADAIR     115.0  128.0  139.0  200.0  270.0  196.0  157.0  521.0  \n",
      "ALLEN      57.0   59.0   66.0    0.0  138.0    0.0   52.0    0.0  \n",
      "ANDERSON  292.0  344.0  369.0  244.0  146.0  233.0  455.0  450.0  \n",
      "BALLARD    42.0  222.0  332.0  152.0  121.0  137.0  204.0    0.0  \n",
      "BARREN    130.0   35.0   88.0   84.0  122.0   89.0  170.0  159.0  \n",
      "...         ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "WAYNE     111.0   86.0   98.0  149.0  140.0  145.0  108.0   86.0  \n",
      "WEBSTER    86.0  134.0  110.0   75.0  144.0   61.0   70.0  148.0  \n",
      "WHITLEY     0.0  367.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
      "WOLFE     496.0  446.0  361.0  592.0    0.0    0.0  471.0    0.0  \n",
      "WOODFORD  238.0  320.0  352.0  292.0  278.0  303.0  297.0  276.0  \n",
      "\n",
      "[120 rows x 120 columns]\n",
      "MultiIndex([('K',    'len', '1990'),\n",
      "            ('K',    'len', '1991'),\n",
      "            ('K',    'len', '1992'),\n",
      "            ('K',    'len', '1993'),\n",
      "            ('K',    'len', '1994'),\n",
      "            ('K',    'len', '1995'),\n",
      "            ('K',    'len', '1996'),\n",
      "            ('K',    'len', '1997'),\n",
      "            ('K',    'len', '1998'),\n",
      "            ('K',    'len', '1999'),\n",
      "            ...\n",
      "            ('P', 'median', '2010'),\n",
      "            ('P', 'median', '2011'),\n",
      "            ('P', 'median', '2012'),\n",
      "            ('P', 'median', '2013'),\n",
      "            ('P', 'median', '2014'),\n",
      "            ('P', 'median', '2015'),\n",
      "            ('P', 'median', '2016'),\n",
      "            ('P', 'median', '2017'),\n",
      "            ('P', 'median', '2018'),\n",
      "            ('P', 'median', '2019')],\n",
      "           names=[None, None, 'YEAR'], length=120)\n",
      "Index(['K_count_1990', 'K_count_1991', 'K_count_1992', 'K_count_1993',\n",
      "       'K_count_1994', 'K_count_1995', 'K_count_1996', 'K_count_1997',\n",
      "       'K_count_1998', 'K_count_1999',\n",
      "       ...\n",
      "       'P_med2010', 'P_med2011', 'P_med2012', 'P_med2013', 'P_med2014',\n",
      "       'P_med2015', 'P_med2016', 'P_med2017', 'P_med2018', 'P_med2019'],\n",
      "      dtype='object', length=120)\n",
      "       COUNTY  K_count_1990  K_count_1991  K_count_1992  K_count_1993  \\\n",
      "0       ADAIR            69            86           100            89   \n",
      "1       ALLEN            80            90            82            69   \n",
      "2    ANDERSON           122           137           116            84   \n",
      "3     BALLARD            43            51            80            58   \n",
      "4      BARREN           167           176           291           291   \n",
      "..        ...           ...           ...           ...           ...   \n",
      "115     WAYNE           102            98           119            95   \n",
      "116   WEBSTER             4            16            16             6   \n",
      "117   WHITLEY            37            63            75            39   \n",
      "118     WOLFE            99            92            90            59   \n",
      "119  WOODFORD           320           375           194           162   \n",
      "\n",
      "     K_count_1994  K_count_1995  K_count_1996  K_count_1997  K_count_1998  \\\n",
      "0              53            80           111           116            79   \n",
      "1              43            22            40            25            27   \n",
      "2              71            56            73            68            88   \n",
      "3              36            49            60            69            84   \n",
      "4             187           147           111            92            45   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "115            62            87            73           158           100   \n",
      "116            10            15            12            10            12   \n",
      "117            22            21            29            36            39   \n",
      "118            35            32            43            61            71   \n",
      "119           129           176           160           187           199   \n",
      "\n",
      "     ...  P_med2010  P_med2011  P_med2012  P_med2013  P_med2014  P_med2015  \\\n",
      "0    ...      139.0      156.0      115.0      128.0      139.0      200.0   \n",
      "1    ...      151.0       72.0       57.0       59.0       66.0        0.0   \n",
      "2    ...      355.0      284.0      292.0      344.0      369.0      244.0   \n",
      "3    ...      145.0        0.0       42.0      222.0      332.0      152.0   \n",
      "4    ...      144.0       60.0      130.0       35.0       88.0       84.0   \n",
      "..   ...        ...        ...        ...        ...        ...        ...   \n",
      "115  ...      126.0      135.0      111.0       86.0       98.0      149.0   \n",
      "116  ...       82.0       85.0       86.0      134.0      110.0       75.0   \n",
      "117  ...       74.0       46.0        0.0      367.0        0.0        0.0   \n",
      "118  ...      322.0      395.0      496.0      446.0      361.0      592.0   \n",
      "119  ...      308.0      243.0      238.0      320.0      352.0      292.0   \n",
      "\n",
      "     P_med2016  P_med2017  P_med2018  P_med2019  \n",
      "0        270.0      196.0      157.0      521.0  \n",
      "1        138.0        0.0       52.0        0.0  \n",
      "2        146.0      233.0      455.0      450.0  \n",
      "3        121.0      137.0      204.0        0.0  \n",
      "4        122.0       89.0      170.0      159.0  \n",
      "..         ...        ...        ...        ...  \n",
      "115      140.0      145.0      108.0       86.0  \n",
      "116      144.0       61.0       70.0      148.0  \n",
      "117        0.0        0.0        0.0        0.0  \n",
      "118        0.0        0.0      471.0        0.0  \n",
      "119      278.0      303.0      297.0      276.0  \n",
      "\n",
      "[120 rows x 121 columns]\n",
      "total number of records written to CSV: 120 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tobacco_median = np.round( df_tobacco_nu.pivot_table(index='COUNTY', columns=['YEAR'], values=['P','K'],aggfunc=(np.median,len),fill_value=0),0)\n",
    "print(df_tobacco_median)\n",
    "print(df_tobacco_median.columns)\n",
    "df_tobacco_median.columns = list(map(\"_\".join,df_tobacco_median.columns))\n",
    "df_tobacco_median.columns = df_tobacco_median.columns.str.replace(\"P_median_\", \"P_med\")\n",
    "df_tobacco_median.columns = df_tobacco_median.columns.str.replace(\"P_len\", \"P_count\")\n",
    "df_tobacco_median.columns = df_tobacco_median.columns.str.replace(\"K_median_\",\"K_med\")\n",
    "df_tobacco_median.columns = df_tobacco_median.columns.str.replace(\"K_len\",\"K_count\")\n",
    "print(df_tobacco_median.columns)\n",
    "df_tobacco_median = df_tobacco_median.reset_index()\n",
    "print(df_tobacco_median)\n",
    "file_out_median = fileOut.joinpath('tobacco_median.csv')  # path and filename\n",
    "df_tobacco_median.to_csv(file_out_median, index=False)  # output to csv\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_tobacco_median)),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tobacco, Set categories for P and K values to very low, low, medium, high, very high. Base values from AGR-1.\n",
    "Combined Burley and Dark Tobacco K into Burley recommendations for K categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories for P\n",
    "    Cat      Title       Break\n",
    "    -------------------------------------\n",
    "    VL       very low    P< 7\n",
    "    L        low         P>= 7 & P<=28\n",
    "    M        medium      P>28 & P<=57\n",
    "    H        high        P>57 & P<=79\n",
    "    VH       very high   P> 80\n",
    "    \n",
    "\n",
    "#### Categories for K\n",
    "    Cat      Title      Break\n",
    "   --------------------------------------\n",
    "    VL       very low   K< 96\n",
    "    L        low        K>=96 & K <=205\n",
    "    M        medium     K>205 & K <=303\n",
    "    H        high       K>303 & K <=449\n",
    "    VH       very high  K> 450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tobacco_nu['CAT_P'] = ''\n",
    "df_tobacco_nu['CAT_P'] = np.where(df_tobacco_nu.P < 7, 'VL', df_tobacco_nu.CAT_P)\n",
    "df_tobacco_nu['CAT_P'] = np.where(((df_tobacco_nu.P >= 7) & (df_tobacco_nu.P <= 28)), 'L', df_tobacco_nu.CAT_P)\n",
    "df_tobacco_nu['CAT_P'] = np.where(((df_tobacco_nu.P > 28) & (df_tobacco_nu.P <= 57)), 'M', df_tobacco_nu.CAT_P)\n",
    "df_tobacco_nu['CAT_P'] = np.where(((df_tobacco_nu.P > 57) &  (df_tobacco_nu.P <= 79)), 'H', df_tobacco_nu.CAT_P)\n",
    "df_tobacco_nu['CAT_P'] = np.where(df_tobacco_nu.P > 80, 'VH', df_tobacco_nu.CAT_P)\n",
    "df_tobacco_nu['CAT_K'] = ''\n",
    "df_tobacco_nu['CAT_K'] = np.where(df_tobacco_nu.K < 96, 'VL', df_tobacco_nu.CAT_K)\n",
    "df_tobacco_nu['CAT_K'] = np.where(((df_tobacco_nu.K >= 96) & (df_tobacco_nu.K <= 205)), 'L', df_tobacco_nu.CAT_K)\n",
    "df_tobacco_nu['CAT_K'] = np.where(((df_tobacco_nu.K > 205) & (df_tobacco_nu.K <= 303)), 'M', df_tobacco_nu.CAT_K)\n",
    "df_tobacco_nu['CAT_K'] = np.where(((df_tobacco_nu.K > 303) & (df_tobacco_nu.K <= 449)), 'H', df_tobacco_nu.CAT_K)\n",
    "df_tobacco_nu['CAT_K'] = np.where(df_tobacco_nu.K > 450, 'VH', df_tobacco_nu.CAT_K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records written to CSV: 120 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "df_tobacco_p = np.round( df_tobacco_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_P'], values=['P'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "df_tobacco_k = np.round( df_tobacco_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_K'], values=['K'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "\n",
    "df_tobacco_p.columns\n",
    "df_tobacco_k.columns\n",
    "df_tobacco_p.columns = list(map(\"_\".join,df_tobacco_p.columns))\n",
    "df_tobacco_k.columns = list(map(\"_\".join,df_tobacco_k.columns))\n",
    "df_tobacco_p.columns = df_tobacco_p.columns.str.replace(\"P_median_\", \"P_\")\n",
    "df_tobacco_p.columns = df_tobacco_p.columns.str.replace(\"P_len\", \"P_count\")\n",
    "df_tobacco_k.columns = df_tobacco_k.columns.str.replace(\"K_median_\",\"K_\")\n",
    "df_tobacco_k.columns = df_tobacco_k.columns.str.replace(\"K_len\",\"K_count\")\n",
    "df_tobacco_p = df_tobacco_p.reset_index()\n",
    "df_tobacco_k = df_tobacco_k.reset_index()\n",
    "\n",
    "tobacco_level = df_tobacco_p.merge(df_tobacco_k, left_on='COUNTY', right_on='COUNTY')\n",
    "\n",
    "file_out_level = fileOut.joinpath('tobacco_levels.csv')\n",
    "tobacco_level.to_csv(file_out_level, index=False)\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(tobacco_level)),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm Season Grass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list to select Warm Season Grass from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bermudagrass', 'Bermudagrass, common', 'Bermudagrass, improved', 'Bluestem', 'Indiangrass', 'Millet', 'Sorghum Sudangrass', 'Sorghum/Sudangras', 'Sudangrass', 'Switchgrass', 'Warm Season Annual Grass', 'Warm Season Grass', 'Warm Season Native Grass', 'Zoyiagrass', 'Zoysiagrass']\n"
     ]
    }
   ],
   "source": [
    "warmseason_sel = ['Bermudagrass', 'Bermudagrass, common', 'Bermudagrass, improved', 'Bluestem', 'Indiangrass', 'Millet', 'Sorghum Sudangrass', 'Sorghum/Sudangras', 'Sudangrass', 'Switchgrass', 'Warm Season Annual Grass', 'Warm Season Grass', 'Warm Season Native Grass', 'Zoyiagrass', 'Zoysiagrass']\n",
    "warmseason_sel.sort()\n",
    "print(warmseason_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Warm Season Grass from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     FIPS_NO COUNTY  YEAR     P      K\n",
      "968        1  ADAIR  1992  89.0  194.0\n",
      "1564       1  ADAIR  1994  93.0  153.0\n",
      "1887       1  ADAIR  1995  26.0  178.0\n",
      "2266       1  ADAIR  1996  58.0  129.0\n",
      "2606       1  ADAIR  1997  94.0  214.0\n"
     ]
    }
   ],
   "source": [
    " df_warmseason = df[df.CROP.isin(warmseason_sel)]\n",
    " df_warmseason_nu = df_warmseason[['FIPS_NO','COUNTY','YEAR','P','K']].copy()\n",
    " print(df_warmseason_nu.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate median by year for each County."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            K                                               ...      P  \\\n",
      "          len                                               ... median   \n",
      "YEAR     1990 1991 1992 1993 1994 1995 1996 1997 1998 1999  ...   2010   \n",
      "COUNTY                                                      ...          \n",
      "ADAIR       0    0    1    0    1    1    1    1    2    4  ...    0.0   \n",
      "ALLEN       3    1    0    0    1    0    0    0    2    2  ...   89.0   \n",
      "ANDERSON    0    0    0    0    0    0    0    3    0    0  ...  128.0   \n",
      "BALLARD     1    0    0    1    2    1    0    0    1    2  ...   34.0   \n",
      "BARREN      3    2    3   12    2    5    4    0    1    0  ...   64.0   \n",
      "...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...   \n",
      "WAYNE       0    0    0    1    0    0    0    0    1    0  ...  224.0   \n",
      "WEBSTER     0    1    0    0    0    0    0    0   20   19  ...   19.0   \n",
      "WHITLEY     0    0    0    0    0    0    0    0    1    1  ...    0.0   \n",
      "WOLFE       0    0    0    0    0    0    0    0    0    1  ...    0.0   \n",
      "WOODFORD    2    0   20    5    6    6    1    1    8    0  ...  309.0   \n",
      "\n",
      "                                                                           \n",
      "                                                                           \n",
      "YEAR        2011   2012   2013   2014    2015   2016   2017   2018   2019  \n",
      "COUNTY                                                                     \n",
      "ADAIR        0.0   22.0    0.0  148.0     0.0    0.0   52.0  152.0  206.0  \n",
      "ALLEN       66.0   76.0  108.0  108.0    58.0   47.0  205.0  137.0   51.0  \n",
      "ANDERSON    83.0   76.0   25.0   32.0     0.0  169.0   46.0  158.0  101.0  \n",
      "BALLARD     47.0   73.0   44.0    0.0   111.0    0.0    0.0    0.0    0.0  \n",
      "BARREN      33.0   36.0    0.0   54.0    56.0    0.0   55.0   47.0   12.0  \n",
      "...          ...    ...    ...    ...     ...    ...    ...    ...    ...  \n",
      "WAYNE     1070.0  170.0  131.0  358.0   169.0    0.0   75.0    0.0  254.0  \n",
      "WEBSTER      0.0   67.0    0.0   60.0    61.0   35.0    0.0    0.0    0.0  \n",
      "WHITLEY      0.0    0.0   49.0    9.0  1126.0   15.0   38.0  246.0   75.0  \n",
      "WOLFE        0.0    0.0    0.0    0.0     0.0    0.0    0.0    0.0    0.0  \n",
      "WOODFORD   326.0   68.0  530.0   50.0   296.0  316.0  374.0  357.0  343.0  \n",
      "\n",
      "[116 rows x 120 columns]\n",
      "MultiIndex([('K',    'len', '1990'),\n",
      "            ('K',    'len', '1991'),\n",
      "            ('K',    'len', '1992'),\n",
      "            ('K',    'len', '1993'),\n",
      "            ('K',    'len', '1994'),\n",
      "            ('K',    'len', '1995'),\n",
      "            ('K',    'len', '1996'),\n",
      "            ('K',    'len', '1997'),\n",
      "            ('K',    'len', '1998'),\n",
      "            ('K',    'len', '1999'),\n",
      "            ...\n",
      "            ('P', 'median', '2010'),\n",
      "            ('P', 'median', '2011'),\n",
      "            ('P', 'median', '2012'),\n",
      "            ('P', 'median', '2013'),\n",
      "            ('P', 'median', '2014'),\n",
      "            ('P', 'median', '2015'),\n",
      "            ('P', 'median', '2016'),\n",
      "            ('P', 'median', '2017'),\n",
      "            ('P', 'median', '2018'),\n",
      "            ('P', 'median', '2019')],\n",
      "           names=[None, None, 'YEAR'], length=120)\n",
      "Index(['K_count_1990', 'K_count_1991', 'K_count_1992', 'K_count_1993',\n",
      "       'K_count_1994', 'K_count_1995', 'K_count_1996', 'K_count_1997',\n",
      "       'K_count_1998', 'K_count_1999',\n",
      "       ...\n",
      "       'P_med2010', 'P_med2011', 'P_med2012', 'P_med2013', 'P_med2014',\n",
      "       'P_med2015', 'P_med2016', 'P_med2017', 'P_med2018', 'P_med2019'],\n",
      "      dtype='object', length=120)\n",
      "       COUNTY  K_count_1990  K_count_1991  K_count_1992  K_count_1993  \\\n",
      "0       ADAIR             0             0             1             0   \n",
      "1       ALLEN             3             1             0             0   \n",
      "2    ANDERSON             0             0             0             0   \n",
      "3     BALLARD             1             0             0             1   \n",
      "4      BARREN             3             2             3            12   \n",
      "..        ...           ...           ...           ...           ...   \n",
      "111     WAYNE             0             0             0             1   \n",
      "112   WEBSTER             0             1             0             0   \n",
      "113   WHITLEY             0             0             0             0   \n",
      "114     WOLFE             0             0             0             0   \n",
      "115  WOODFORD             2             0            20             5   \n",
      "\n",
      "     K_count_1994  K_count_1995  K_count_1996  K_count_1997  K_count_1998  \\\n",
      "0               1             1             1             1             2   \n",
      "1               1             0             0             0             2   \n",
      "2               0             0             0             3             0   \n",
      "3               2             1             0             0             1   \n",
      "4               2             5             4             0             1   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "111             0             0             0             0             1   \n",
      "112             0             0             0             0            20   \n",
      "113             0             0             0             0             1   \n",
      "114             0             0             0             0             0   \n",
      "115             6             6             1             1             8   \n",
      "\n",
      "     ...  P_med2010  P_med2011  P_med2012  P_med2013  P_med2014  P_med2015  \\\n",
      "0    ...        0.0        0.0       22.0        0.0      148.0        0.0   \n",
      "1    ...       89.0       66.0       76.0      108.0      108.0       58.0   \n",
      "2    ...      128.0       83.0       76.0       25.0       32.0        0.0   \n",
      "3    ...       34.0       47.0       73.0       44.0        0.0      111.0   \n",
      "4    ...       64.0       33.0       36.0        0.0       54.0       56.0   \n",
      "..   ...        ...        ...        ...        ...        ...        ...   \n",
      "111  ...      224.0     1070.0      170.0      131.0      358.0      169.0   \n",
      "112  ...       19.0        0.0       67.0        0.0       60.0       61.0   \n",
      "113  ...        0.0        0.0        0.0       49.0        9.0     1126.0   \n",
      "114  ...        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "115  ...      309.0      326.0       68.0      530.0       50.0      296.0   \n",
      "\n",
      "     P_med2016  P_med2017  P_med2018  P_med2019  \n",
      "0          0.0       52.0      152.0      206.0  \n",
      "1         47.0      205.0      137.0       51.0  \n",
      "2        169.0       46.0      158.0      101.0  \n",
      "3          0.0        0.0        0.0        0.0  \n",
      "4          0.0       55.0       47.0       12.0  \n",
      "..         ...        ...        ...        ...  \n",
      "111        0.0       75.0        0.0      254.0  \n",
      "112       35.0        0.0        0.0        0.0  \n",
      "113       15.0       38.0      246.0       75.0  \n",
      "114        0.0        0.0        0.0        0.0  \n",
      "115      316.0      374.0      357.0      343.0  \n",
      "\n",
      "[116 rows x 121 columns]\n",
      "total number of records written to CSV: 116 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_warmseason_median = np.round( df_warmseason_nu.pivot_table(index='COUNTY', columns=['YEAR'], values=['P','K'],aggfunc=(np.median,len),fill_value=0),0)\n",
    "print(df_warmseason_median)\n",
    "print(df_warmseason_median.columns)\n",
    "df_warmseason_median.columns = list(map(\"_\".join,df_warmseason_median.columns))\n",
    "df_warmseason_median.columns = df_warmseason_median.columns.str.replace(\"P_median_\", \"P_med\")\n",
    "df_warmseason_median.columns = df_warmseason_median.columns.str.replace(\"P_len\", \"P_count\")\n",
    "df_warmseason_median.columns = df_warmseason_median.columns.str.replace(\"K_median_\",\"K_med\")\n",
    "df_warmseason_median.columns = df_warmseason_median.columns.str.replace(\"K_len\",\"K_count\")\n",
    "print(df_warmseason_median.columns)\n",
    "df_warmseason_median = df_warmseason_median.reset_index()\n",
    "print(df_warmseason_median)\n",
    "file_out_median = fileOut.joinpath('warmseason_median.csv')  # path and filename\n",
    "df_warmseason_median.to_csv(file_out_median, index=False)  # output to csv\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_warmseason_median)),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warm Season Grass, Set categories for P and K values to very low, low, medium, high, very high. Base values from AGR-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories for P\n",
    "    Cat      Title       Break\n",
    "    -------------------------------------\n",
    "    VL       very low    P< 10\n",
    "    L        low         P>= 10 & P<=30\n",
    "    M        medium      P>30 & P<=60\n",
    "    H        high        P>60\n",
    "    \n",
    "#### Categories for K\n",
    "    Cat      Title      Break\n",
    "   --------------------------------------\n",
    "    VL       very low   K< 100\n",
    "    L        low        K>=100 & K <=204\n",
    "    M        medium     K>=205 & K <=300\n",
    "    H        high       K>300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_warmseason_nu['CAT_P'] = ''\n",
    "df_warmseason_nu['CAT_P'] = np.where(df_warmseason_nu.P < 10, 'VL', df_warmseason_nu.CAT_P)\n",
    "df_warmseason_nu['CAT_P'] = np.where(((df_warmseason_nu.P > 10) & (df_warmseason_nu.P <= 30)), 'L', df_warmseason_nu.CAT_P)\n",
    "df_warmseason_nu['CAT_P'] = np.where(((df_warmseason_nu.P > 30) & (df_warmseason_nu.P <= 60)), 'M', df_warmseason_nu.CAT_P)\n",
    "df_warmseason_nu['CAT_P'] = np.where((df_warmseason_nu.P > 60), 'H', df_warmseason_nu.CAT_P)\n",
    " \n",
    "df_warmseason_nu['CAT_K'] = ''\n",
    "df_warmseason_nu['CAT_K'] = np.where(df_warmseason_nu.K < 100, 'VL', df_warmseason_nu.CAT_K)\n",
    "df_warmseason_nu['CAT_K'] = np.where(((df_warmseason_nu.K >= 100) & (df_warmseason_nu.K <= 204)), 'L', df_warmseason_nu.CAT_K)\n",
    "df_warmseason_nu['CAT_K'] = np.where(((df_warmseason_nu.K > 204) & (df_warmseason_nu.K <= 300)), 'M', df_warmseason_nu.CAT_K)\n",
    "df_warmseason_nu['CAT_K'] = np.where((df_warmseason_nu.K > 300), 'H', df_warmseason_nu.CAT_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records written to CSV: 116 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "df_warmseason_p = np.round( df_warmseason_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_P'], values=['P'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "df_warmseason_k = np.round( df_warmseason_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_K'], values=['K'],aggfunc=(np.median,len),fill_value=0),2)\n",
    " \n",
    "df_warmseason_p.columns\n",
    "df_warmseason_k.columns\n",
    "df_warmseason_p.columns = list(map(\"_\".join,df_warmseason_p.columns))\n",
    "df_warmseason_k.columns = list(map(\"_\".join,df_warmseason_k.columns))\n",
    "df_warmseason_p.columns = df_warmseason_p.columns.str.replace(\"P_median_\", \"P_\")\n",
    "df_warmseason_p.columns = df_warmseason_p.columns.str.replace(\"P_len\", \"P_count\")\n",
    "df_warmseason_k.columns = df_warmseason_k.columns.str.replace(\"K_median_\",\"K_\")\n",
    "df_warmseason_k.columns = df_warmseason_k.columns.str.replace(\"K_len\",\"K_count\")\n",
    "df_warmseason_p = df_warmseason_p.reset_index()\n",
    "df_warmseason_k = df_warmseason_k.reset_index()\n",
    "\n",
    "\n",
    "warmseason_level = df_warmseason_p.merge(df_warmseason_k, left_on='COUNTY', right_on='COUNTY')\n",
    "\n",
    "file_out_level = fileOut.joinpath('warmseason_levels.csv')\n",
    "warmseason_level.to_csv(file_out_level, index=False)\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(warmseason_level)),'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cool Season Grass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list to select Cool Season Grass from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bluegrass', 'Cool Season Grass', 'Fescue', 'Fescue/Lespedeza', 'Fescue/Lespedeza (multiple)', 'Fine Fescue', 'Lespedeza', 'Lespedeza/Grass', 'Millet', 'Orchardgrass', 'Perennial Ryegrass', 'Sorghum Sudangrass', 'Sorghum/Sudangras', 'Switchgrass', 'Tall Fescue', 'Timothy']\n"
     ]
    }
   ],
   "source": [
    "coolseason_sel = ['Bluegrass', 'Cool Season Grass', 'Fescue', 'Fescue/Lespedeza', 'Fescue/Lespedeza (multiple)', 'Fine Fescue', 'Lespedeza', 'Lespedeza/Grass', 'Millet', 'Orchardgrass', 'Perennial Ryegrass', 'Sorghum Sudangrass', 'Sorghum/Sudangras', 'Switchgrass', 'Tall Fescue', 'Timothy']\n",
    "coolseason_sel.sort()\n",
    "print(coolseason_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Cool Season Grass from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    FIPS_NO COUNTY  YEAR      P      K\n",
      "187       1  ADAIR  1990   28.0  108.0\n",
      "188       1  ADAIR  1990   88.0  408.0\n",
      "189       1  ADAIR  1990   30.0  533.0\n",
      "190       1  ADAIR  1990   66.0  384.0\n",
      "191       1  ADAIR  1990  140.0  767.0\n"
     ]
    }
   ],
   "source": [
    "df_coolseason = df[df.CROP.isin(coolseason_sel)]\n",
    "df_coolseason_nu = df_coolseason[['FIPS_NO','COUNTY','YEAR','P','K']].copy()\n",
    "print(df_coolseason_nu.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate median by the year for each County."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            K                                               ...      P         \\\n",
      "          len                                               ... median          \n",
      "YEAR     1990 1991 1992 1993 1994 1995 1996 1997 1998 1999  ...   2010   2011   \n",
      "COUNTY                                                      ...                 \n",
      "ADAIR      37   57   43   43   51   49   96   57   75   52  ...   76.0   56.0   \n",
      "ALLEN     135  250  201  272  276  154  130  156  119  133  ...   49.0   44.0   \n",
      "ANDERSON   36    7   12   15   16   25   22   22    9   10  ...  130.0   27.0   \n",
      "BALLARD    10   10   38   12   11   17   17   10   12   12  ...   66.0   22.0   \n",
      "BARREN     82  106  149  201  242  200   90   56   31   39  ...   73.0   70.0   \n",
      "...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
      "WAYNE      55   40   32   52   64   83   77   76   64   76  ...   68.0   69.0   \n",
      "WEBSTER     6   15    6    3    2   15    1   11    5   66  ...   32.0   34.0   \n",
      "WHITLEY     3    3    4    1    1   12   14    8    6   19  ...   36.0   28.0   \n",
      "WOLFE       7    8   12   12    6   15   11    6   14   28  ...   30.0   46.0   \n",
      "WOODFORD   35   42   50   30  102   26   43   61   43   60  ...  226.0  330.0   \n",
      "\n",
      "                                                                  \n",
      "                                                                  \n",
      "YEAR       2012   2013   2014   2015   2016   2017   2018   2019  \n",
      "COUNTY                                                            \n",
      "ADAIR      53.0   54.0   42.0   38.0   41.0   46.0   48.0   55.0  \n",
      "ALLEN      55.0   44.0   66.0   56.0   42.0   51.0   41.0   37.0  \n",
      "ANDERSON   39.0   39.0   40.0   29.0   33.0   48.0   75.0   43.0  \n",
      "BALLARD    82.0   88.0    0.0   46.0   53.0   48.0   52.0   55.0  \n",
      "BARREN     43.0   52.0   47.0   48.0   50.0   46.0   48.0   44.0  \n",
      "...         ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "WAYNE      86.0   65.0   73.0   63.0   50.0   46.0   51.0   60.0  \n",
      "WEBSTER    39.0   18.0   70.0   48.0   31.0   41.0   23.0   14.0  \n",
      "WHITLEY    31.0   47.0   29.0   42.0   28.0   32.0   34.0   28.0  \n",
      "WOLFE      52.0   30.0   41.0   36.0    7.0   17.0   15.0   21.0  \n",
      "WOODFORD  321.0  342.0  326.0  307.0  259.0  301.0  356.0  244.0  \n",
      "\n",
      "[120 rows x 120 columns]\n",
      "MultiIndex([('K',    'len', '1990'),\n",
      "            ('K',    'len', '1991'),\n",
      "            ('K',    'len', '1992'),\n",
      "            ('K',    'len', '1993'),\n",
      "            ('K',    'len', '1994'),\n",
      "            ('K',    'len', '1995'),\n",
      "            ('K',    'len', '1996'),\n",
      "            ('K',    'len', '1997'),\n",
      "            ('K',    'len', '1998'),\n",
      "            ('K',    'len', '1999'),\n",
      "            ...\n",
      "            ('P', 'median', '2010'),\n",
      "            ('P', 'median', '2011'),\n",
      "            ('P', 'median', '2012'),\n",
      "            ('P', 'median', '2013'),\n",
      "            ('P', 'median', '2014'),\n",
      "            ('P', 'median', '2015'),\n",
      "            ('P', 'median', '2016'),\n",
      "            ('P', 'median', '2017'),\n",
      "            ('P', 'median', '2018'),\n",
      "            ('P', 'median', '2019')],\n",
      "           names=[None, None, 'YEAR'], length=120)\n",
      "Index(['K_count_1990', 'K_count_1991', 'K_count_1992', 'K_count_1993',\n",
      "       'K_count_1994', 'K_count_1995', 'K_count_1996', 'K_count_1997',\n",
      "       'K_count_1998', 'K_count_1999',\n",
      "       ...\n",
      "       'P_med2010', 'P_med2011', 'P_med2012', 'P_med2013', 'P_med2014',\n",
      "       'P_med2015', 'P_med2016', 'P_med2017', 'P_med2018', 'P_med2019'],\n",
      "      dtype='object', length=120)\n",
      "       COUNTY  K_count_1990  K_count_1991  K_count_1992  K_count_1993  \\\n",
      "0       ADAIR            37            57            43            43   \n",
      "1       ALLEN           135           250           201           272   \n",
      "2    ANDERSON            36             7            12            15   \n",
      "3     BALLARD            10            10            38            12   \n",
      "4      BARREN            82           106           149           201   \n",
      "..        ...           ...           ...           ...           ...   \n",
      "115     WAYNE            55            40            32            52   \n",
      "116   WEBSTER             6            15             6             3   \n",
      "117   WHITLEY             3             3             4             1   \n",
      "118     WOLFE             7             8            12            12   \n",
      "119  WOODFORD            35            42            50            30   \n",
      "\n",
      "     K_count_1994  K_count_1995  K_count_1996  K_count_1997  K_count_1998  \\\n",
      "0              51            49            96            57            75   \n",
      "1             276           154           130           156           119   \n",
      "2              16            25            22            22             9   \n",
      "3              11            17            17            10            12   \n",
      "4             242           200            90            56            31   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "115            64            83            77            76            64   \n",
      "116             2            15             1            11             5   \n",
      "117             1            12            14             8             6   \n",
      "118             6            15            11             6            14   \n",
      "119           102            26            43            61            43   \n",
      "\n",
      "     ...  P_med2010  P_med2011  P_med2012  P_med2013  P_med2014  P_med2015  \\\n",
      "0    ...       76.0       56.0       53.0       54.0       42.0       38.0   \n",
      "1    ...       49.0       44.0       55.0       44.0       66.0       56.0   \n",
      "2    ...      130.0       27.0       39.0       39.0       40.0       29.0   \n",
      "3    ...       66.0       22.0       82.0       88.0        0.0       46.0   \n",
      "4    ...       73.0       70.0       43.0       52.0       47.0       48.0   \n",
      "..   ...        ...        ...        ...        ...        ...        ...   \n",
      "115  ...       68.0       69.0       86.0       65.0       73.0       63.0   \n",
      "116  ...       32.0       34.0       39.0       18.0       70.0       48.0   \n",
      "117  ...       36.0       28.0       31.0       47.0       29.0       42.0   \n",
      "118  ...       30.0       46.0       52.0       30.0       41.0       36.0   \n",
      "119  ...      226.0      330.0      321.0      342.0      326.0      307.0   \n",
      "\n",
      "     P_med2016  P_med2017  P_med2018  P_med2019  \n",
      "0         41.0       46.0       48.0       55.0  \n",
      "1         42.0       51.0       41.0       37.0  \n",
      "2         33.0       48.0       75.0       43.0  \n",
      "3         53.0       48.0       52.0       55.0  \n",
      "4         50.0       46.0       48.0       44.0  \n",
      "..         ...        ...        ...        ...  \n",
      "115       50.0       46.0       51.0       60.0  \n",
      "116       31.0       41.0       23.0       14.0  \n",
      "117       28.0       32.0       34.0       28.0  \n",
      "118        7.0       17.0       15.0       21.0  \n",
      "119      259.0      301.0      356.0      244.0  \n",
      "\n",
      "[120 rows x 121 columns]\n",
      "total number of records written to CSV: 120 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_coolseason_median = np.round( df_coolseason_nu.pivot_table(index='COUNTY', columns=['YEAR'], values=['P','K'],aggfunc=(np.median,len),fill_value=0),0)\n",
    "print(df_coolseason_median)\n",
    "print(df_coolseason_median.columns)\n",
    "df_coolseason_median.columns = list(map(\"_\".join,df_coolseason_median.columns))\n",
    "df_coolseason_median.columns = df_coolseason_median.columns.str.replace(\"P_median_\", \"P_med\")\n",
    "df_coolseason_median.columns = df_coolseason_median.columns.str.replace(\"P_len\", \"P_count\")\n",
    "df_coolseason_median.columns = df_coolseason_median.columns.str.replace(\"K_median_\",\"K_med\")\n",
    "df_coolseason_median.columns = df_coolseason_median.columns.str.replace(\"K_len\",\"K_count\")\n",
    "print(df_coolseason_median.columns)\n",
    "df_coolseason_median = df_coolseason_median.reset_index()\n",
    "print(df_coolseason_median)\n",
    "file_out_median = fileOut.joinpath('coolseason_median.csv')  # path and filename\n",
    "df_coolseason_median.to_csv(file_out_median, index=False)  # output to csv\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_coolseason_median)),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cool Season Grass, Set categories for P and K values to very low, low, medium, high, very high. Base values from AGR-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories for P\n",
    "    Cat      Title       Break\n",
    "    -------------------------------------\n",
    "    VL       very low    P< 10\n",
    "    L        low         P>= 10 & P<=30\n",
    "    M        medium      P>30 & P<=60\n",
    "    H        high        P>60\n",
    "    \n",
    "#### Categories for K\n",
    "    Cat      Title      Break\n",
    "   --------------------------------------\n",
    "    VL       very low   K< 104\n",
    "    L        low        K>=104 & K <=186\n",
    "    M        medium     K>=187 & K <=300\n",
    "    H        high       K>300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coolseason_nu['CAT_P'] = ''\n",
    "df_coolseason_nu['CAT_P'] = np.where(df_coolseason_nu.P < 10, 'VL', df_coolseason_nu.CAT_P)\n",
    "df_coolseason_nu['CAT_P'] = np.where(((df_coolseason_nu.P > 10) & (df_coolseason_nu.P <= 30)), 'L', df_coolseason_nu.CAT_P)\n",
    "df_coolseason_nu['CAT_P'] = np.where(((df_coolseason_nu.P > 30) & (df_coolseason_nu.P <= 60)), 'M', df_coolseason_nu.CAT_P)\n",
    "df_coolseason_nu['CAT_P'] = np.where((df_coolseason_nu.P > 60), 'H', df_coolseason_nu.CAT_P)\n",
    " \n",
    "df_coolseason_nu['CAT_K'] = ''\n",
    "df_coolseason_nu['CAT_K'] = np.where(df_coolseason_nu.K < 104, 'VL', df_coolseason_nu.CAT_K)\n",
    "df_coolseason_nu['CAT_K'] = np.where(((df_coolseason_nu.K >= 104) & (df_coolseason_nu.K <= 186)), 'L', df_coolseason_nu.CAT_K)\n",
    "df_coolseason_nu['CAT_K'] = np.where(((df_coolseason_nu.K > 186) & (df_coolseason_nu.K <= 300)), 'M', df_coolseason_nu.CAT_K)\n",
    "df_coolseason_nu['CAT_K'] = np.where((df_coolseason_nu.K > 300), 'H', df_coolseason_nu.CAT_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records written to CSV: 120 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "df_coolseason_p = np.round( df_coolseason_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_P'], values=['P'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "df_coolseason_k = np.round( df_coolseason_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_K'], values=['K'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "\n",
    "df_coolseason_p.columns\n",
    "df_coolseason_k.columns\n",
    "df_coolseason_p.columns = list(map(\"_\".join,df_coolseason_p.columns))\n",
    "df_coolseason_k.columns = list(map(\"_\".join,df_coolseason_k.columns))\n",
    "df_coolseason_p.columns = df_coolseason_p.columns.str.replace(\"P_median_\", \"P_\")\n",
    "df_coolseason_p.columns = df_coolseason_p.columns.str.replace(\"P_len\", \"P_count\")\n",
    "df_coolseason_k.columns = df_coolseason_k.columns.str.replace(\"K_median_\",\"K_\")\n",
    "df_coolseason_k.columns = df_coolseason_k.columns.str.replace(\"K_len\",\"K_count\")\n",
    "df_coolseason_p = df_coolseason_p.reset_index()\n",
    "df_coolseason_k = df_coolseason_k.reset_index()\n",
    "\n",
    "coolseason_level = df_coolseason_p.merge(df_coolseason_k, left_on='COUNTY', right_on='COUNTY')\n",
    "\n",
    "file_out_level = fileOut.joinpath('coolseason_levels.csv')\n",
    "coolseason_level.to_csv(file_out_level, index=False)\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(coolseason_level)),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alfalfa Clover mix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list to select Alfalfa Clover mix from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alfalfa', 'Alfalfa/Cool Season', 'Bluegrass/White Clover', 'Clover/Grass', 'Fescue/White Clover', 'Orchardgrass/Red Clover', 'Orchardgrass/White Clover', 'Red Clover', 'Red Clover/Grass', 'Timothy/Red Clover', 'White Clover', 'White Clover/Grass']\n"
     ]
    }
   ],
   "source": [
    "alfalfa_sel = ['Alfalfa', 'Alfalfa/Cool Season', 'Bluegrass/White Clover', 'Clover/Grass', 'Fescue/White Clover', 'Orchardgrass/Red Clover', 'Orchardgrass/White Clover', 'Red Clover', 'Red Clover/Grass', 'Timothy/Red Clover', 'White Clover', 'White Clover/Grass']\n",
    "alfalfa_sel.sort()\n",
    "print(alfalfa_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Alfalfa Clover mixCanfrom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FIPS_NO COUNTY  YEAR      P      K\n",
      "0       1  ADAIR  1990   28.0  158.0\n",
      "1       1  ADAIR  1990   88.0  134.0\n",
      "2       1  ADAIR  1990   70.0  256.0\n",
      "3       1  ADAIR  1990  161.0  611.0\n",
      "4       1  ADAIR  1990  105.0  315.0\n"
     ]
    }
   ],
   "source": [
    "df_alfalfa = df[df.CROP.isin(alfalfa_sel)]\n",
    "df_alfalfa_nu = df_alfalfa[['FIPS_NO','COUNTY','YEAR','P','K']].copy()\n",
    "print(df_alfalfa_nu.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate  median by year for each County."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            K                                               ...      P         \\\n",
      "          len                                               ... median          \n",
      "YEAR     1990 1991 1992 1993 1994 1995 1996 1997 1998 1999  ...   2010   2011   \n",
      "COUNTY                                                      ...                 \n",
      "ADAIR     209  130  130  145   67  115   90   75   66   49  ...   56.0   70.0   \n",
      "ALLEN     115  112  119  116   72   57   23   54   20   34  ...  102.0   56.0   \n",
      "ANDERSON   31   20   22   35   27   22   31   17    6    8  ...   93.0  128.0   \n",
      "BALLARD    38   43   36   54   22   43   33   18   17   23  ...   54.0   28.0   \n",
      "BARREN    337  262  498  474  299  287  146   54   63   42  ...   46.0   56.0   \n",
      "...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
      "WAYNE      75   79  101   85   68   60   51   34   39   30  ...   74.0   42.0   \n",
      "WEBSTER    46   76   74   45   18   10   21   24   11   16  ...   26.0   23.0   \n",
      "WHITLEY   145  114  154  164  133  113   38   25   27   37  ...   55.0   36.0   \n",
      "WOLFE      55   37   26   29   28   33   11   20    2    3  ...   44.0   31.0   \n",
      "WOODFORD   93   82   57   73   98  112  118   78   54   57  ...  313.0  237.0   \n",
      "\n",
      "                                                                 \n",
      "                                                                 \n",
      "YEAR       2012   2013   2014   2015   2016   2017   2018  2019  \n",
      "COUNTY                                                           \n",
      "ADAIR      67.0   36.0   63.0   45.0   50.0   49.0   45.0  50.0  \n",
      "ALLEN      70.0   50.0   58.0   54.0   52.0   52.0  179.0  58.0  \n",
      "ANDERSON   58.0   52.0   78.0   42.0  107.0   90.0   76.0  54.0  \n",
      "BALLARD    64.0   40.0   24.0   42.0   37.0   39.0   60.0  46.0  \n",
      "BARREN     67.0   55.0   52.0   49.0   41.0   31.0   49.0  44.0  \n",
      "...         ...    ...    ...    ...    ...    ...    ...   ...  \n",
      "WAYNE      66.0   62.0   63.0   96.0   56.0   69.0   70.0  66.0  \n",
      "WEBSTER    48.0   27.0   23.0   28.0   13.0   28.0   44.0  50.0  \n",
      "WHITLEY    39.0   42.0   38.0   34.0   22.0   28.0   55.0  31.0  \n",
      "WOLFE      38.0  452.0    0.0    0.0   43.0   40.0  102.0  51.0  \n",
      "WOODFORD  336.0  296.0  211.0  253.0  288.0  234.0  182.0  97.0  \n",
      "\n",
      "[120 rows x 120 columns]\n",
      "MultiIndex([('K',    'len', '1990'),\n",
      "            ('K',    'len', '1991'),\n",
      "            ('K',    'len', '1992'),\n",
      "            ('K',    'len', '1993'),\n",
      "            ('K',    'len', '1994'),\n",
      "            ('K',    'len', '1995'),\n",
      "            ('K',    'len', '1996'),\n",
      "            ('K',    'len', '1997'),\n",
      "            ('K',    'len', '1998'),\n",
      "            ('K',    'len', '1999'),\n",
      "            ...\n",
      "            ('P', 'median', '2010'),\n",
      "            ('P', 'median', '2011'),\n",
      "            ('P', 'median', '2012'),\n",
      "            ('P', 'median', '2013'),\n",
      "            ('P', 'median', '2014'),\n",
      "            ('P', 'median', '2015'),\n",
      "            ('P', 'median', '2016'),\n",
      "            ('P', 'median', '2017'),\n",
      "            ('P', 'median', '2018'),\n",
      "            ('P', 'median', '2019')],\n",
      "           names=[None, None, 'YEAR'], length=120)\n",
      "Index(['K_count_1990', 'K_count_1991', 'K_count_1992', 'K_count_1993',\n",
      "       'K_count_1994', 'K_count_1995', 'K_count_1996', 'K_count_1997',\n",
      "       'K_count_1998', 'K_count_1999',\n",
      "       ...\n",
      "       'P_med2010', 'P_med2011', 'P_med2012', 'P_med2013', 'P_med2014',\n",
      "       'P_med2015', 'P_med2016', 'P_med2017', 'P_med2018', 'P_med2019'],\n",
      "      dtype='object', length=120)\n",
      "       COUNTY  K_count_1990  K_count_1991  K_count_1992  K_count_1993  \\\n",
      "0       ADAIR           209           130           130           145   \n",
      "1       ALLEN           115           112           119           116   \n",
      "2    ANDERSON            31            20            22            35   \n",
      "3     BALLARD            38            43            36            54   \n",
      "4      BARREN           337           262           498           474   \n",
      "..        ...           ...           ...           ...           ...   \n",
      "115     WAYNE            75            79           101            85   \n",
      "116   WEBSTER            46            76            74            45   \n",
      "117   WHITLEY           145           114           154           164   \n",
      "118     WOLFE            55            37            26            29   \n",
      "119  WOODFORD            93            82            57            73   \n",
      "\n",
      "     K_count_1994  K_count_1995  K_count_1996  K_count_1997  K_count_1998  \\\n",
      "0              67           115            90            75            66   \n",
      "1              72            57            23            54            20   \n",
      "2              27            22            31            17             6   \n",
      "3              22            43            33            18            17   \n",
      "4             299           287           146            54            63   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "115            68            60            51            34            39   \n",
      "116            18            10            21            24            11   \n",
      "117           133           113            38            25            27   \n",
      "118            28            33            11            20             2   \n",
      "119            98           112           118            78            54   \n",
      "\n",
      "     ...  P_med2010  P_med2011  P_med2012  P_med2013  P_med2014  P_med2015  \\\n",
      "0    ...       56.0       70.0       67.0       36.0       63.0       45.0   \n",
      "1    ...      102.0       56.0       70.0       50.0       58.0       54.0   \n",
      "2    ...       93.0      128.0       58.0       52.0       78.0       42.0   \n",
      "3    ...       54.0       28.0       64.0       40.0       24.0       42.0   \n",
      "4    ...       46.0       56.0       67.0       55.0       52.0       49.0   \n",
      "..   ...        ...        ...        ...        ...        ...        ...   \n",
      "115  ...       74.0       42.0       66.0       62.0       63.0       96.0   \n",
      "116  ...       26.0       23.0       48.0       27.0       23.0       28.0   \n",
      "117  ...       55.0       36.0       39.0       42.0       38.0       34.0   \n",
      "118  ...       44.0       31.0       38.0      452.0        0.0        0.0   \n",
      "119  ...      313.0      237.0      336.0      296.0      211.0      253.0   \n",
      "\n",
      "     P_med2016  P_med2017  P_med2018  P_med2019  \n",
      "0         50.0       49.0       45.0       50.0  \n",
      "1         52.0       52.0      179.0       58.0  \n",
      "2        107.0       90.0       76.0       54.0  \n",
      "3         37.0       39.0       60.0       46.0  \n",
      "4         41.0       31.0       49.0       44.0  \n",
      "..         ...        ...        ...        ...  \n",
      "115       56.0       69.0       70.0       66.0  \n",
      "116       13.0       28.0       44.0       50.0  \n",
      "117       22.0       28.0       55.0       31.0  \n",
      "118       43.0       40.0      102.0       51.0  \n",
      "119      288.0      234.0      182.0       97.0  \n",
      "\n",
      "[120 rows x 121 columns]\n",
      "total number of records written to CSV: 120 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_alfalfa_median = np.round( df_alfalfa_nu.pivot_table(index='COUNTY', columns=['YEAR'], values=['P','K'],aggfunc=(np.median,len),fill_value=0),0)\n",
    "print(df_alfalfa_median)\n",
    "print(df_alfalfa_median.columns)\n",
    "df_alfalfa_median.columns = list(map(\"_\".join,df_alfalfa_median.columns))\n",
    "df_alfalfa_median.columns = df_alfalfa_median.columns.str.replace(\"P_median_\", \"P_med\")\n",
    "df_alfalfa_median.columns = df_alfalfa_median.columns.str.replace(\"P_len\", \"P_count\")\n",
    "df_alfalfa_median.columns = df_alfalfa_median.columns.str.replace(\"K_median_\",\"K_med\")\n",
    "df_alfalfa_median.columns = df_alfalfa_median.columns.str.replace(\"K_len\",\"K_count\")\n",
    "print(df_alfalfa_median.columns)\n",
    "df_alfalfa_median = df_alfalfa_median.reset_index()\n",
    "print(df_alfalfa_median)\n",
    "file_out_median = fileOut.joinpath('alfalfa_median.csv')  # path and filename\n",
    "df_alfalfa_median.to_csv(file_out_median, index=False)  # output to csv\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_alfalfa_median)),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alfalfa Clover mix, Set categories for P and K values to very low, low, medium, high, very high. Base values from AGR-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories for P\n",
    "    Cat      Title       Break\n",
    "    -------------------------------------\n",
    "    VL       very low    P< 9\n",
    "    L        low         P>= 9 & P<=27\n",
    "    M        medium      P>28 & P<=60\n",
    "    H        high        P>60\n",
    "    \n",
    "#### Categories for K\n",
    "    Cat      Title      Break\n",
    "   --------------------------------------\n",
    "    VL       very low   K< 97\n",
    "    L        low        K>=97 & K <=203\n",
    "    M        medium     K>=204 & K <=296\n",
    "    H        high       K>296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alfalfa_nu['CAT_P'] = ''\n",
    "df_alfalfa_nu['CAT_P'] = np.where(df_alfalfa_nu.P < 9, 'VL', df_alfalfa_nu.CAT_P)\n",
    "df_alfalfa_nu['CAT_P'] = np.where(((df_alfalfa_nu.P >= 9) & (df_alfalfa_nu.P <= 27)), 'L', df_alfalfa_nu.CAT_P)\n",
    "df_alfalfa_nu['CAT_P'] = np.where(((df_alfalfa_nu.P > 27) & (df_alfalfa_nu.P <= 60)), 'M', df_alfalfa_nu.CAT_P)\n",
    "df_alfalfa_nu['CAT_P'] = np.where((df_alfalfa_nu.P > 60), 'H', df_alfalfa_nu.CAT_P)\n",
    "\n",
    "df_alfalfa_nu['CAT_K'] = ''\n",
    "df_alfalfa_nu['CAT_K'] = np.where(df_alfalfa_nu.K < 97, 'VL', df_alfalfa_nu.CAT_K)\n",
    "df_alfalfa_nu['CAT_K'] = np.where(((df_alfalfa_nu.K >= 97) & (df_alfalfa_nu.K <= 203)), 'L', df_alfalfa_nu.CAT_K)\n",
    "df_alfalfa_nu['CAT_K'] = np.where(((df_alfalfa_nu.K > 203) & (df_alfalfa_nu.K <= 296)), 'M', df_alfalfa_nu.CAT_K)\n",
    "df_alfalfa_nu['CAT_K'] = np.where((df_alfalfa_nu.K > 296), 'H', df_alfalfa_nu.CAT_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records written to CSV: 120 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "df_alfalfa_p = np.round( df_alfalfa_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_P'], values=['P'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "df_alfalfa_k = np.round( df_alfalfa_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_K'], values=['K'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "\n",
    "df_alfalfa_p.columns\n",
    "df_alfalfa_k.columns\n",
    "df_alfalfa_p.columns = list(map(\"_\".join,df_alfalfa_p.columns))\n",
    "df_alfalfa_k.columns = list(map(\"_\".join,df_alfalfa_k.columns))\n",
    "df_alfalfa_p.columns = df_alfalfa_p.columns.str.replace(\"P_median_\", \"P_\")\n",
    "df_alfalfa_p.columns = df_alfalfa_p.columns.str.replace(\"P_len\", \"P_count\")\n",
    "df_alfalfa_k.columns = df_alfalfa_k.columns.str.replace(\"K_median_\",\"K_\")\n",
    "df_alfalfa_k.columns = df_alfalfa_k.columns.str.replace(\"K_len\",\"K_count\")\n",
    "df_alfalfa_p = df_alfalfa_p.reset_index()\n",
    "df_alfalfa_k = df_alfalfa_k.reset_index()\n",
    "\n",
    "alfalfa_level = df_alfalfa_p.merge(df_alfalfa_k, left_on='COUNTY', right_on='COUNTY')\n",
    "\n",
    "file_out_level = fileOut.joinpath('alfalfa_levels.csv')\n",
    "alfalfa_level.to_csv(file_out_level, index=False)\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(alfalfa_level)),'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
