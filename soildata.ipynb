{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangling Soil Test data from University of Kentucky's Soil Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Microsoft Access to export data into CSV text file with FIPS code add and quary to select just County by County name. Export as soildata_fips.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import profiling to get quick analysis of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets\n",
    "from pandas_profiling import ProfileReport\n",
    "# from pandas_profiling.utils.cache import cache_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set file path to get data to work on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = Path('data')\n",
    "fileOut = Path('project-data')\n",
    "file_soil = filePath.joinpath('soildata_fips.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soil = pd.read_csv(file_soil, dtype='str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that file is read into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1190126 entries, 0 to 1190125\n",
      "Data columns (total 14 columns):\n",
      "FIPS_NO    1190126 non-null object\n",
      "YEAR       1190126 non-null object\n",
      "FM         1190052 non-null object\n",
      "COUNTY     1190126 non-null object\n",
      "AREA       1190126 non-null object\n",
      "PH         1187607 non-null object\n",
      "BUPH       1056246 non-null object\n",
      "P          1187473 non-null object\n",
      "K          1187494 non-null object\n",
      "CA         969266 non-null object\n",
      "MG         969725 non-null object\n",
      "ZN         967041 non-null object\n",
      "ACRES      525128 non-null object\n",
      "CROP       1183431 non-null object\n",
      "dtypes: object(14)\n",
      "memory usage: 127.1+ MB\n"
     ]
    }
   ],
   "source": [
    "soil.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS_NO</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>FM</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>AREA</th>\n",
       "      <th>PH</th>\n",
       "      <th>BUPH</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>CA</th>\n",
       "      <th>MG</th>\n",
       "      <th>ZN</th>\n",
       "      <th>ACRES</th>\n",
       "      <th>CROP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1190121</th>\n",
       "      <td>239.00</td>\n",
       "      <td>2019.00</td>\n",
       "      <td>A</td>\n",
       "      <td>WOODFORD</td>\n",
       "      <td>Bluegrass</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.30</td>\n",
       "      <td>62.00</td>\n",
       "      <td>319.00</td>\n",
       "      <td>1489.00</td>\n",
       "      <td>223.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Wildlife Food Plot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190122</th>\n",
       "      <td>239.00</td>\n",
       "      <td>2019.00</td>\n",
       "      <td>A</td>\n",
       "      <td>WOODFORD</td>\n",
       "      <td>Bluegrass</td>\n",
       "      <td>5.90</td>\n",
       "      <td>6.70</td>\n",
       "      <td>46.00</td>\n",
       "      <td>257.00</td>\n",
       "      <td>5247.00</td>\n",
       "      <td>268.00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Wildlife Food Plot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190123</th>\n",
       "      <td>239.00</td>\n",
       "      <td>2019.00</td>\n",
       "      <td>A</td>\n",
       "      <td>WOODFORD</td>\n",
       "      <td>Bluegrass</td>\n",
       "      <td>6.80</td>\n",
       "      <td>7.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>243.00</td>\n",
       "      <td>12047.00</td>\n",
       "      <td>281.00</td>\n",
       "      <td>1.20</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Wildlife Food Plot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190124</th>\n",
       "      <td>239.00</td>\n",
       "      <td>2019.00</td>\n",
       "      <td>A</td>\n",
       "      <td>WOODFORD</td>\n",
       "      <td>Bluegrass</td>\n",
       "      <td>5.30</td>\n",
       "      <td>6.60</td>\n",
       "      <td>60.00</td>\n",
       "      <td>407.00</td>\n",
       "      <td>3304.00</td>\n",
       "      <td>396.00</td>\n",
       "      <td>2.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wildlife Food Plot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190125</th>\n",
       "      <td>239.00</td>\n",
       "      <td>2019.00</td>\n",
       "      <td>A</td>\n",
       "      <td>WOODFORD</td>\n",
       "      <td>Bluegrass</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.30</td>\n",
       "      <td>59.00</td>\n",
       "      <td>377.00</td>\n",
       "      <td>4341.00</td>\n",
       "      <td>349.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Wildlife Food Plot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        FIPS_NO     YEAR FM    COUNTY       AREA    PH  BUPH      P       K  \\\n",
       "1190121  239.00  2019.00  A  WOODFORD  Bluegrass  5.00  6.30  62.00  319.00   \n",
       "1190122  239.00  2019.00  A  WOODFORD  Bluegrass  5.90  6.70  46.00  257.00   \n",
       "1190123  239.00  2019.00  A  WOODFORD  Bluegrass  6.80  7.00  75.00  243.00   \n",
       "1190124  239.00  2019.00  A  WOODFORD  Bluegrass  5.30  6.60  60.00  407.00   \n",
       "1190125  239.00  2019.00  A  WOODFORD  Bluegrass  5.00  6.30  59.00  377.00   \n",
       "\n",
       "               CA      MG    ZN ACRES                CROP  \n",
       "1190121   1489.00  223.00  3.50  1.00  Wildlife Food Plot  \n",
       "1190122   5247.00  268.00  2.10  2.00  Wildlife Food Plot  \n",
       "1190123  12047.00  281.00  1.20  2.00  Wildlife Food Plot  \n",
       "1190124   3304.00  396.00  2.80   NaN  Wildlife Food Plot  \n",
       "1190125   4341.00  349.00  2.00  1.50  Wildlife Food Plot  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soil.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove decimal from FIPS_NO and Year, can't convert to an integer because of pivot table columns later in processing. Convert PH, BUPH, P, K, and Acres into Float type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = soil.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1190126 entries, 0 to 1190125\n",
      "Data columns (total 14 columns):\n",
      "FIPS_NO    1190126 non-null object\n",
      "YEAR       1190126 non-null object\n",
      "FM         1190052 non-null object\n",
      "COUNTY     1190126 non-null object\n",
      "AREA       1190126 non-null object\n",
      "PH         1187607 non-null float64\n",
      "BUPH       1056246 non-null float64\n",
      "P          1187473 non-null float64\n",
      "K          1187494 non-null float64\n",
      "CA         969266 non-null object\n",
      "MG         969725 non-null object\n",
      "ZN         967041 non-null object\n",
      "ACRES      525128 non-null float64\n",
      "CROP       1183431 non-null object\n",
      "dtypes: float64(5), object(9)\n",
      "memory usage: 127.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.FIPS_NO = df.FIPS_NO.astype('str').replace('\\.00','',regex=True)\n",
    "df.YEAR = df.YEAR.astype('str').replace('\\.00','',regex=True)\n",
    "df.PH = df.PH.astype('float')\n",
    "df.BUPH = df.BUPH.astype('float')\n",
    "df.P = df.P.astype('float')\n",
    "df.K = df.K.astype('float')\n",
    "df.ACRES = df.ACRES.astype('float')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1190126 entries, 0 to 1190125\n",
      "Data columns (total 14 columns):\n",
      "FIPS_NO    1190126 non-null object\n",
      "YEAR       1190126 non-null object\n",
      "FM         1190052 non-null object\n",
      "COUNTY     1190126 non-null object\n",
      "AREA       1190126 non-null object\n",
      "PH         1187607 non-null float64\n",
      "BUPH       1056246 non-null float64\n",
      "P          1187473 non-null float64\n",
      "K          1187494 non-null float64\n",
      "CA         969266 non-null object\n",
      "MG         969725 non-null object\n",
      "ZN         967041 non-null object\n",
      "ACRES      525128 non-null float64\n",
      "CROP       1183431 non-null object\n",
      "dtypes: float64(5), object(9)\n",
      "memory usage: 127.1+ MB\n",
      "  FIPS_NO  YEAR FM COUNTY                AREA    PH  BUPH      P      K  \\\n",
      "0       1  1990  A  ADAIR  Eastern Pennyroyal  7.15  7.23   28.0  158.0   \n",
      "1       1  1990  A  ADAIR  Eastern Pennyroyal  6.95  7.22   88.0  134.0   \n",
      "2       1  1990  A  ADAIR  Eastern Pennyroyal  6.26  6.94   70.0  256.0   \n",
      "3       1  1990  A  ADAIR  Eastern Pennyroyal  5.67  6.69  161.0  611.0   \n",
      "4       1  1990  A  ADAIR  Eastern Pennyroyal  7.26  7.47  105.0  315.0   \n",
      "\n",
      "        CA      MG   ZN  ACRES     CROP  \n",
      "0      NaN     NaN  NaN   18.0  Alfalfa  \n",
      "1  2890.00  159.00  NaN   15.0  Alfalfa  \n",
      "2      NaN     NaN  NaN   16.0  Alfalfa  \n",
      "3      NaN     NaN  NaN    6.0  Alfalfa  \n",
      "4  2940.00  137.00  NaN   25.0  Alfalfa  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS_NO</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>FM</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>AREA</th>\n",
       "      <th>PH</th>\n",
       "      <th>BUPH</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>CA</th>\n",
       "      <th>MG</th>\n",
       "      <th>ZN</th>\n",
       "      <th>ACRES</th>\n",
       "      <th>CROP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1190121</th>\n",
       "      <td>239</td>\n",
       "      <td>2019</td>\n",
       "      <td>A</td>\n",
       "      <td>WOODFORD</td>\n",
       "      <td>Bluegrass</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>62.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>1489.00</td>\n",
       "      <td>223.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Wildlife Food Plot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190122</th>\n",
       "      <td>239</td>\n",
       "      <td>2019</td>\n",
       "      <td>A</td>\n",
       "      <td>WOODFORD</td>\n",
       "      <td>Bluegrass</td>\n",
       "      <td>5.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>46.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>5247.00</td>\n",
       "      <td>268.00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Wildlife Food Plot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190123</th>\n",
       "      <td>239</td>\n",
       "      <td>2019</td>\n",
       "      <td>A</td>\n",
       "      <td>WOODFORD</td>\n",
       "      <td>Bluegrass</td>\n",
       "      <td>6.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>12047.00</td>\n",
       "      <td>281.00</td>\n",
       "      <td>1.20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Wildlife Food Plot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190124</th>\n",
       "      <td>239</td>\n",
       "      <td>2019</td>\n",
       "      <td>A</td>\n",
       "      <td>WOODFORD</td>\n",
       "      <td>Bluegrass</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6.6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>3304.00</td>\n",
       "      <td>396.00</td>\n",
       "      <td>2.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wildlife Food Plot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190125</th>\n",
       "      <td>239</td>\n",
       "      <td>2019</td>\n",
       "      <td>A</td>\n",
       "      <td>WOODFORD</td>\n",
       "      <td>Bluegrass</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>59.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>4341.00</td>\n",
       "      <td>349.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Wildlife Food Plot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        FIPS_NO  YEAR FM    COUNTY       AREA   PH  BUPH     P      K  \\\n",
       "1190121     239  2019  A  WOODFORD  Bluegrass  5.0   6.3  62.0  319.0   \n",
       "1190122     239  2019  A  WOODFORD  Bluegrass  5.9   6.7  46.0  257.0   \n",
       "1190123     239  2019  A  WOODFORD  Bluegrass  6.8   7.0  75.0  243.0   \n",
       "1190124     239  2019  A  WOODFORD  Bluegrass  5.3   6.6  60.0  407.0   \n",
       "1190125     239  2019  A  WOODFORD  Bluegrass  5.0   6.3  59.0  377.0   \n",
       "\n",
       "               CA      MG    ZN  ACRES                CROP  \n",
       "1190121   1489.00  223.00  3.50    1.0  Wildlife Food Plot  \n",
       "1190122   5247.00  268.00  2.10    2.0  Wildlife Food Plot  \n",
       "1190123  12047.00  281.00  1.20    2.0  Wildlife Food Plot  \n",
       "1190124   3304.00  396.00  2.80    NaN  Wildlife Food Plot  \n",
       "1190125   4341.00  349.00  2.00    1.5  Wildlife Food Plot  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "print(df.head())\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create profile report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop CA, MG, ZN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['CA','MG','ZN'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1190126 entries, 0 to 1190125\n",
      "Data columns (total 11 columns):\n",
      "FIPS_NO    1190126 non-null object\n",
      "YEAR       1190126 non-null object\n",
      "FM         1190052 non-null object\n",
      "COUNTY     1190126 non-null object\n",
      "AREA       1190126 non-null object\n",
      "PH         1187607 non-null float64\n",
      "BUPH       1056246 non-null float64\n",
      "P          1187473 non-null float64\n",
      "K          1187494 non-null float64\n",
      "ACRES      525128 non-null float64\n",
      "CROP       1183431 non-null object\n",
      "dtypes: float64(5), object(6)\n",
      "memory usage: 99.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the maximum and minimum values for P and K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max P = 21658.0 min P = -9.0\n",
      "max K 60452.0 min K = -26.0\n"
     ]
    }
   ],
   "source": [
    "print(\"max P =\", df.P.max(), \"min P =\",df.P.min())\n",
    "print(\"max K\" , df.K.max(), \"min K =\", df.K.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove values less than zero and above 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df['P'] < 0)]\n",
    "df = df[~(df['K'] < 0)]\n",
    "df = df[~(df['P'] >= 9999)]\n",
    "df = df[~(df['K'] >= 9999)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max P = 9778.0 min P = 0.0\n",
      "max K 9964.0 min K = 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"max P =\", df.P.max(), \"min P =\",df.P.min())\n",
    "print(\"max K\" , df.K.max(), \"min K =\", df.K.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select agricultural \"A\" and commercial \"C\" types from FM column. Append df together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.loc[(df['FM'] == 'A')]\n",
    "df2 = df.loc[(df['FM'] == 'C')]\n",
    "df3 = df1.append(df2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 941637 entries, 0 to 1190125\n",
      "Data columns (total 11 columns):\n",
      "FIPS_NO    941637 non-null object\n",
      "YEAR       941637 non-null object\n",
      "FM         941637 non-null object\n",
      "COUNTY     941637 non-null object\n",
      "AREA       941637 non-null object\n",
      "PH         940288 non-null float64\n",
      "BUPH       836405 non-null float64\n",
      "P          940284 non-null float64\n",
      "K          940295 non-null float64\n",
      "ACRES      511570 non-null float64\n",
      "CROP       938347 non-null object\n",
      "dtypes: float64(5), object(6)\n",
      "memory usage: 86.2+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21910 entries, 153 to 1190012\n",
      "Data columns (total 11 columns):\n",
      "FIPS_NO    21910 non-null object\n",
      "YEAR       21910 non-null object\n",
      "FM         21910 non-null object\n",
      "COUNTY     21910 non-null object\n",
      "AREA       21910 non-null object\n",
      "PH         21882 non-null float64\n",
      "BUPH       20540 non-null float64\n",
      "P          21881 non-null float64\n",
      "K          21883 non-null float64\n",
      "ACRES      7362 non-null float64\n",
      "CROP       21858 non-null object\n",
      "dtypes: float64(5), object(6)\n",
      "memory usage: 2.0+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 963547 entries, 0 to 963546\n",
      "Data columns (total 11 columns):\n",
      "FIPS_NO    963547 non-null object\n",
      "YEAR       963547 non-null object\n",
      "FM         963547 non-null object\n",
      "COUNTY     963547 non-null object\n",
      "AREA       963547 non-null object\n",
      "PH         962170 non-null float64\n",
      "BUPH       856945 non-null float64\n",
      "P          962165 non-null float64\n",
      "K          962178 non-null float64\n",
      "ACRES      518932 non-null float64\n",
      "CROP       960205 non-null object\n",
      "dtypes: float64(5), object(6)\n",
      "memory usage: 80.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df1.info())\n",
    "print(df2.info())\n",
    "print(df3.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop null values from CROP, P, K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 958826 entries, 0 to 963546\n",
      "Data columns (total 11 columns):\n",
      "FIPS_NO    958826 non-null object\n",
      "YEAR       958826 non-null object\n",
      "FM         958826 non-null object\n",
      "COUNTY     958826 non-null object\n",
      "AREA       958826 non-null object\n",
      "PH         958813 non-null float64\n",
      "BUPH       854104 non-null float64\n",
      "P          958826 non-null float64\n",
      "K          958826 non-null float64\n",
      "ACRES      517097 non-null float64\n",
      "CROP       958826 non-null object\n",
      "dtypes: float64(5), object(6)\n",
      "memory usage: 87.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df3.drop(df3[df3['CROP'].isnull()].index, inplace=True)\n",
    "df3.drop(df3[df3['P'].isnull()].index, inplace=True)\n",
    "df3.drop(df3[df3['K'].isnull()].index, inplace=True)\n",
    "df3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resort and index dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS_NO</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>AREA</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>CROP</th>\n",
       "      <th>ACRES</th>\n",
       "      <th>PH</th>\n",
       "      <th>BUPH</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>Eastern Pennyroyal</td>\n",
       "      <td>1990</td>\n",
       "      <td>Alfalfa</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.15</td>\n",
       "      <td>7.23</td>\n",
       "      <td>28.0</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>Eastern Pennyroyal</td>\n",
       "      <td>1990</td>\n",
       "      <td>Alfalfa</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.95</td>\n",
       "      <td>7.22</td>\n",
       "      <td>88.0</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>Eastern Pennyroyal</td>\n",
       "      <td>1990</td>\n",
       "      <td>Alfalfa</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.26</td>\n",
       "      <td>6.94</td>\n",
       "      <td>70.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>Eastern Pennyroyal</td>\n",
       "      <td>1990</td>\n",
       "      <td>Alfalfa</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.67</td>\n",
       "      <td>6.69</td>\n",
       "      <td>161.0</td>\n",
       "      <td>611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>Eastern Pennyroyal</td>\n",
       "      <td>1990</td>\n",
       "      <td>Alfalfa</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.26</td>\n",
       "      <td>7.47</td>\n",
       "      <td>105.0</td>\n",
       "      <td>315.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FIPS_NO COUNTY                AREA  YEAR     CROP  ACRES    PH  BUPH      P  \\\n",
       "0       1  ADAIR  Eastern Pennyroyal  1990  Alfalfa   18.0  7.15  7.23   28.0   \n",
       "1       1  ADAIR  Eastern Pennyroyal  1990  Alfalfa   15.0  6.95  7.22   88.0   \n",
       "2       1  ADAIR  Eastern Pennyroyal  1990  Alfalfa   16.0  6.26  6.94   70.0   \n",
       "3       1  ADAIR  Eastern Pennyroyal  1990  Alfalfa    6.0  5.67  6.69  161.0   \n",
       "4       1  ADAIR  Eastern Pennyroyal  1990  Alfalfa   25.0  7.26  7.47  105.0   \n",
       "\n",
       "       K  \n",
       "0  158.0  \n",
       "1  134.0  \n",
       "2  256.0  \n",
       "3  611.0  \n",
       "4  315.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df3[['FIPS_NO','COUNTY','AREA','YEAR','CROP','ACRES', 'PH', 'BUPH', 'P', 'K', ]]\n",
    "order_by_cols = ['FIPS_NO','YEAR','CROP']\n",
    "df = df.sort_values(by=order_by_cols, ascending=[True,True,True]).copy()\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save clean CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'data\\clean_soil_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 958826 entries, 0 to 958825\n",
      "Data columns (total 10 columns):\n",
      "FIPS_NO    958826 non-null object\n",
      "COUNTY     958826 non-null object\n",
      "AREA       958826 non-null object\n",
      "YEAR       958826 non-null object\n",
      "CROP       958826 non-null object\n",
      "ACRES      517097 non-null float64\n",
      "PH         958813 non-null float64\n",
      "BUPH       854104 non-null float64\n",
      "P          958826 non-null float64\n",
      "K          958826 non-null float64\n",
      "dtypes: float64(5), object(5)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find unique CROP types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alfalfa', 'Alfalfa/Cool Season', 'Burley Tobacco', 'Clover/Grass',\n",
       "       'Cole Crops (broccoli, etc.)', 'Corn', 'Corn, Sweet', 'Cucumbers',\n",
       "       'Fescue', 'No Info Given', 'Orchardgrass', 'Other Vegetables',\n",
       "       'Peppers (bell & pimento)', 'Red Clover', 'Timothy', 'Tomatoes',\n",
       "       'White Clover', 'White Clover/Grass', 'Rye', 'Soybeans',\n",
       "       'Tobacco Beds', 'Wheat', 'Oats', 'Red Clover/Grass',\n",
       "       'Warm Season Grass', 'Blueberries', 'Fescue/Lespedeza (multiple)',\n",
       "       'Forage Sorghum', 'Strawberries', 'Cool Season Grass',\n",
       "       'Evergreen Shrubs, Broadleaved', 'Sudangrass',\n",
       "       'Timothy/Red Clover', 'Lespedeza', 'Other Fruit & Nuts',\n",
       "       'Small Grains/Corn', 'Small Grains/Soybeans', 'Squash & Pumpkins',\n",
       "       'Birdsfoot Trefoil', 'Grain Sorghum', 'Lespedeza/Grass', 'Annuals',\n",
       "       'Fescue/Lespedeza', 'Forage Crops', 'Millet',\n",
       "       'Orchardgrass/Red Clover', 'Apples', 'Grapes', 'Peaches',\n",
       "       'Small Grains', 'Bermudagrass, common', 'Sweet Potatoes', 'Other',\n",
       "       'Azaleas', 'Brambles', 'Wheat/Soybeans', 'Potatoes',\n",
       "       'Warm Season Annual Grass', 'Bermudagrass, improved', 'Sunflower',\n",
       "       'Fescue/White Clover', 'Sorghum/Sudangras', 'Cherries, Tart',\n",
       "       'Pears', 'Watermelons', 'Root Crops (beets, carrots,etc.)',\n",
       "       'Switchgrass', 'Muskmelons (cantaloupes)',\n",
       "       'Native Grassland Restoration', 'Wildlife Food Plot',\n",
       "       'Beans (snap,dry,lima,etc.)', 'Greens (collards, kale, etc.)',\n",
       "       'Okra', 'Asparagus', 'Eggplant', 'Hemp', 'Rhubarb',\n",
       "       'Sorghum Sudangrass', 'Crownvetch', 'Canola/Soybeans',\n",
       "       'Dark Tobacco', 'Grain Crops (multiple)', 'Bluestem', 'Walnuts',\n",
       "       'Indiangrass', 'Warm Season Native Grass', 'Deciduous Trees',\n",
       "       'Conifers (not pines or junipers)', 'Conifers, pines', 'Pecans',\n",
       "       'Hollies', 'Orchardgrass/White Clover', 'Perrenials (not bulbs)',\n",
       "       'Bluegrass', 'Onions (green & bulb)', 'Canola', 'Rye/Soybeans',\n",
       "       'Buffer or Filter Strip', 'Triticale', 'Bulbs', 'Other Flowers',\n",
       "       'Other Nursery plants', 'Deciduous Shrubs',\n",
       "       'Evergreen Trees, Broadleaved', 'Oats/Soybeans',\n",
       "       'Currants and Gooseberries', 'Barley', 'Bluegrass/White Clover',\n",
       "       'Side-oats grama', 'Wheat/Corn', 'Rhododendrons', 'Plums',\n",
       "       'Cool Peas', 'Southern Peas', 'Barley/Soybeans', 'Unknown',\n",
       "       'Conifers, junipers', 'Triticale/Soybeans'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "croptypes = df.CROP.unique()\n",
    "croptypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select CROP based on AGR-1 crop types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list to select Corn from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Corn', 'Small Grains/Corn', 'Wheat/Corn']\n"
     ]
    }
   ],
   "source": [
    "corn_sel = ['Corn','Small Grains/Corn','Wheat/Corn']\n",
    "corn_sel.sort()\n",
    "print(corn_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe for nutrients phosphorus (P) and potassium (K)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    FIPS_NO COUNTY  YEAR     P      K\n",
      "155       1  ADAIR  1990  37.0  146.0\n",
      "156       1  ADAIR  1990  93.0  105.0\n",
      "157       1  ADAIR  1990  25.0  252.0\n",
      "158       1  ADAIR  1990  24.0  121.0\n",
      "159       1  ADAIR  1990  92.0  283.0\n"
     ]
    }
   ],
   "source": [
    "df_corn = df[df.CROP.isin(corn_sel)]\n",
    "df_corn_nu = df_corn[['FIPS_NO','COUNTY','YEAR','P','K']].copy()\n",
    "print(df_corn_nu.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corn,  Set categories for P and K values to very low, low, medium, high, very high. Base values from AGR-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories for P\n",
    "        Cat      Title       Break\n",
    "        -------------------------------------\n",
    "        VL       very low    P<= 5\n",
    "        L        low         P>5 & P<=27\n",
    "        M        medium      P>27 & P<=60\n",
    "        H        high        P>60\n",
    "\n",
    "#### Categories for K\n",
    "        Cat      Title      Break\n",
    "       --------------------------------------\n",
    "        VL       very low   K< 100\n",
    "        L        low        K>=100 & K <=190\n",
    "        M        medium     K>=191 & K <=300\n",
    "        H        high       K>=301 & K <=420\n",
    "        VH       very high  K>420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS_NO</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>CAT_P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>1990</td>\n",
       "      <td>37.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>1990</td>\n",
       "      <td>93.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>1990</td>\n",
       "      <td>25.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>1990</td>\n",
       "      <td>24.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>1990</td>\n",
       "      <td>92.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    FIPS_NO COUNTY  YEAR     P      K CAT_P\n",
       "155       1  ADAIR  1990  37.0  146.0     M\n",
       "156       1  ADAIR  1990  93.0  105.0     H\n",
       "157       1  ADAIR  1990  25.0  252.0     L\n",
       "158       1  ADAIR  1990  24.0  121.0     L\n",
       "159       1  ADAIR  1990  92.0  283.0     H"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corn_nu['CAT_P'] = ''\n",
    "df_corn_nu['CAT_P'] = np.where(df_corn_nu.P <= 5, 'VL', df_corn_nu.CAT_P)\n",
    "df_corn_nu['CAT_P'] = np.where(((df_corn_nu.P > 5) & (df_corn_nu.P <= 27)), 'L', df_corn_nu.CAT_P)\n",
    "df_corn_nu['CAT_P'] = np.where(((df_corn_nu.P > 27) & (df_corn_nu.P <= 60)), 'M', df_corn_nu.CAT_P)\n",
    "df_corn_nu['CAT_P'] = np.where((df_corn_nu.P > 60), 'H', df_corn_nu.CAT_P)\n",
    "df_corn_nu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS_NO</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>CAT_P</th>\n",
       "      <th>CAT_K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>1990</td>\n",
       "      <td>37.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>M</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>1990</td>\n",
       "      <td>93.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>H</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>1990</td>\n",
       "      <td>25.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>L</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>1990</td>\n",
       "      <td>24.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>L</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>1990</td>\n",
       "      <td>92.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    FIPS_NO COUNTY  YEAR     P      K CAT_P CAT_K\n",
       "155       1  ADAIR  1990  37.0  146.0     M     L\n",
       "156       1  ADAIR  1990  93.0  105.0     H     L\n",
       "157       1  ADAIR  1990  25.0  252.0     L     M\n",
       "158       1  ADAIR  1990  24.0  121.0     L     L\n",
       "159       1  ADAIR  1990  92.0  283.0     H     M"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corn_nu['CAT_K'] = ''\n",
    "df_corn_nu['CAT_K'] = np.where(df_corn_nu.K <= 100, 'VL', df_corn_nu.CAT_K)\n",
    "df_corn_nu['CAT_K'] = np.where(((df_corn_nu.K > 100) & (df_corn_nu.K <= 190)), 'L', df_corn_nu.CAT_K)\n",
    "df_corn_nu['CAT_K'] = np.where(((df_corn_nu.K > 190) & (df_corn_nu.K <= 300)), 'M', df_corn_nu.CAT_K)\n",
    "df_corn_nu['CAT_K'] = np.where(((df_corn_nu.K > 300) & (df_corn_nu.K <= 420)), 'H', df_corn_nu.CAT_K)\n",
    "df_corn_nu['CAT_K'] = np.where((df_corn_nu.K > 420), 'VH', df_corn_nu.CAT_K)\n",
    "df_corn_nu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create pivot table to sort categories by year and County for each nutrient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get median value of P and K nutrient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            P                                     ...                         \\\n",
      "          len                                     ... median                   \n",
      "YEAR     1990            1991           1992      ...   2017      2018         \n",
      "CAT_P       H   L   M VL    H  L   M VL    H   L  ...      M VL      H     L   \n",
      "COUNTY                                            ...                          \n",
      "ADAIR      15   4  11  0   24  7   4  0   18   4  ...   44.0  0  140.0  20.0   \n",
      "ALLEN       7  10   6  0   19  4  18  0    9   5  ...   36.0  0  116.0   0.0   \n",
      "ANDERSON   10   3   1  1   18  3   9  0    9   1  ...    0.0  0  147.0   8.0   \n",
      "BALLARD    69   0  12  0   33  4  28  0   51   2  ...   42.0  0   74.0   0.0   \n",
      "BARREN     66   9  26  0   86  9  45  0  114  12  ...   58.0  0  108.0  24.0   \n",
      "\n",
      "                                         \n",
      "                                         \n",
      "YEAR                2019                 \n",
      "CAT_P        M VL      H     L     M VL  \n",
      "COUNTY                                   \n",
      "ADAIR     42.0  0  104.0  24.0  43.0  2  \n",
      "ALLEN     34.0  0  312.0  16.0  38.0  0  \n",
      "ANDERSON  30.0  0  248.0   0.0  51.0  0  \n",
      "BALLARD   37.0  0   74.0  24.0  46.0  0  \n",
      "BARREN    45.0  0  133.0  20.0  45.0  2  \n",
      "\n",
      "[5 rows x 240 columns]\n",
      "            K                                     ...                       \\\n",
      "          len                                     ... median                 \n",
      "YEAR     1990                1991                 ...   2018                 \n",
      "CAT_K       H   L   M  VH VL    H   L   M  VH VL  ...      H      L      M   \n",
      "COUNTY                                            ...                        \n",
      "ADAIR       3  12  12   1  2    5  12  12   4  2  ...  346.0  156.0  237.0   \n",
      "ALLEN       2   6  13   1  1   11   7  18   5  0  ...    0.0    0.0  234.0   \n",
      "ANDERSON    4   5   3   2  1    9   6  11   4  0  ...    0.0  174.0  216.0   \n",
      "BALLARD    20  10  48   3  0   11  17  35   2  0  ...  309.0  168.0  222.0   \n",
      "BARREN     32  16  26  26  1   35  23  62  19  1  ...  339.0  184.0  243.0   \n",
      "\n",
      "                                                         \n",
      "                                                         \n",
      "YEAR                    2019                             \n",
      "CAT_K        VH    VL      H      L      M     VH    VL  \n",
      "COUNTY                                                   \n",
      "ADAIR     455.0  91.0  336.0  160.0  234.0    0.0  78.0  \n",
      "ALLEN       0.0  95.0    0.0  140.0  217.0    0.0  86.0  \n",
      "ANDERSON  502.0  96.0    0.0  181.0  209.0  543.0   0.0  \n",
      "BALLARD   509.0   0.0  387.0  164.0  211.0    0.0   0.0  \n",
      "BARREN    451.0   0.0  358.0  162.0  219.0  422.0  90.0  \n",
      "\n",
      "[5 rows x 300 columns]\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "df_corn_p = np.round( df_corn_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_P'], values=['P'],aggfunc=(np.median,len),fill_value=0),0)\n",
    "df_corn_k = np.round( df_corn_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_K'], values=['K'],aggfunc=(np.median,len),fill_value=0),0)\n",
    "print(df_corn_p.head())\n",
    "print(df_corn_k.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpivot table and save to CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create column names from pivot table data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex([('P',    'len', '1990',  'H'),\n",
      "            ('P',    'len', '1990',  'L'),\n",
      "            ('P',    'len', '1990',  'M'),\n",
      "            ('P',    'len', '1990', 'VL'),\n",
      "            ('P',    'len', '1991',  'H'),\n",
      "            ('P',    'len', '1991',  'L'),\n",
      "            ('P',    'len', '1991',  'M'),\n",
      "            ('P',    'len', '1991', 'VL'),\n",
      "            ('P',    'len', '1992',  'H'),\n",
      "            ('P',    'len', '1992',  'L'),\n",
      "            ...\n",
      "            ('P', 'median', '2017',  'M'),\n",
      "            ('P', 'median', '2017', 'VL'),\n",
      "            ('P', 'median', '2018',  'H'),\n",
      "            ('P', 'median', '2018',  'L'),\n",
      "            ('P', 'median', '2018',  'M'),\n",
      "            ('P', 'median', '2018', 'VL'),\n",
      "            ('P', 'median', '2019',  'H'),\n",
      "            ('P', 'median', '2019',  'L'),\n",
      "            ('P', 'median', '2019',  'M'),\n",
      "            ('P', 'median', '2019', 'VL')],\n",
      "           names=[None, None, 'YEAR', 'CAT_P'], length=240)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiIndex([('K',    'len', '1990',  'H'),\n",
       "            ('K',    'len', '1990',  'L'),\n",
       "            ('K',    'len', '1990',  'M'),\n",
       "            ('K',    'len', '1990', 'VH'),\n",
       "            ('K',    'len', '1990', 'VL'),\n",
       "            ('K',    'len', '1991',  'H'),\n",
       "            ('K',    'len', '1991',  'L'),\n",
       "            ('K',    'len', '1991',  'M'),\n",
       "            ('K',    'len', '1991', 'VH'),\n",
       "            ('K',    'len', '1991', 'VL'),\n",
       "            ...\n",
       "            ('K', 'median', '2018',  'H'),\n",
       "            ('K', 'median', '2018',  'L'),\n",
       "            ('K', 'median', '2018',  'M'),\n",
       "            ('K', 'median', '2018', 'VH'),\n",
       "            ('K', 'median', '2018', 'VL'),\n",
       "            ('K', 'median', '2019',  'H'),\n",
       "            ('K', 'median', '2019',  'L'),\n",
       "            ('K', 'median', '2019',  'M'),\n",
       "            ('K', 'median', '2019', 'VH'),\n",
       "            ('K', 'median', '2019', 'VL')],\n",
       "           names=[None, None, 'YEAR', 'CAT_K'], length=300)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_corn_p.columns)\n",
    "df_corn_k.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corn_p.columns = list(map(\"_\".join,df_corn_p.columns))\n",
    "df_corn_k.columns = list(map(\"_\".join,df_corn_k.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['P_len_1990_H', 'P_len_1990_L', 'P_len_1990_M', 'P_len_1990_VL',\n",
      "       'P_len_1991_H', 'P_len_1991_L', 'P_len_1991_M', 'P_len_1991_VL',\n",
      "       'P_len_1992_H', 'P_len_1992_L',\n",
      "       ...\n",
      "       'P_median_2017_M', 'P_median_2017_VL', 'P_median_2018_H',\n",
      "       'P_median_2018_L', 'P_median_2018_M', 'P_median_2018_VL',\n",
      "       'P_median_2019_H', 'P_median_2019_L', 'P_median_2019_M',\n",
      "       'P_median_2019_VL'],\n",
      "      dtype='object', length=240)\n",
      "Index(['K_len_1990_H', 'K_len_1990_L', 'K_len_1990_M', 'K_len_1990_VH',\n",
      "       'K_len_1990_VL', 'K_len_1991_H', 'K_len_1991_L', 'K_len_1991_M',\n",
      "       'K_len_1991_VH', 'K_len_1991_VL',\n",
      "       ...\n",
      "       'K_median_2018_H', 'K_median_2018_L', 'K_median_2018_M',\n",
      "       'K_median_2018_VH', 'K_median_2018_VL', 'K_median_2019_H',\n",
      "       'K_median_2019_L', 'K_median_2019_M', 'K_median_2019_VH',\n",
      "       'K_median_2019_VL'],\n",
      "      dtype='object', length=300)\n"
     ]
    }
   ],
   "source": [
    "print(df_corn_p.columns)\n",
    "print(df_corn_k.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['count_1990_H', 'count_1990_L', 'count_1990_M', 'count_1990_VL',\n",
      "       'count_1991_H', 'count_1991_L', 'count_1991_M', 'count_1991_VL',\n",
      "       'count_1992_H', 'count_1992_L',\n",
      "       ...\n",
      "       '2017_M', '2017_VL', '2018_H', '2018_L', '2018_M', '2018_VL', '2019_H',\n",
      "       '2019_L', '2019_M', '2019_VL'],\n",
      "      dtype='object', length=240)\n",
      "Index(['count_1990_H', 'count_1990_L', 'count_1990_M', 'count_1990_VH',\n",
      "       'count_1990_VL', 'count_1991_H', 'count_1991_L', 'count_1991_M',\n",
      "       'count_1991_VH', 'count_1991_VL',\n",
      "       ...\n",
      "       '2018_H', '2018_L', '2018_M', '2018_VH', '2018_VL', '2019_H', '2019_L',\n",
      "       '2019_M', '2019_VH', '2019_VL'],\n",
      "      dtype='object', length=300)\n"
     ]
    }
   ],
   "source": [
    "df_corn_p.columns = df_corn_p.columns.str.replace(\"P_median_\", \"\")\n",
    "df_corn_p.columns = df_corn_p.columns.str.replace(\"P_len\", \"count\")\n",
    "df_corn_k.columns = df_corn_k.columns.str.replace(\"K_median_\",\"\")\n",
    "df_corn_k.columns = df_corn_k.columns.str.replace(\"K_len\",\"count\")\n",
    "print(df_corn_p.columns)\n",
    "print(df_corn_k.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reindex unpivot table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     COUNTY  count_1990_H  count_1990_L  count_1990_M  count_1990_VL  \\\n",
      "0     ADAIR            15             4            11              0   \n",
      "1     ALLEN             7            10             6              0   \n",
      "2  ANDERSON            10             3             1              1   \n",
      "3   BALLARD            69             0            12              0   \n",
      "4    BARREN            66             9            26              0   \n",
      "\n",
      "   count_1991_H  count_1991_L  count_1991_M  count_1991_VL  count_1992_H  ...  \\\n",
      "0            24             7             4              0            18  ...   \n",
      "1            19             4            18              0             9  ...   \n",
      "2            18             3             9              0             9  ...   \n",
      "3            33             4            28              0            51  ...   \n",
      "4            86             9            45              0           114  ...   \n",
      "\n",
      "   2017_M  2017_VL  2018_H  2018_L  2018_M  2018_VL  2019_H  2019_L  2019_M  \\\n",
      "0    44.0        0   140.0    20.0    42.0        0   104.0    24.0    43.0   \n",
      "1    36.0        0   116.0     0.0    34.0        0   312.0    16.0    38.0   \n",
      "2     0.0        0   147.0     8.0    30.0        0   248.0     0.0    51.0   \n",
      "3    42.0        0    74.0     0.0    37.0        0    74.0    24.0    46.0   \n",
      "4    58.0        0   108.0    24.0    45.0        0   133.0    20.0    45.0   \n",
      "\n",
      "   2019_VL  \n",
      "0        2  \n",
      "1        0  \n",
      "2        0  \n",
      "3        0  \n",
      "4        2  \n",
      "\n",
      "[5 rows x 241 columns]\n",
      "     COUNTY  count_1990_H  count_1990_L  count_1990_M  count_1990_VH  \\\n",
      "0     ADAIR             3            12            12              1   \n",
      "1     ALLEN             2             6            13              1   \n",
      "2  ANDERSON             4             5             3              2   \n",
      "3   BALLARD            20            10            48              3   \n",
      "4    BARREN            32            16            26             26   \n",
      "\n",
      "   count_1990_VL  count_1991_H  count_1991_L  count_1991_M  count_1991_VH  \\\n",
      "0              2             5            12            12              4   \n",
      "1              1            11             7            18              5   \n",
      "2              1             9             6            11              4   \n",
      "3              0            11            17            35              2   \n",
      "4              1            35            23            62             19   \n",
      "\n",
      "   ...  2018_H  2018_L  2018_M  2018_VH  2018_VL  2019_H  2019_L  2019_M  \\\n",
      "0  ...   346.0   156.0   237.0    455.0     91.0   336.0   160.0   234.0   \n",
      "1  ...     0.0     0.0   234.0      0.0     95.0     0.0   140.0   217.0   \n",
      "2  ...     0.0   174.0   216.0    502.0     96.0     0.0   181.0   209.0   \n",
      "3  ...   309.0   168.0   222.0    509.0      0.0   387.0   164.0   211.0   \n",
      "4  ...   339.0   184.0   243.0    451.0      0.0   358.0   162.0   219.0   \n",
      "\n",
      "   2019_VH  2019_VL  \n",
      "0      0.0     78.0  \n",
      "1      0.0     86.0  \n",
      "2    543.0      0.0  \n",
      "3      0.0      0.0  \n",
      "4    422.0     90.0  \n",
      "\n",
      "[5 rows x 301 columns]\n"
     ]
    }
   ],
   "source": [
    "df_corn_p = df_corn_p.reset_index()\n",
    "df_corn_k = df_corn_k.reset_index()\n",
    "print(df_corn_p.head())\n",
    "print(df_corn_k.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save categorized data to file. Separate by crop and nutrient type (P and K) with count by category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records written to CSV: 120 \n",
      "\n",
      "total number of records written to CSV: 120 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_out_p = fileOut.joinpath('corn_p_levels.csv')  # path and filename\n",
    "df_corn_p.to_csv(file_out_p, index=False)  # output to csv\n",
    "file_out_k = fileOut.joinpath('corn_k_levels.csv')  # path and filename\n",
    "df_corn_k.to_csv(file_out_k, index=False)  # output to csv\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_corn_p)),'\\n')\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_corn_k)),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile = ProfileReport((df_corn_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soybeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list to select Soybeans from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barley/Soybeans', 'Canola/Soybeans', 'Oats/Soybeans', 'Rye/Soybeans', 'Small Grains/Soybeans', 'Soybeans', 'Triticale/Soybeans', 'Wheat/Soybeans']\n"
     ]
    }
   ],
   "source": [
    "soy_sel = ['Soybeans', 'Small Grains/Soybeans', 'Wheat/Soybeans', 'Canola/Soybeans', 'Rye/Soybeans', 'Oats/Soybeans', 'Barley/Soybeans', 'Triticale/Soybeans']\n",
    "soy_sel.sort()\n",
    "print(soy_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select soybeans from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     FIPS_NO COUNTY  YEAR      P      K\n",
      "628        1  ADAIR  1991  238.0  318.0\n",
      "1879       1  ADAIR  1995   83.0  173.0\n",
      "1880       1  ADAIR  1995   59.0  150.0\n",
      "1881       1  ADAIR  1995   65.0  152.0\n",
      "1882       1  ADAIR  1995  148.0  317.0\n"
     ]
    }
   ],
   "source": [
    "df_soy = df[df.CROP.isin(soy_sel)]\n",
    "df_soy_nu = df_soy[['FIPS_NO','COUNTY','YEAR','P','K']].copy()\n",
    "print(df_soy_nu.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soybeans, Set categories for P and K values to very low, low, medium, high, very high. Base values from AGR-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories for P\n",
    "        Cat      Title       Break\n",
    "        -------------------------------------\n",
    "        VL       very low    P<= 5\n",
    "        L        low         P>5 & P<=27\n",
    "        M        medium      P>27 & P<=60\n",
    "        H        high        P>60\n",
    "\n",
    "#### Categories for K\n",
    "        Cat      Title      Break\n",
    "       --------------------------------------\n",
    "        VL       very low   K< 100\n",
    "        L        low        K>=100 & K <=190\n",
    "        M        medium     K>=191 & K <=300\n",
    "        H        high       K>300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soy_nu['CAT_P'] = ''\n",
    "df_soy_nu['CAT_P'] = np.where(df_soy_nu.P <= 5, 'VL', df_soy_nu.CAT_P)\n",
    "df_soy_nu['CAT_P'] = np.where(((df_soy_nu.P > 5) & (df_soy_nu.P <= 27)), 'L', df_soy_nu.CAT_P)\n",
    "df_soy_nu['CAT_P'] = np.where(((df_soy_nu.P > 27) & (df_soy_nu.P <= 60)), 'M', df_soy_nu.CAT_P)\n",
    "df_soy_nu['CAT_P'] = np.where((df_soy_nu.P > 60), 'H', df_soy_nu.CAT_P)\n",
    "\n",
    "df_soy_nu['CAT_K'] = ''\n",
    "df_soy_nu['CAT_K'] = np.where(df_soy_nu.K <= 99, 'VL', df_soy_nu.CAT_K)\n",
    "df_soy_nu['CAT_K'] = np.where(((df_soy_nu.K > 99) & (df_soy_nu.K <= 190)), 'L', df_soy_nu.CAT_K)\n",
    "df_soy_nu['CAT_K'] = np.where(((df_soy_nu.K > 190) & (df_soy_nu.K <= 300)), 'M', df_soy_nu.CAT_K)\n",
    "df_soy_nu['CAT_K'] = np.where((df_soy_nu.K > 300), 'H', df_soy_nu.CAT_K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "df_soy_p = np.round( df_soy_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_P'], values=['P'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "df_soy_k = np.round( df_soy_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_K'], values=['K'],aggfunc=(np.median,len),fill_value=0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records written to CSV: 117 \n",
      "\n",
      "total number of records written to CSV: 117 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_soy_p.columns\n",
    "df_soy_k.columns\n",
    "df_soy_p.columns = list(map(\"_\".join,df_soy_p.columns))\n",
    "df_soy_k.columns = list(map(\"_\".join,df_soy_k.columns))\n",
    "df_soy_p.columns = df_soy_p.columns.str.replace(\"P_median_\", \"\")\n",
    "df_soy_p.columns = df_soy_p.columns.str.replace(\"P_len\", \"count\")\n",
    "df_soy_k.columns = df_soy_k.columns.str.replace(\"K_median_\",\"\")\n",
    "df_soy_k.columns = df_soy_k.columns.str.replace(\"K_len\",\"count\")\n",
    "df_soy_p = df_soy_p.reset_index()\n",
    "df_soy_k = df_soy_k.reset_index()\n",
    "file_out_p = fileOut.joinpath('soy_p_levels.csv')  # path and filename\n",
    "df_soy_p.to_csv(file_out_p, index=False)  # output to csv\n",
    "file_out_k = fileOut.joinpath('soy_k_levels.csv')  # path and filename\n",
    "df_soy_k.to_csv(file_out_k, index=False)  # output to csv\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_soy_p)),'\\n')\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_soy_k)),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canola"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list to select Canola from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Canola', 'Canola/Soybeans']\n"
     ]
    }
   ],
   "source": [
    "canola_sel = ['Canola', 'Canola/Soybeans']\n",
    "canola_sel.sort()\n",
    "print(canola_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Canola from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      FIPS_NO     COUNTY  YEAR     P      K\n",
      "14175     101  HENDERSON  1991  29.0  200.0\n",
      "14176     101  HENDERSON  1991  36.0  163.0\n",
      "14177     101  HENDERSON  1991  43.0  250.0\n",
      "14178     101  HENDERSON  1991  25.0  163.0\n",
      "14179     101  HENDERSON  1991  36.0  158.0\n"
     ]
    }
   ],
   "source": [
    "df_canola = df[df.CROP.isin(canola_sel)]\n",
    "df_canola_nu = df_canola[['FIPS_NO','COUNTY','YEAR','P','K']].copy()\n",
    "print(df_canola_nu.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Canola, Set categories for P and K values to very low, low, medium, high, very high. Base values from AGR-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories for P\n",
    "    Cat      Title       Break\n",
    "    -------------------------------------\n",
    "    VL       very low    P< 10\n",
    "    L        low         P>= 10 & P<=30\n",
    "    M        medium      P>30 & P<=60\n",
    "    H        high        P>60\n",
    "    \n",
    "#### Categories for K\n",
    "    Cat      Title      Break\n",
    "   --------------------------------------\n",
    "    VL       very low   K< 104\n",
    "    L        low        K>=104 & K <=186\n",
    "    M        medium     K>=187 & K <=300\n",
    "    H        high       K>300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_canola_nu['CAT_P'] = ''\n",
    "df_canola_nu['CAT_P'] = np.where(df_canola_nu.P < 10, 'VL', df_canola_nu.CAT_P)\n",
    "df_canola_nu['CAT_P'] = np.where(((df_canola_nu.P > 10) & (df_canola_nu.P <= 30)), 'L', df_canola_nu.CAT_P)\n",
    "df_canola_nu['CAT_P'] = np.where(((df_canola_nu.P > 30) & (df_canola_nu.P <= 60)), 'M', df_canola_nu.CAT_P)\n",
    "df_canola_nu['CAT_P'] = np.where((df_canola_nu.P > 60), 'H', df_canola_nu.CAT_P)\n",
    "\n",
    "df_canola_nu['CAT_K'] = ''\n",
    "df_canola_nu['CAT_K'] = np.where(df_canola_nu.K < 104, 'VL', df_canola_nu.CAT_K)\n",
    "df_canola_nu['CAT_K'] = np.where(((df_canola_nu.K > 104) & (df_canola_nu.K <= 186)), 'L', df_canola_nu.CAT_K)\n",
    "df_canola_nu['CAT_K'] = np.where(((df_canola_nu.K > 186) & (df_canola_nu.K <= 300)), 'M', df_canola_nu.CAT_K)\n",
    "df_canola_nu['CAT_K'] = np.where((df_canola_nu.K > 300), 'H', df_canola_nu.CAT_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "df_canola_p = np.round( df_canola_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_P'], values=['P'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "df_canola_k = np.round( df_canola_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_K'], values=['K'],aggfunc=(np.median,len),fill_value=0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records written to CSV: 65 \n",
      "\n",
      "total number of records written to CSV: 65 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_canola_p.columns\n",
    "df_canola_k.columns\n",
    "df_canola_p.columns = list(map(\"_\".join,df_canola_p.columns))\n",
    "df_canola_k.columns = list(map(\"_\".join,df_canola_k.columns))\n",
    "df_canola_p.columns = df_canola_p.columns.str.replace(\"P_median_\", \"\")\n",
    "df_canola_p.columns = df_canola_p.columns.str.replace(\"P_len\", \"count\")\n",
    "df_canola_k.columns = df_canola_k.columns.str.replace(\"K_median_\",\"\")\n",
    "df_canola_k.columns = df_canola_k.columns.str.replace(\"K_len\",\"count\")\n",
    "df_canola_p = df_canola_p.reset_index()\n",
    "df_canola_k = df_canola_k.reset_index()\n",
    "file_out_p = fileOut.joinpath('canola_p_levels.csv')  # path and filename\n",
    "df_canola_p.to_csv(file_out_p, index=False)  # output to csv\n",
    "file_out_k = fileOut.joinpath('canola_k_levels.csv')  # path and filename\n",
    "df_canola_k.to_csv(file_out_k, index=False)  # output to csv\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_canola_p)),'\\n')\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_canola_k)),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorghum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list to select Sorghum from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Grain Sorghum']\n"
     ]
    }
   ],
   "source": [
    "sorghum_sel = ['Grain Sorghum']\n",
    "sorghum_sel.sort()\n",
    "print(sorghum_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Sorghum from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      FIPS_NO     COUNTY  YEAR      P       K\n",
      "2237        1      ADAIR  1996   67.0   284.0\n",
      "2532        1      ADAIR  1997  318.0   303.0\n",
      "18439     101  HENDERSON  2007   42.0  1281.0\n",
      "18440     101  HENDERSON  2007  120.0  1499.0\n",
      "19885     101  HENDERSON  2014   48.0   110.0\n"
     ]
    }
   ],
   "source": [
    "df_sorghum = df[df.CROP.isin(sorghum_sel)]\n",
    "df_sorghum_nu = df_sorghum[['FIPS_NO','COUNTY','YEAR','P','K']].copy()\n",
    "print(df_sorghum_nu.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorghum, Set categories for P and K values to very low, low, medium, high, very high. Base values from AGR-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories for P\n",
    "    Cat      Title       Break\n",
    "    -------------------------------------\n",
    "    VL       very low    P< 6\n",
    "    L        low         P>= 6 & P<=27\n",
    "    M        medium      P>27 & P<=60\n",
    "    H        high        P>60\n",
    "    \n",
    "#### Categories for K\n",
    "    Cat      Title      Break\n",
    "   --------------------------------------\n",
    "    VL       very low   K< 100\n",
    "    L        low        K>=100 & K <=190\n",
    "    M        medium     K>=191 & K <=300\n",
    "    H        high       K>300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorghum_nu['CAT_P'] = ''\n",
    "df_sorghum_nu['CAT_P'] = np.where(df_sorghum_nu.P < 6, 'VL', df_sorghum_nu.CAT_P)\n",
    "df_sorghum_nu['CAT_P'] = np.where(((df_sorghum_nu.P >= 6) & (df_sorghum_nu.P <= 27)), 'L', df_sorghum_nu.CAT_P)\n",
    "df_sorghum_nu['CAT_P'] = np.where(((df_sorghum_nu.P > 27) & (df_sorghum_nu.P <= 60)), 'M', df_sorghum_nu.CAT_P)\n",
    "df_sorghum_nu['CAT_P'] = np.where((df_sorghum_nu.P > 60), 'H', df_sorghum_nu.CAT_P)\n",
    "\n",
    "df_sorghum_nu['CAT_K'] = ''\n",
    "df_sorghum_nu['CAT_K'] = np.where(df_sorghum_nu.K < 100, 'VL', df_sorghum_nu.CAT_K)\n",
    "df_sorghum_nu['CAT_K'] = np.where(((df_sorghum_nu.K >= 100) & (df_sorghum_nu.K <= 190)), 'L', df_sorghum_nu.CAT_K)\n",
    "df_sorghum_nu['CAT_K'] = np.where(((df_sorghum_nu.K > 190) & (df_sorghum_nu.K <= 300)), 'M', df_sorghum_nu.CAT_K)\n",
    "df_sorghum_nu['CAT_K'] = np.where((df_sorghum_nu.K > 300), 'H', df_sorghum_nu.CAT_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records written to CSV: 73 \n",
      "\n",
      "total number of records written to CSV: 73 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "df_sorghum_p = np.round( df_sorghum_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_P'], values=['P'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "df_sorghum_k = np.round( df_sorghum_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_K'], values=['K'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "\n",
    "df_sorghum_p.columns\n",
    "df_sorghum_k.columns\n",
    "df_sorghum_p.columns = list(map(\"_\".join,df_sorghum_p.columns))\n",
    "df_sorghum_k.columns = list(map(\"_\".join,df_sorghum_k.columns))\n",
    "df_sorghum_p.columns = df_sorghum_p.columns.str.replace(\"P_median_\", \"\")\n",
    "df_sorghum_p.columns = df_sorghum_p.columns.str.replace(\"P_len\", \"count\")\n",
    "df_sorghum_k.columns = df_sorghum_k.columns.str.replace(\"K_median_\",\"\")\n",
    "df_sorghum_k.columns = df_sorghum_k.columns.str.replace(\"K_len\",\"count\")\n",
    "df_sorghum_p = df_sorghum_p.reset_index()\n",
    "df_sorghum_k = df_sorghum_k.reset_index()\n",
    "file_out_p = fileOut.joinpath('sorghum_p_levels.csv')  # path and filename\n",
    "df_sorghum_p.to_csv(file_out_p, index=False)  # output to csv\n",
    "file_out_k = fileOut.joinpath('sorghum_k_levels.csv')  # path and filename\n",
    "df_sorghum_k.to_csv(file_out_k, index=False)  # output to csv\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_sorghum_p)),'\\n')\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_sorghum_k)),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small Grains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list to select Small Grains from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barley', 'Barley/Soybeans', 'Grain Crops (multiple)', 'Oats', 'Oats/Soybeans', 'Rye/Soybeans', 'Small Grains', 'Small Grains/Corn', 'Small Grains/Soybeans', 'Triticale', 'Triticale/Soybeans', 'Wheat', 'Wheat/Corn', 'Wheat/Soybeans']\n"
     ]
    }
   ],
   "source": [
    "smallgrains_sel = ['Barley' , 'Barley/Soybeans', 'Grain Crops (multiple)','Oats','Oats/Soybeans', 'Rye/Soybeans', 'Small Grains', 'Small Grains/Corn', 'Small Grains/Soybeans', 'Triticale', 'Triticale/Soybeans', 'Wheat', 'Wheat/Corn', 'Wheat/Soybeans']\n",
    "smallgrains_sel.sort()\n",
    "print(smallgrains_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Small Grains from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     FIPS_NO COUNTY  YEAR     P      K\n",
      "635        1  ADAIR  1991  16.0  234.0\n",
      "901        1  ADAIR  1992  51.0  203.0\n",
      "969        1  ADAIR  1992  29.0  152.0\n",
      "970        1  ADAIR  1992  15.0  193.0\n",
      "1333       1  ADAIR  1993  16.0   94.0\n"
     ]
    }
   ],
   "source": [
    "df_smallgrains = df[df.CROP.isin(smallgrains_sel)]\n",
    "df_smallgrains_nu = df_smallgrains[['FIPS_NO','COUNTY','YEAR','P','K']].copy()\n",
    "print(df_smallgrains_nu.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small Grains, Set categories for P and K values to very low, low, medium, high, very high. Base values from AGR-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories for P\n",
    "    Cat      Title       Break\n",
    "    -------------------------------------\n",
    "    VL       very low    P< 10\n",
    "    L        low         P>= 10 & P<=30\n",
    "    M        medium      P>30 & P<=60\n",
    "    H        high        P>60\n",
    "    \n",
    "#### Categories for K\n",
    "    Cat      Title      Break\n",
    "   --------------------------------------\n",
    "    VL       very low   K< 104\n",
    "    L        low        K>=104 & K <=186\n",
    "    M        medium     K>=187 & K <=300\n",
    "    H        high       K>300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smallgrains_nu['CAT_P'] = ''\n",
    "df_smallgrains_nu['CAT_P'] = np.where(df_smallgrains_nu.P < 10, 'VL', df_smallgrains_nu.CAT_P)\n",
    "df_smallgrains_nu['CAT_P'] = np.where(((df_smallgrains_nu.P > 10) & (df_smallgrains_nu.P <= 30)), 'L', df_smallgrains_nu.CAT_P)\n",
    "df_smallgrains_nu['CAT_P'] = np.where(((df_smallgrains_nu.P > 30) & (df_smallgrains_nu.P <= 60)), 'M', df_smallgrains_nu.CAT_P)\n",
    "df_smallgrains_nu['CAT_P'] = np.where((df_smallgrains_nu.P > 60), 'H', df_smallgrains_nu.CAT_P)\n",
    "\n",
    "df_smallgrains_nu['CAT_K'] = ''\n",
    "df_smallgrains_nu['CAT_K'] = np.where(df_smallgrains_nu.K < 104, 'VL', df_smallgrains_nu.CAT_K)\n",
    "df_smallgrains_nu['CAT_K'] = np.where(((df_smallgrains_nu.K >= 104) & (df_smallgrains_nu.K <= 186)), 'L', df_smallgrains_nu.CAT_K)\n",
    "df_smallgrains_nu['CAT_K'] = np.where(((df_smallgrains_nu.K > 186) & (df_smallgrains_nu.K <= 300)), 'M', df_smallgrains_nu.CAT_K)\n",
    "df_smallgrains_nu['CAT_K'] = np.where((df_smallgrains_nu.K > 300), 'H', df_smallgrains_nu.CAT_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records written to CSV: 119 \n",
      "\n",
      "total number of records written to CSV: 119 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "df_smallgrains_p = np.round( df_smallgrains_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_P'], values=['P'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "df_smallgrains_k = np.round( df_smallgrains_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_K'], values=['K'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "\n",
    "df_smallgrains_p.columns\n",
    "df_smallgrains_k.columns\n",
    "df_smallgrains_p.columns = list(map(\"_\".join,df_smallgrains_p.columns))\n",
    "df_smallgrains_k.columns = list(map(\"_\".join,df_smallgrains_k.columns))\n",
    "df_smallgrains_p.columns = df_smallgrains_p.columns.str.replace(\"P_median_\", \"\")\n",
    "df_smallgrains_p.columns = df_smallgrains_p.columns.str.replace(\"P_len\", \"count\")\n",
    "df_smallgrains_k.columns = df_smallgrains_k.columns.str.replace(\"K_median_\",\"\")\n",
    "df_smallgrains_k.columns = df_smallgrains_k.columns.str.replace(\"K_len\",\"count\")\n",
    "df_smallgrains_p = df_smallgrains_p.reset_index()\n",
    "df_smallgrains_k = df_smallgrains_k.reset_index()\n",
    "file_out_p = fileOut.joinpath('smallgrains_p_levels.csv')  # path and filename\n",
    "df_smallgrains_p.to_csv(file_out_p, index=False)  # output to csv\n",
    "file_out_k = fileOut.joinpath('smallgrains_k_levels.csv')  # path and filename\n",
    "df_smallgrains_k.to_csv(file_out_k, index=False)  # output to csv\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_smallgrains_p)),'\\n')\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_smallgrains_k)),'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tobacco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list to select Tobacco from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Burley Tobacco', 'Dark Tobacco']\n"
     ]
    }
   ],
   "source": [
    "tobacco_sel = ['Burley Tobacco', 'Dark Tobacco']\n",
    "tobacco_sel.sort()\n",
    "print(tobacco_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Tobacco from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FIPS_NO COUNTY  YEAR      P      K\n",
      "24       1  ADAIR  1990  282.0  298.0\n",
      "25       1  ADAIR  1990  206.0  611.0\n",
      "26       1  ADAIR  1990   71.0  120.0\n",
      "27       1  ADAIR  1990  124.0  320.0\n",
      "28       1  ADAIR  1990  300.0  283.0\n"
     ]
    }
   ],
   "source": [
    "df_tobacco = df[df.CROP.isin(tobacco_sel)]\n",
    "df_tobacco_nu = df_tobacco[['FIPS_NO','COUNTY','YEAR','P','K']].copy()\n",
    "print(df_tobacco_nu.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tobacco, Set categories for P and K values to very low, low, medium, high, very high. Base values from AGR-1.\n",
    "Combined Burley and Dark Tobacco K into Burley recommendations for K categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories for P\n",
    "    Cat      Title       Break\n",
    "    -------------------------------------\n",
    "    VL       very low    P< 7\n",
    "    L        low         P>= 7 & P<=28\n",
    "    M        medium      P>28 & P<=57\n",
    "    H        high        P>57 & P<=79\n",
    "    VH       very high   P> 80\n",
    "    \n",
    "\n",
    "#### Categories for K\n",
    "    Cat      Title      Break\n",
    "   --------------------------------------\n",
    "    VL       very low   K< 96\n",
    "    L        low        K>=96 & K <=205\n",
    "    M        medium     K>205 & K <=303\n",
    "    H        high       K>303 & K <=449\n",
    "    VH       very high  K> 450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tobacco_nu['CAT_P'] = ''\n",
    "df_tobacco_nu['CAT_P'] = np.where(df_tobacco_nu.P < 7, 'VL', df_tobacco_nu.CAT_P)\n",
    "df_tobacco_nu['CAT_P'] = np.where(((df_tobacco_nu.P >= 7) & (df_tobacco_nu.P <= 28)), 'L', df_tobacco_nu.CAT_P)\n",
    "df_tobacco_nu['CAT_P'] = np.where(((df_tobacco_nu.P > 28) & (df_tobacco_nu.P <= 57)), 'M', df_tobacco_nu.CAT_P)\n",
    "df_tobacco_nu['CAT_P'] = np.where(((df_tobacco_nu.P > 57) &  (df_tobacco_nu.P <= 79)), 'H', df_tobacco_nu.CAT_P)\n",
    "df_tobacco_nu['CAT_P'] = np.where(df_tobacco_nu.P > 80, 'VH', df_tobacco_nu.CAT_P)\n",
    "df_tobacco_nu['CAT_K'] = ''\n",
    "df_tobacco_nu['CAT_K'] = np.where(df_tobacco_nu.K < 96, 'VL', df_tobacco_nu.CAT_K)\n",
    "df_tobacco_nu['CAT_K'] = np.where(((df_tobacco_nu.K >= 96) & (df_tobacco_nu.K <= 205)), 'L', df_tobacco_nu.CAT_K)\n",
    "df_tobacco_nu['CAT_K'] = np.where(((df_tobacco_nu.K > 205) & (df_tobacco_nu.K <= 303)), 'M', df_tobacco_nu.CAT_K)\n",
    "df_tobacco_nu['CAT_K'] = np.where(((df_tobacco_nu.K > 303) & (df_tobacco_nu.K <= 449)), 'H', df_tobacco_nu.CAT_K)\n",
    "df_tobacco_nu['CAT_K'] = np.where(df_tobacco_nu.K > 450, 'VH', df_tobacco_nu.CAT_K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records written to CSV: 120 \n",
      "\n",
      "total number of records written to CSV: 120 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "df_tobacco_p = np.round( df_tobacco_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_P'], values=['P'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "df_tobacco_k = np.round( df_tobacco_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_K'], values=['K'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "\n",
    "df_tobacco_p.columns\n",
    "df_tobacco_k.columns\n",
    "df_tobacco_p.columns = list(map(\"_\".join,df_tobacco_p.columns))\n",
    "df_tobacco_k.columns = list(map(\"_\".join,df_tobacco_k.columns))\n",
    "df_tobacco_p.columns = df_tobacco_p.columns.str.replace(\"P_median_\", \"\")\n",
    "df_tobacco_p.columns = df_tobacco_p.columns.str.replace(\"P_len\", \"count\")\n",
    "df_tobacco_k.columns = df_tobacco_k.columns.str.replace(\"K_median_\",\"\")\n",
    "df_tobacco_k.columns = df_tobacco_k.columns.str.replace(\"K_len\",\"count\")\n",
    "df_tobacco_p = df_tobacco_p.reset_index()\n",
    "df_tobacco_k = df_tobacco_k.reset_index()\n",
    "file_out_p = fileOut.joinpath('tobacco_p_levels.csv')  # path and filename\n",
    "df_tobacco_p.to_csv(file_out_p, index=False)  # output to csv\n",
    "file_out_k = fileOut.joinpath('tobacco_k_levels.csv')  # path and filename\n",
    "df_tobacco_k.to_csv(file_out_k, index=False)  # output to csv\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_tobacco_p)),'\\n')\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_tobacco_k)),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm Season Grass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list to select Warm Season Grass from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bermudagrass', 'Bermudagrass, common', 'Bermudagrass, improved', 'Bluestem', 'Indiangrass', 'Millet', 'Sorghum Sudangrass', 'Sorghum/Sudangras', 'Sudangrass', 'Switchgrass', 'Warm Season Annual Grass', 'Warm Season Grass', 'Warm Season Native Grass', 'Zoyiagrass', 'Zoysiagrass']\n"
     ]
    }
   ],
   "source": [
    "warmseason_sel = ['Bermudagrass', 'Bermudagrass, common', 'Bermudagrass, improved', 'Bluestem', 'Indiangrass', 'Millet', 'Sorghum Sudangrass', 'Sorghum/Sudangras', 'Sudangrass', 'Switchgrass', 'Warm Season Annual Grass', 'Warm Season Grass', 'Warm Season Native Grass', 'Zoyiagrass', 'Zoysiagrass']\n",
    "warmseason_sel.sort()\n",
    "print(warmseason_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Warm Season Grass from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     FIPS_NO COUNTY  YEAR     P      K\n",
      "968        1  ADAIR  1992  89.0  194.0\n",
      "1564       1  ADAIR  1994  93.0  153.0\n",
      "1887       1  ADAIR  1995  26.0  178.0\n",
      "2266       1  ADAIR  1996  58.0  129.0\n",
      "2606       1  ADAIR  1997  94.0  214.0\n"
     ]
    }
   ],
   "source": [
    " df_warmseason = df[df.CROP.isin(warmseason_sel)]\n",
    " df_warmseason_nu = df_warmseason[['FIPS_NO','COUNTY','YEAR','P','K']].copy()\n",
    " print(df_warmseason_nu.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warm Season Grass, Set categories for P and K values to very low, low, medium, high, very high. Base values from AGR-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories for P\n",
    "    Cat      Title       Break\n",
    "    -------------------------------------\n",
    "    VL       very low    P< 10\n",
    "    L        low         P>= 10 & P<=30\n",
    "    M        medium      P>30 & P<=60\n",
    "    H        high        P>60\n",
    "    \n",
    "#### Categories for K\n",
    "    Cat      Title      Break\n",
    "   --------------------------------------\n",
    "    VL       very low   K< 100\n",
    "    L        low        K>=100 & K <=204\n",
    "    M        medium     K>=205 & K <=300\n",
    "    H        high       K>300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_warmseason_nu['CAT_P'] = ''\n",
    "df_warmseason_nu['CAT_P'] = np.where(df_warmseason_nu.P < 10, 'VL', df_warmseason_nu.CAT_P)\n",
    "df_warmseason_nu['CAT_P'] = np.where(((df_warmseason_nu.P > 10) & (df_warmseason_nu.P <= 30)), 'L', df_warmseason_nu.CAT_P)\n",
    "df_warmseason_nu['CAT_P'] = np.where(((df_warmseason_nu.P > 30) & (df_warmseason_nu.P <= 60)), 'M', df_warmseason_nu.CAT_P)\n",
    "df_warmseason_nu['CAT_P'] = np.where((df_warmseason_nu.P > 60), 'H', df_warmseason_nu.CAT_P)\n",
    " \n",
    "df_warmseason_nu['CAT_K'] = ''\n",
    "df_warmseason_nu['CAT_K'] = np.where(df_warmseason_nu.K < 100, 'VL', df_warmseason_nu.CAT_K)\n",
    "df_warmseason_nu['CAT_K'] = np.where(((df_warmseason_nu.K >= 100) & (df_warmseason_nu.K <= 204)), 'L', df_warmseason_nu.CAT_K)\n",
    "df_warmseason_nu['CAT_K'] = np.where(((df_warmseason_nu.K > 204) & (df_warmseason_nu.K <= 300)), 'M', df_warmseason_nu.CAT_K)\n",
    "df_warmseason_nu['CAT_K'] = np.where((df_warmseason_nu.K > 300), 'H', df_warmseason_nu.CAT_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records written to CSV: 116 \n",
      "\n",
      "total number of records written to CSV: 116 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "df_warmseason_p = np.round( df_warmseason_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_P'], values=['P'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "df_warmseason_k = np.round( df_warmseason_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_K'], values=['K'],aggfunc=(np.median,len),fill_value=0),2)\n",
    " \n",
    "df_warmseason_p.columns\n",
    "df_warmseason_k.columns\n",
    "df_warmseason_p.columns = list(map(\"_\".join,df_warmseason_p.columns))\n",
    "df_warmseason_k.columns = list(map(\"_\".join,df_warmseason_k.columns))\n",
    "df_warmseason_p.columns = df_warmseason_p.columns.str.replace(\"P_median_\", \"\")\n",
    "df_warmseason_p.columns = df_warmseason_p.columns.str.replace(\"P_len\", \"count\")\n",
    "df_warmseason_k.columns = df_warmseason_k.columns.str.replace(\"K_median_\",\"\")\n",
    "df_warmseason_k.columns = df_warmseason_k.columns.str.replace(\"K_len\",\"count\")\n",
    "df_warmseason_p = df_warmseason_p.reset_index()\n",
    "df_warmseason_k = df_warmseason_k.reset_index()\n",
    "file_out_p = fileOut.joinpath('warmseason_p_levels.csv')  # path and filename\n",
    "df_warmseason_p.to_csv(file_out_p, index=False)  # output to csv\n",
    "file_out_k = fileOut.joinpath('warmseason_k_levels.csv')  # path and filename\n",
    "df_warmseason_k.to_csv(file_out_k, index=False)  # output to csv\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_warmseason_p)),'\\n')\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_warmseason_k)),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cool Season Grass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list to select Cool Season Grass from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bluegrass', 'Cool Season Grass', 'Fescue', 'Fescue/Lespedeza', 'Fescue/Lespedeza (multiple)', 'Fine Fescue', 'Lespedeza', 'Lespedeza/Grass', 'Millet', 'Orchardgrass', 'Perennial Ryegrass', 'Sorghum Sudangrass', 'Sorghum/Sudangras', 'Switchgrass', 'Tall Fescue', 'Timothy']\n"
     ]
    }
   ],
   "source": [
    "coolseason_sel = ['Bluegrass', 'Cool Season Grass', 'Fescue', 'Fescue/Lespedeza', 'Fescue/Lespedeza (multiple)', 'Fine Fescue', 'Lespedeza', 'Lespedeza/Grass', 'Millet', 'Orchardgrass', 'Perennial Ryegrass', 'Sorghum Sudangrass', 'Sorghum/Sudangras', 'Switchgrass', 'Tall Fescue', 'Timothy']\n",
    "coolseason_sel.sort()\n",
    "print(coolseason_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Cool Season Grass from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    FIPS_NO COUNTY  YEAR      P      K\n",
      "187       1  ADAIR  1990   28.0  108.0\n",
      "188       1  ADAIR  1990   88.0  408.0\n",
      "189       1  ADAIR  1990   30.0  533.0\n",
      "190       1  ADAIR  1990   66.0  384.0\n",
      "191       1  ADAIR  1990  140.0  767.0\n"
     ]
    }
   ],
   "source": [
    "df_coolseason = df[df.CROP.isin(coolseason_sel)]\n",
    "df_coolseason_nu = df_coolseason[['FIPS_NO','COUNTY','YEAR','P','K']].copy()\n",
    "print(df_coolseason_nu.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cool Season Grass, Set categories for P and K values to very low, low, medium, high, very high. Base values from AGR-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories for P\n",
    "    Cat      Title       Break\n",
    "    -------------------------------------\n",
    "    VL       very low    P< 10\n",
    "    L        low         P>= 10 & P<=30\n",
    "    M        medium      P>30 & P<=60\n",
    "    H        high        P>60\n",
    "    \n",
    "#### Categories for K\n",
    "    Cat      Title      Break\n",
    "   --------------------------------------\n",
    "    VL       very low   K< 104\n",
    "    L        low        K>=104 & K <=186\n",
    "    M        medium     K>=187 & K <=300\n",
    "    H        high       K>300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coolseason_nu['CAT_P'] = ''\n",
    "df_coolseason_nu['CAT_P'] = np.where(df_coolseason_nu.P < 10, 'VL', df_coolseason_nu.CAT_P)\n",
    "df_coolseason_nu['CAT_P'] = np.where(((df_coolseason_nu.P > 10) & (df_coolseason_nu.P <= 30)), 'L', df_coolseason_nu.CAT_P)\n",
    "df_coolseason_nu['CAT_P'] = np.where(((df_coolseason_nu.P > 30) & (df_coolseason_nu.P <= 60)), 'M', df_coolseason_nu.CAT_P)\n",
    "df_coolseason_nu['CAT_P'] = np.where((df_coolseason_nu.P > 60), 'H', df_coolseason_nu.CAT_P)\n",
    " \n",
    "df_coolseason_nu['CAT_K'] = ''\n",
    "df_coolseason_nu['CAT_K'] = np.where(df_coolseason_nu.K < 104, 'VL', df_coolseason_nu.CAT_K)\n",
    "df_coolseason_nu['CAT_K'] = np.where(((df_coolseason_nu.K >= 104) & (df_coolseason_nu.K <= 186)), 'L', df_coolseason_nu.CAT_K)\n",
    "df_coolseason_nu['CAT_K'] = np.where(((df_coolseason_nu.K > 186) & (df_coolseason_nu.K <= 300)), 'M', df_coolseason_nu.CAT_K)\n",
    "df_coolseason_nu['CAT_K'] = np.where((df_coolseason_nu.K > 300), 'H', df_coolseason_nu.CAT_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records written to CSV: 120 \n",
      "\n",
      "total number of records written to CSV: 120 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "df_coolseason_p = np.round( df_coolseason_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_P'], values=['P'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "df_coolseason_k = np.round( df_coolseason_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_K'], values=['K'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "\n",
    "df_coolseason_p.columns\n",
    "df_coolseason_k.columns\n",
    "df_coolseason_p.columns = list(map(\"_\".join,df_coolseason_p.columns))\n",
    "df_coolseason_k.columns = list(map(\"_\".join,df_coolseason_k.columns))\n",
    "df_coolseason_p.columns = df_coolseason_p.columns.str.replace(\"P_median_\", \"\")\n",
    "df_coolseason_p.columns = df_coolseason_p.columns.str.replace(\"P_len\", \"count\")\n",
    "df_coolseason_k.columns = df_coolseason_k.columns.str.replace(\"K_median_\",\"\")\n",
    "df_coolseason_k.columns = df_coolseason_k.columns.str.replace(\"K_len\",\"count\")\n",
    "df_coolseason_p = df_coolseason_p.reset_index()\n",
    "df_coolseason_k = df_coolseason_k.reset_index()\n",
    "file_out_p = fileOut.joinpath('coolseason_p_levels.csv')  # path and filename\n",
    "df_coolseason_p.to_csv(file_out_p, index=False)  # output to csv\n",
    "file_out_k = fileOut.joinpath('coolseason_k_levels.csv')  # path and filename\n",
    "df_coolseason_k.to_csv(file_out_k, index=False)  # output to csv\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_coolseason_p)),'\\n')\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_coolseason_k)),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alfalfa Clover mix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list to select Alfalfa Clover mix from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alfalfa', 'Alfalfa/Cool Season', 'Bluegrass/White Clover', 'Clover/Grass', 'Fescue/White Clover', 'Orchardgrass/Red Clover', 'Orchardgrass/White Clover', 'Red Clover', 'Red Clover/Grass', 'Timothy/Red Clover', 'White Clover', 'White Clover/Grass']\n"
     ]
    }
   ],
   "source": [
    "alfalfa_sel = ['Alfalfa', 'Alfalfa/Cool Season', 'Bluegrass/White Clover', 'Clover/Grass', 'Fescue/White Clover', 'Orchardgrass/Red Clover', 'Orchardgrass/White Clover', 'Red Clover', 'Red Clover/Grass', 'Timothy/Red Clover', 'White Clover', 'White Clover/Grass']\n",
    "alfalfa_sel.sort()\n",
    "print(alfalfa_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Alfalfa Clover mixCanfrom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FIPS_NO COUNTY  YEAR      P      K\n",
      "0       1  ADAIR  1990   28.0  158.0\n",
      "1       1  ADAIR  1990   88.0  134.0\n",
      "2       1  ADAIR  1990   70.0  256.0\n",
      "3       1  ADAIR  1990  161.0  611.0\n",
      "4       1  ADAIR  1990  105.0  315.0\n"
     ]
    }
   ],
   "source": [
    "df_alfalfa = df[df.CROP.isin(alfalfa_sel)]\n",
    "df_alfalfa_nu = df_alfalfa[['FIPS_NO','COUNTY','YEAR','P','K']].copy()\n",
    "print(df_alfalfa_nu.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alfalfa Clover mix, Set categories for P and K values to very low, low, medium, high, very high. Base values from AGR-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories for P\n",
    "    Cat      Title       Break\n",
    "    -------------------------------------\n",
    "    VL       very low    P< 9\n",
    "    L        low         P>= 9 & P<=27\n",
    "    M        medium      P>28 & P<=60\n",
    "    H        high        P>60\n",
    "    \n",
    "#### Categories for K\n",
    "    Cat      Title      Break\n",
    "   --------------------------------------\n",
    "    VL       very low   K< 97\n",
    "    L        low        K>=97 & K <=203\n",
    "    M        medium     K>=204 & K <=296\n",
    "    H        high       K>296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alfalfa_nu['CAT_P'] = ''\n",
    "df_alfalfa_nu['CAT_P'] = np.where(df_alfalfa_nu.P < 9, 'VL', df_alfalfa_nu.CAT_P)\n",
    "df_alfalfa_nu['CAT_P'] = np.where(((df_alfalfa_nu.P >= 9) & (df_alfalfa_nu.P <= 27)), 'L', df_alfalfa_nu.CAT_P)\n",
    "df_alfalfa_nu['CAT_P'] = np.where(((df_alfalfa_nu.P > 27) & (df_alfalfa_nu.P <= 60)), 'M', df_alfalfa_nu.CAT_P)\n",
    "df_alfalfa_nu['CAT_P'] = np.where((df_alfalfa_nu.P > 60), 'H', df_alfalfa_nu.CAT_P)\n",
    "\n",
    "df_alfalfa_nu['CAT_K'] = ''\n",
    "df_alfalfa_nu['CAT_K'] = np.where(df_alfalfa_nu.K < 97, 'VL', df_alfalfa_nu.CAT_K)\n",
    "df_alfalfa_nu['CAT_K'] = np.where(((df_alfalfa_nu.K >= 97) & (df_alfalfa_nu.K <= 203)), 'L', df_alfalfa_nu.CAT_K)\n",
    "df_alfalfa_nu['CAT_K'] = np.where(((df_alfalfa_nu.K > 203) & (df_alfalfa_nu.K <= 296)), 'M', df_alfalfa_nu.CAT_K)\n",
    "df_alfalfa_nu['CAT_K'] = np.where((df_alfalfa_nu.K > 296), 'H', df_alfalfa_nu.CAT_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records written to CSV: 120 \n",
      "\n",
      "total number of records written to CSV: 120 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "df_alfalfa_p = np.round( df_alfalfa_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_P'], values=['P'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "df_alfalfa_k = np.round( df_alfalfa_nu.pivot_table(index='COUNTY', columns=['YEAR', 'CAT_K'], values=['K'],aggfunc=(np.median,len),fill_value=0),2)\n",
    "\n",
    "df_alfalfa_p.columns\n",
    "df_alfalfa_k.columns\n",
    "df_alfalfa_p.columns = list(map(\"_\".join,df_alfalfa_p.columns))\n",
    "df_alfalfa_k.columns = list(map(\"_\".join,df_alfalfa_k.columns))\n",
    "df_alfalfa_p.columns = df_alfalfa_p.columns.str.replace(\"P_median_\", \"\")\n",
    "df_alfalfa_p.columns = df_alfalfa_p.columns.str.replace(\"P_len\", \"count\")\n",
    "df_alfalfa_k.columns = df_alfalfa_k.columns.str.replace(\"K_median_\",\"\")\n",
    "df_alfalfa_k.columns = df_alfalfa_k.columns.str.replace(\"K_len\",\"count\")\n",
    "df_alfalfa_p = df_alfalfa_p.reset_index()\n",
    "df_alfalfa_k = df_alfalfa_k.reset_index()\n",
    "file_out_p = fileOut.joinpath('alfalfa_p_levels.csv')  # path and filename\n",
    "df_alfalfa_p.to_csv(file_out_p, index=False)  # output to csv\n",
    "file_out_k = fileOut.joinpath('alfalfa_k_levels.csv')  # path and filename\n",
    "df_alfalfa_k.to_csv(file_out_k, index=False)  # output to csv\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_alfalfa_p)),'\\n')\n",
    "print ('total number of records written to CSV:','{:,}'.format(len(df_alfalfa_k)),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
